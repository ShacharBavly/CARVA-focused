{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Curation Notebook C - Gene Set Annotation\n",
    "\n",
    "Covers:\n",
    "- Processing of annotation data\n",
    "- Biological features\n",
    "- Analysis of gene sets\n",
    "- analysis of overlap data\n",
    "\n",
    "\n",
    "Figures generated:\n",
    "- Figure 1C\n",
    "- Figure 1F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:41:38.398421Z",
     "start_time": "2025-06-30T20:41:38.395786Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "#import networkx as nx\n",
    "#import obonet as obo\n",
    "from scipy.stats import wilcoxon, mannwhitneyu\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:41:38.750684Z",
     "start_time": "2025-06-30T20:41:38.748827Z"
    }
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "datadir = os.path.join(cwd, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T18:18:18.614867Z",
     "start_time": "2025-06-30T18:18:18.613224Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elkon2/shacharbavly/micromamba/envs/networks/lib/python3.11/site-packages/obonet/__init__.py:12: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n"
     ]
    }
   ],
   "source": [
    "from neteval.gene_mapper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T18:18:26.054807Z",
     "start_time": "2025-06-30T18:18:26.047844Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "plt.rcParams.update({'font.size': 7})\n",
    "plt.rcParams['axes.linewidth'] = 0.5\n",
    "plt.rcParams['hatch.linewidth'] = 0.5\n",
    "plt.rcParams['xtick.major.width'] = 0.4\n",
    "plt.rcParams['ytick.major.width'] = 0.4\n",
    "plt.rcParams['xtick.minor.width'] = 0.3\n",
    "plt.rcParams['ytick.minor.width'] = 0.3\n",
    "plt.rcParams['legend.frameon'] = False\n",
    "plt.rcParams['xtick.major.size'] = 3\n",
    "plt.rcParams['ytick.major.size'] = 3\n",
    "plt.rcParams['xtick.minor.size'] = 2\n",
    "plt.rcParams['ytick.minor.size'] = 2\n",
    "plt.rcParams['xtick.major.pad'] = 1\n",
    "plt.rcParams['ytick.major.pad'] = 1\n",
    "plt.rcParams['axes.labelpad'] = 1\n",
    "plt.rcParams['patch.linewidth'] = 0.25\n",
    "import matplotlib.font_manager as fm\n",
    "arial_font_path = os.path.join(datadir, 'Reference_Data', 'Arial.TTF')\n",
    "fm.fontManager.addfont(arial_font_path)\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family'] = 'Arial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T18:18:45.232684Z",
     "start_time": "2025-06-30T18:18:45.230802Z"
    }
   },
   "outputs": [],
   "source": [
    "blue='#6ec1e0'\n",
    "green='#5fad56'\n",
    "shared='#af3800'\n",
    "binary='#00606f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T17:21:40.190603Z",
     "start_time": "2025-06-18T17:21:40.188929Z"
    }
   },
   "outputs": [],
   "source": [
    "#datadir='/cellar/users/snwright/Data/RareCommon/'\n",
    "#outdir='/cellar/users/snwright/Data/Transfer/RVC/'\n",
    "#figdir='/cellar/users/snwright/Data/Transfer/RVC/figures/FigureOverlap/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T17:21:40.197603Z",
     "start_time": "2025-06-18T17:21:40.195376Z"
    }
   },
   "outputs": [],
   "source": [
    "#basedir='/cellar/users/snwright/Data/RareCommon'\n",
    "#annot_dir = os.path.join(basedir, 'Annotations')\n",
    "#input_dir = os.path.join(basedir, 'inputs/March_2025')\n",
    "#keydir= os.path.join(basedir, 'outputs/key_files')\n",
    "#colocdir = os.path.join(basedir, 'outputs/netcoloc/March_2025')\n",
    "#figdir = '/cellar/users/snwright/Data/Transfer/RVC/figures/Bio_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T18:18:52.360279Z",
     "start_time": "2025-06-30T18:18:52.356391Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def map_trait_code(code):\n",
    "    efo = next((match.group() for match in re.finditer(r'EFO_\\d+', code)), None)\n",
    "    if efo is not None:\n",
    "        return efo\n",
    "    mondo = next((match.group() for match in re.finditer(r'MONDO_\\d+', code)), None)\n",
    "    if mondo is not None:\n",
    "        return mondo\n",
    "    hp = next((match.group() for match in re.finditer(r'HP_\\d+', code)), None)\n",
    "    if hp is not None:\n",
    "        return hp\n",
    "    go = next((match.group() for match in re.finditer(r'GO_\\d+', code)), None)\n",
    "    if go is not None:\n",
    "        return go\n",
    "    oba = next((match.group() for match in re.finditer(r'OBA_\\d+', code)), None)\n",
    "    if oba is not None:\n",
    "        return oba\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T18:19:27.041604Z",
     "start_time": "2025-06-30T18:19:27.039482Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_trait_pair(df):\n",
    "    df['trait_pair'] = df['Rare Study'].astype(int).astype(str) + '_' + df['EFO'] +'_' +df['Common Study'] +'_'+ df['EFO']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:40:20.323826Z",
     "start_time": "2025-06-30T22:40:20.313731Z"
    }
   },
   "outputs": [],
   "source": [
    "coloc_df = pd.read_csv(os.path.join(datadir, 'outputs/STable2.tsv'), sep='\\t', usecols=['EFO', 'Trait', 'Common Study',\n",
    "            'Rare Study', 'Analysis Set', 'nCommon', 'nRare', 'nShared', 'pShared'])\n",
    "coloc_df = get_trait_pair(coloc_df)\n",
    "over_df = coloc_df[coloc_df['Analysis Set']=='Initial'].copy()\n",
    "over_df['logp'] = -1 * np.log10(over_df['pShared'] + 1e-250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:38:34.513413Z",
     "start_time": "2025-06-30T22:38:34.511390Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs = over_df.trait_pair.values\n",
    "all_pairs = coloc_df.trait_pair.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutational Constraint\n",
    "\n",
    "- LOEUF\n",
    "    * -lof.oe_ci.upper: LOEUF: upper bound of 90% confidence interval for o/e ratio for high confidence pLoF variants (lower values indicate more constrained)\n",
    "- Synonymous intolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T18:23:57.024032Z",
     "start_time": "2025-06-30T18:23:57.019359Z"
    }
   },
   "outputs": [],
   "source": [
    "def prioritize_gene_duplicates(df, gene, score_cols):\n",
    "    \"\"\"Where there are multiple distinct entries for a gene, we first prioritize those representing canonical transcripts. \n",
    "    If there are multiple or no canonical transcripts we next prioritize MANE Select transcripts. Where these filters are \n",
    "    unable to produce a single gene entry, we prioritize the entry assigned an NCBI Gene ID. \"\"\"\n",
    "    # sort such that NCBI Gene IDs will be first\n",
    "    gene_df = df[df.gene==gene].sort_values('gene_id')\n",
    "    if len(gene_df) == 0:\n",
    "        return None\n",
    "    # if there is only one entry, take this entry\n",
    "    if len(gene_df)==1:\n",
    "        return gene_df.index.values[0]\n",
    "    # if there are multiple entries\n",
    "    else:\n",
    "        # if all entries have the same scores, take the first ID (will be NCBI Gene ID if available)\n",
    "        if len(gene_df.drop_duplicates(subset=score_cols)) == 1:\n",
    "            # results are all the same anyway. Return the entry with entrez id\n",
    "            return gene_df.index.values[0]\n",
    "        \n",
    "        # Otherwise, we need to prioritize amongst the results\n",
    "        else:\n",
    "            # is there at least one canonical transcript\n",
    "            if len(gene_df[(gene_df.canonical)]) >= 1:\n",
    "                gene_df = gene_df[gene_df.canonical]\n",
    "                \n",
    "            # is there at least one mane select transcript\n",
    "            if len(gene_df[(gene_df.mane_select)]) >= 1:\n",
    "                gene_df = gene_df[gene_df.mane_select]\n",
    "                \n",
    "            # at this point all entries should have the same values for canonical and mane_select\n",
    "            # check if these prioritizations have left us with just one entry\n",
    "            if len(gene_df) == 1:\n",
    "                return gene_df.index.values[0]\n",
    "            \n",
    "            # check if there are any duplicates\n",
    "            dups = gene_df.duplicated(subset=score_cols, keep='first')\n",
    "            if sum(dups) > 0:\n",
    "                # take the duplicated values as the correct ones.\n",
    "                return gene_df[~dups].index.values[0]\n",
    "            \n",
    "            # any dfs making it here have different scores, but same transcript designations\n",
    "            return gene_df.index.values[0]\n",
    "\n",
    "                \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOEUF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T18:23:48.210190Z",
     "start_time": "2025-06-30T18:23:47.493037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18203\n"
     ]
    }
   ],
   "source": [
    "pli_df = pd.read_csv(os.path.join(datadir, 'Reference_Data', 'gnomad.v4.1.constraint_metrics.tsv.gz'), sep='\\t',\n",
    "                    usecols=['gene', 'gene_id', 'canonical','mane_select', 'lof.z_score', 'lof.pLI', 'lof_hc_lc.pLI','lof.oe_ci.upper' ])\n",
    "# exclude non-canonical transcripts\n",
    "print(pli_df.gene.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T18:28:32.997368Z",
     "start_time": "2025-06-30T18:23:59.323827Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18204/18204 [04:04<00:00, 74.42it/s]\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "for gene in tqdm(pli_df.gene.unique()):\n",
    "    out.append(prioritize_gene_duplicates(pli_df, gene, score_cols=['lof.pLI', 'lof.z_score', 'lof_hc_lc.pLI', 'lof.oe_ci.upper']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:41:45.620501Z",
     "start_time": "2025-06-30T20:41:45.614792Z"
    }
   },
   "outputs": [],
   "source": [
    "gene_pli = pli_df.iloc[out[:-1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map identifiers to NCBI Gene IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:41:48.876699Z",
     "start_time": "2025-06-30T20:41:48.872036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ensembl IDs: 749\n"
     ]
    }
   ],
   "source": [
    "print('# Ensembl IDs:', len(gene_pli[~gene_pli.gene_id.str.isnumeric()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:41:53.968719Z",
     "start_time": "2025-06-30T20:41:53.920535Z"
    }
   },
   "outputs": [],
   "source": [
    "gene_map = pli_df.loc[pli_df.gene_id.str.isnumeric(), ('gene', 'gene_id')].merge(gene_pli[~gene_pli.gene_id.str.isnumeric()], on='gene', suffixes=('', 'x'), how='right').drop_duplicates(subset=['gene'])\n",
    "gene_pli = pd.concat([gene_pli[gene_pli.gene_id.str.isnumeric()], gene_map])#.drop(columns=['gene_idx', 'canonical', 'mane_select'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:41:56.101785Z",
     "start_time": "2025-06-30T20:41:56.098015Z"
    }
   },
   "outputs": [],
   "source": [
    "missing_pli = gene_pli[gene_pli.gene_id.isna()]\n",
    "missing_sym = gene_pli[gene_pli.gene_id.isna()]['gene'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:42:06.234635Z",
     "start_time": "2025-06-30T20:41:56.846395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Ids 110\n",
      "Checking approved symbols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:biothings.client:Input sequence provided is already in string format. No operation performed\n",
      "WARNING:biothings.client:Input sequence provided is already in string format. No operation performed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received\n",
      "Check names 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Ids 8\n",
      "Checking previous symbols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:biothings.client:Input sequence provided is already in string format. No operation performed\n",
      "WARNING:biothings.client:Input sequence provided is already in string format. No operation performed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67691/2069913422.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_pli['gene_id'] = missing_pli.gene.apply(lambda x: converted_ids[updated_symb[x]])\n"
     ]
    }
   ],
   "source": [
    "updated_symb, missing = update_nodes(missing_sym, 'Symbol')\n",
    "print('Missing:', len(missing))\n",
    "converted_ids, missing= convert_node_ids(list(updated_symb.values()), 'Symbol', 'Entrez') \n",
    "print('Missing:', len(missing))\n",
    "missing_pli['gene_id'] = missing_pli.gene.apply(lambda x: converted_ids[updated_symb[x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:42:12.313991Z",
     "start_time": "2025-06-30T20:42:12.304105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18237 18200\n"
     ]
    }
   ],
   "source": [
    "gene_pli = pd.concat([gene_pli, missing_pli ])\n",
    "gene_pli = gene_pli.drop_duplicates(subset=['gene_id', 'lof.oe_ci.upper'])\n",
    "print(len(gene_pli), gene_pli.gene_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:42:24.184503Z",
     "start_time": "2025-06-30T20:42:23.128554Z"
    }
   },
   "outputs": [],
   "source": [
    "gene_pli = gene_pli.drop(columns=['gene_idx', 'canonical', 'mane_select'])\n",
    "gene_pli.columns = ['Symbol', 'Entrez', 'lof_hc_lc.pLI', 'lof.pLI', 'lof.z_score', 'LOEUF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:42:33.005741Z",
     "start_time": "2025-06-30T20:42:32.903751Z"
    }
   },
   "outputs": [],
   "source": [
    "gene_pli.loc[:, ('Entrez', 'LOEUF')].to_csv(os.path.join(datadir, 'outputs', 'Gene_pLI.txt'), index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synonymous Intolerance\n",
    "\n",
    "-syn.z_score: Z-score for synonymous variants in transcript. Higher (more positive) Z scores indicate that the transcript is more intolerant of variation (more constrained)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:42:54.280100Z",
     "start_time": "2025-06-30T20:42:53.606825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18203\n"
     ]
    }
   ],
   "source": [
    "mis_df = pd.read_csv(os.path.join(datadir, 'Reference_Data', 'gnomad.v4.1.constraint_metrics.tsv.gz'), sep='\\t',\n",
    "                    usecols=['gene', 'gene_id', 'canonical','mane_select', 'mis.z_score', 'syn.z_score'])\n",
    "# exclude non-canonical transcripts\n",
    "print(mis_df.gene.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:47:19.901484Z",
     "start_time": "2025-06-30T20:42:55.349860Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18204/18204 [03:59<00:00, 76.12it/s]\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "for gene in tqdm(mis_df.gene.unique()):\n",
    "    out.append(prioritize_gene_duplicates(mis_df, gene, score_cols=['mis.z_score', 'syn.z_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:47:19.962984Z",
     "start_time": "2025-06-30T20:47:19.956366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18203"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_mis = mis_df.iloc[out[:-1], :]\n",
    "len(gene_mis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map indentifiers to NCBI Gene IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:47:23.708299Z",
     "start_time": "2025-06-30T20:47:23.703528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ensembl IDs: 740\n"
     ]
    }
   ],
   "source": [
    "# replace with NCBI IDs as needed\n",
    "print('# Ensembl IDs:', len(gene_mis[~gene_mis.gene_id.str.isnumeric()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:47:24.630010Z",
     "start_time": "2025-06-30T20:47:24.583202Z"
    }
   },
   "outputs": [],
   "source": [
    "gene_map = mis_df.loc[mis_df.gene_id.str.isnumeric(), ('gene', 'gene_id')].merge(gene_mis[~gene_mis.gene_id.str.isnumeric()], on='gene', suffixes=('', 'x'), how='right').drop_duplicates(subset=['gene'])\n",
    "gene_mis = pd.concat([gene_mis[gene_mis.gene_id.str.isnumeric()], gene_map]).drop(columns=['gene_idx', 'canonical', 'mane_select'])\n",
    "gene_mis.columns = ['Symbol', 'Entrez', 'mis.z_score', 'syn.z_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:47:26.935619Z",
     "start_time": "2025-06-30T20:47:26.873725Z"
    }
   },
   "outputs": [],
   "source": [
    "gene_mis.loc[:, ('Entrez', 'syn.z_score')].to_csv(os.path.join(datadir,'outputs', 'Gene_MisSyn.txt'), index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mRNA Expression\n",
    "\n",
    "- Average expression\n",
    "- Number of expressed tissues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:47:30.724036Z",
     "start_time": "2025-06-30T20:47:30.339109Z"
    }
   },
   "outputs": [],
   "source": [
    "rna_raw = pd.read_csv(os.path.join(datadir, 'Reference_Data', 'gtex_median_processed_1.tsv.gz'), sep='\\t')\n",
    "rna_df = rna_raw[~rna_raw.Entrez.isna()].drop(columns=['Ensembl_ID', 'Symbol']).set_index('Entrez')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:47:30.845555Z",
     "start_time": "2025-06-30T20:47:30.826191Z"
    }
   },
   "outputs": [],
   "source": [
    "rna_metrics = pd.DataFrame({'Mean_mRNA':rna_df.mean(axis=1), 'n_Expressed':(rna_df > 1).sum(axis=1)}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:47:31.212174Z",
     "start_time": "2025-06-30T20:47:31.205213Z"
    }
   },
   "outputs": [],
   "source": [
    "rna_metrics = rna_metrics.sort_values(by='Mean_mRNA', ascending=False).drop_duplicates(subset='Entrez', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:47:31.734826Z",
     "start_time": "2025-06-30T20:47:31.644365Z"
    }
   },
   "outputs": [],
   "source": [
    "rna_metrics.to_csv(os.path.join(datadir, 'outputs', 'Gene_mRNA.txt'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GO Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:47:35.003680Z",
     "start_time": "2025-06-30T20:47:32.652669Z"
    }
   },
   "outputs": [],
   "source": [
    "go_df = pd.read_csv(os.path.join(datadir, 'Reference_Data', 'gene2go.gz'), sep='\\t')\n",
    "go_df = go_df[go_df['#tax_id']==9606].drop(columns=['#tax_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:47:35.147795Z",
     "start_time": "2025-06-30T20:47:35.111114Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove negating qualifiers\n",
    "exclude_qualifiers = [x for x in go_df.Qualifier.unique() if 'NOT' in x]\n",
    "go_df = go_df[~go_df.Qualifier.isin(exclude_qualifiers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:47:35.324276Z",
     "start_time": "2025-06-30T20:47:35.255022Z"
    }
   },
   "outputs": [],
   "source": [
    "go_counts = go_df.groupby(['GeneID', 'Category']).GO_ID.nunique().reset_index()\n",
    "go_counts = go_counts.pivot_table(index='GeneID', columns=['Category'], values='GO_ID', fill_value=0).reset_index()\n",
    "go_counts.columns = ['Entrez', 'n_GO_CC', 'n_GO_MF', 'n_GO_BP']\n",
    "go_counts['n_GO']=go_counts['n_GO_CC'] + go_counts['n_GO_MF'] + go_counts['n_GO_BP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:47:36.444703Z",
     "start_time": "2025-06-30T20:47:36.395734Z"
    }
   },
   "outputs": [],
   "source": [
    "go_counts.to_csv(os.path.join(datadir, 'outputs', 'Gene_GO.txt'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:47:38.435263Z",
     "start_time": "2025-06-30T20:47:37.861309Z"
    }
   },
   "outputs": [],
   "source": [
    "length_df = pd.read_csv(os.path.join(datadir, 'Reference_Data','Ensembl_Feb14_2025.txt.gz'), sep='\\t', low_memory=False,\n",
    "                       usecols=['Gene stable ID', 'Gene start (bp)', 'Gene end (bp)', 'Chromosome/scaffold name',\n",
    "                               'NCBI gene (formerly Entrezgene) ID', 'HGNC symbol'],\n",
    "                       )\n",
    "length_df.columns = ['Ensembl', 'Start', 'End', 'Chrom', 'Entrez', 'Symbol']\n",
    "length_df = length_df.dropna(subset=['Start', 'End', 'Entrez']).drop_duplicates()\n",
    "length_df = length_df[length_df.Chrom.isin([str(x) for x in range(1, 23)] + ['X', 'Y'])]\n",
    "length_df = length_df[~length_df.Symbol.isna()]\n",
    "length_df['GeneSize'] = length_df['End'] - length_df['Start']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map indentifiers to NCBI Gene IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:48:58.499257Z",
     "start_time": "2025-06-30T20:47:39.516310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Ids 25034\n",
      "Checking approved symbols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:biothings.client:Input sequence provided is already in string format. No operation performed\n",
      "WARNING:biothings.client:Input sequence provided is already in string format. No operation performed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received\n",
      "Check names 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Ids 53\n",
      "Checking previous symbols\n",
      "Alias Ids 2\n",
      "Searching aliases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:biothings.client:Input sequence provided is already in string format. No operation performed\n",
      "WARNING:biothings.client:Input sequence provided is already in string format. No operation performed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching Entrez\n",
      "Missing: 0\n"
     ]
    }
   ],
   "source": [
    "updated_symbols, missing = update_nodes(length_df.Symbol.unique(), 'Symbol')\n",
    "print('Missing:', len(missing))\n",
    "converted_ids, missing= convert_node_ids(list(updated_symbols.values()), 'Symbol', 'Entrez') \n",
    "print('Missing:', len(missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:48:58.656213Z",
     "start_time": "2025-06-30T20:48:58.631329Z"
    }
   },
   "outputs": [],
   "source": [
    "gene_map = {x: converted_ids[y] for x,y in updated_symbols.items()}\n",
    "length_df = length_df.assign(Entrez = length_df.Symbol.map(gene_map))\n",
    "# remove duplicated gene lengths\n",
    "length_df = length_df.drop_duplicates(subset=['Entrez', 'GeneSize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:49:05.784819Z",
     "start_time": "2025-06-30T20:49:05.773619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genes with conflicting entries: 21\n",
      "Final size: 25003\n"
     ]
    }
   ],
   "source": [
    "print('Genes with conflicting entries:',  length_df[length_df.Entrez.duplicated(keep=False)].Entrez.nunique())\n",
    "# Remove genes with conflicting entries\n",
    "length_df = length_df[~length_df.Entrez.isin(length_df[length_df.Entrez.duplicated(keep=False)].Entrez.values)]\n",
    "print('Final size:', len(length_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:49:08.931783Z",
     "start_time": "2025-06-30T20:49:08.872297Z"
    }
   },
   "outputs": [],
   "source": [
    "length_df.sort_values('Entrez').loc[:, ('Entrez','Chrom', 'Start', 'End', 'GeneSize')].to_csv(os.path.join(datadir, 'outputs', 'Gene_length.txt'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collate Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:49:11.376318Z",
     "start_time": "2025-06-30T20:49:11.373715Z"
    }
   },
   "outputs": [],
   "source": [
    "files = { 'MisSyn': 'Gene_MisSyn.txt',  'pli': 'Gene_pLI.txt',\n",
    "    'Length': 'Gene_length.txt',\n",
    "    'GO': 'Gene_GO.txt' ,\n",
    "    'mrna':'Gene_mRNA.txt', 'n_mrna':'Gene_mRNA.txt'\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:49:12.193525Z",
     "start_time": "2025-06-30T20:49:12.191081Z"
    }
   },
   "outputs": [],
   "source": [
    "missing_val = {\n",
    " 'GO': 0,\n",
    "}\n",
    "\n",
    "usecols = {\n",
    " 'MisSyn': 'syn.z_score',\n",
    " 'pli': 'LOEUF',\n",
    " 'Length': 'GeneSize',\n",
    " 'GO': 'n_GO',\n",
    " 'mrna': 'Mean_mRNA', \n",
    " 'n_mrna': 'n_Expressed'}\n",
    "\n",
    "labels = {\n",
    " 'MisSyn': 'Synonymous intolerance',\n",
    " 'pli': 'Med. LOEUF',\n",
    " 'Length': 'Med. Gene Size',\n",
    " 'GO': 'Med. GO Terms',\n",
    " 'mrna': 'mRNA Exp.', \n",
    " 'n_mrna': 'Med. Exp. Tissues'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:49:26.445074Z",
     "start_time": "2025-06-30T20:49:26.406802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MisSyn (18075, 1)\n",
      "pli (17954, 1)\n",
      "Length (25003, 1)\n",
      "GO (20739, 1)\n",
      "mrna (34812, 1)\n",
      "n_mrna (34812, 1)\n"
     ]
    }
   ],
   "source": [
    "annot_dfs = {}\n",
    "for met, file in files.items():\n",
    "    annot_dfs[met] = pd.read_csv(os.path.join(datadir, 'outputs', file), sep='\\t', index_col=0, usecols=['Entrez']+[usecols[met]]).dropna()\n",
    "    annot_dfs[met] = annot_dfs[met][~annot_dfs[met].index.isna()]\n",
    "    annot_dfs[met].index = annot_dfs[met].index.astype(int)\n",
    "    print(met, annot_dfs[met].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:49:28.794979Z",
     "start_time": "2025-06-30T20:49:28.771514Z"
    }
   },
   "outputs": [],
   "source": [
    "bio_df = annot_dfs['MisSyn']\n",
    "for met, df in annot_dfs.items():\n",
    "    if met != 'MisSyn':\n",
    "        bio_df = bio_df.join(annot_dfs[met], how='outer')\n",
    "bio_df = bio_df.dropna(thresh=2)\n",
    "#bio_df = bio_df.fillna({usecols[k]:missing_val[k] for k in missing_val})\n",
    "bio_df = bio_df.rename(columns={usecols[k]:k for k in usecols})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T17:21:53.969911Z",
     "start_time": "2025-06-18T17:21:53.827916Z"
    }
   },
   "outputs": [],
   "source": [
    "bio_df.to_csv(os.path.join(datadir, 'outputs', 'Features_bio_gene_test.txt'), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene Set Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T21:08:59.998057Z",
     "start_time": "2025-06-30T21:08:59.994289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536 947\n"
     ]
    }
   ],
   "source": [
    "r_traitlist = set([x.split('_GCST')[0] for x in all_pairs])\n",
    "c_traitlist = set(['GCST'+x.split('_GCST')[-1] for x in all_pairs])\n",
    "print(len(r_traitlist), len(c_traitlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elkon2/shacharbavly/networks/CARVA/Notebooks/..\n"
     ]
    }
   ],
   "source": [
    "print(datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T21:09:37.411559Z",
     "start_time": "2025-06-30T21:09:37.409266Z"
    }
   },
   "outputs": [],
   "source": [
    "nrnb_dir = os.path.join(datadir, '../../Data/RareCommon/inputs/March_2025')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shachar note: \n",
    "code in cell above refrences a file not in their git, probably local files. they seem by the error code to use files created\n",
    "in the outputs dir of notebook 1b, from the form '34375979_EFO_0009959_RV.txt' so i assume they cleared the outputs out to\n",
    "prevent override, but that its the same files generated earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elkon2/shacharbavly/networks/CARVA/Notebooks/.././outputs\n"
     ]
    }
   ],
   "source": [
    "nrnb_dir = os.path.join(datadir, './outputs')\n",
    "print(nrnb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shachar note: added skipping missed files. i dont know where they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T21:10:11.439421Z",
     "start_time": "2025-06-30T21:10:09.610024Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████████████████████████▍                                                                                | 201/536 [00:02<00:03, 104.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: 36303018_EFO_0004574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|████████████████████████████████████████████████████████████████████████████████████████████████▎                                 | 397/536 [00:04<00:01, 79.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: 37262146_EFO_0006335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 446/536 [00:05<00:00, 94.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: 37262146_EFO_0006336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋           | 489/536 [00:05<00:00, 100.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: 37262146_EFO_0009270\n",
      "missed: 36809768_EFO_0004541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 536/536 [00:05<00:00, 91.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rare_annot = {}\n",
    "count=0\n",
    "missing_count = 0\n",
    "for gs in tqdm(list(r_traitlist)):\n",
    "    count+=1\n",
    "    try:\n",
    "        genes = pd.read_csv(os.path.join(nrnb_dir, f'{gs}_RV.txt'), sep='\\t').Entrez.values\n",
    "    except FileNotFoundError:\n",
    "        print(\"missed:\", gs)\n",
    "        missing_count+=1\n",
    "        continue\n",
    "        \n",
    "    genes = [x for x in genes if x in bio_df.index.values]\n",
    "    gene_df = bio_df.loc[genes, :]\n",
    "    gene_df = gene_df.fillna(missing_val)\n",
    "    #gene_df = gene_df.dropna(axis=1, thresh=)\n",
    "    rare_annot[gs] = gene_df.median(axis=0).to_dict()\n",
    "print (count, missing_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T21:09:50.785088Z",
     "start_time": "2025-06-30T21:09:46.308605Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████▉                                                                                                                             | 36/947 [00:00<00:05, 174.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: GCST90018968_EFO_0004833\n",
      "missed: GCST004278_EFO_0005763\n",
      "missed: GCST010866_EFO_0001645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████████▍                                                                                                                        | 69/947 [00:00<00:06, 134.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: GCST000424_MONDO_0005301\n",
      "missed: GCST002086_EFO_0004458\n",
      "missed: GCST006867_MONDO_0005148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████████▊                                                                                                                  | 109/947 [00:00<00:07, 108.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: GCST90239620_OBA_2045260\n",
      "missed: GCST90132905_EFO_0005763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████████████▏                                                                                                            | 148/947 [00:01<00:06, 122.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: GCST005829_EFO_0006941\n",
      "missed: GCST004139_MONDO_0004985\n",
      "missed: GCST011488_EFO_0001645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████████████▋                                                                                                         | 174/947 [00:01<00:06, 114.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: GCST003925_EFO_0004274\n",
      "missed: GCST008150_EFO_0004530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████████████████▏                                                                                                     | 200/947 [00:01<00:06, 121.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: GCST000224_EFO_0000095\n",
      "missed: GCST90018969_EFO_0004309\n",
      "missed: GCST004776_EFO_0006335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████████████████████▊                                                                                              | 256/947 [00:01<00:04, 165.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: GCST002081_MONDO_0005277\n",
      "missed: GCST90101748_EFO_0004530\n",
      "missed: GCST011049_MONDO_0008315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████████████████████▎                                                                                      | 311/947 [00:02<00:02, 213.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: GCST90278638_EFO_0004611\n",
      "missed: GCST004483_EFO_0001378\n",
      "missed: GCST004210_EFO_0007800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████████████████████████▎                                                                                | 355/947 [00:02<00:02, 201.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: GCST90134634_EFO_0006335\n",
      "missed: GCST004629_EFO_0004833\n",
      "missed: GCST001228_EFO_0006336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████████████████████████████▏                                                                       | 420/947 [00:02<00:02, 198.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: GCST005831_MONDO_0007915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████████████████████████▉                                                                | 477/947 [00:02<00:02, 227.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: GCST004603_EFO_0004309\n",
      "missed: GCST90269957_MONDO_0008315\n",
      "missed: GCST90011808_MONDO_0008315\n",
      "missed: GCST003819_EFO_0001065\n",
      "missed: GCST90092809_EFO_0004615\n",
      "missed: GCST90239723_HP_0000023\n",
      "missed: GCST90301366_EFO_0006335\n",
      "missed: GCST000386_EFO_0004570\n",
      "missed: GCST90258652_EFO_0004509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████████████████████████████████████████████████████                                                        | 536/947 [00:03<00:01, 237.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: GCST012378_EFO_0006336\n",
      "missed: GCST008103_MONDO_0004985\n",
      "missed: GCST90013679_MONDO_0004979\n",
      "missed: GCST010681_MONDO_0005147\n",
      "missed: GCST007692_EFO_0000341\n",
      "missed: GCST90018957_EFO_0004509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████████████████████████████████████████▋                                                 | 585/947 [00:03<00:01, 188.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: GCST007838_EFO_0009767\n",
      "missed: GCST012201_EFO_0000571\n",
      "missed: GCST004902_MONDO_0005180\n",
      "missed: GCST90018742_EFO_0004587\n",
      "missed: GCST90012111_EFO_0004696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████████████████████████████████████████████▊                                        | 652/947 [00:03<00:01, 188.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: GCST90018747_EFO_0005091\n",
      "missed: GCST90011866_MONDO_0007915\n",
      "missed: GCST003566_MONDO_0005301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                  | 691/947 [00:04<00:01, 169.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: GCST90455518_MONDO_0008903\n",
      "missed: GCST005306_EFO_0000275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████████████████████████████████████████████████████████████████████████████████████████████████                              | 727/947 [00:04<00:01, 167.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: GCST012398_EFO_0004838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 760/947 [00:04<00:01, 149.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: GCST004132_EFO_0000384\n",
      "missed: GCST90025987_EFO_0004842\n",
      "missed: GCST003880_MONDO_0005090\n",
      "missed: GCST002233_EFO_0004502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                    | 795/947 [00:04<00:00, 155.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: GCST003960_EFO_0000729\n",
      "missed: GCST90012210_EFO_0004509\n",
      "missed: GCST004346_EFO_0000676\n",
      "missed: GCST90018587_EFO_0000341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌        | 885/947 [00:05<00:00, 207.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: GCST009021_MONDO_0004975\n",
      "missed: GCST006614_EFO_0004574\n",
      "missed: GCST006041_MONDO_0002009\n",
      "missed: GCST002874_EFO_0000676\n",
      "missed: GCST90018749_EFO_0004309\n",
      "missed: GCST90278643_EFO_0004570\n",
      "missed: GCST90090980_MONDO_0007254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 947/947 [00:05<00:00, 172.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed: GCST003017_MONDO_0005575\n",
      "missed: GCST000504_EFO_0004527\n",
      "missed: GCST001267_EFO_0000756\n",
      "947 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "common_annot = {}\n",
    "count=0\n",
    "missing_count = 0\n",
    "for gs in tqdm(list(c_traitlist)):\n",
    "    count+=1\n",
    "    try:\n",
    "        genes = pd.read_csv(os.path.join(nrnb_dir, f'{gs}_CV.txt'), sep='\\t').Entrez.values\n",
    "    except FileNotFoundError:\n",
    "        print(\"missed:\", gs)\n",
    "        missing_count+=1\n",
    "        continue\n",
    "    genes = [x for x in genes if x in bio_df.index.values]\n",
    "    gene_df = bio_df.loc[genes, :]\n",
    "    gene_df = gene_df.fillna(missing_val)\n",
    "    #gene_df = gene_df.dropna(axis=1, thresh=3)\n",
    "    common_annot[gs] = gene_df.median(axis=0).to_dict()\n",
    "print (count, missing_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T21:10:13.544772Z",
     "start_time": "2025-06-30T21:10:13.521974Z"
    }
   },
   "outputs": [],
   "source": [
    "rare_df = pd.DataFrame(rare_annot).T\n",
    "rare_df['Set'] = 'Rare'\n",
    "common_df = pd.DataFrame(common_annot).T\n",
    "common_df['Set'] = 'Common'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T21:10:16.325138Z",
     "start_time": "2025-06-30T21:10:16.322656Z"
    }
   },
   "outputs": [],
   "source": [
    "rc_df= pd.concat([rare_df, common_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T17:22:07.745901Z",
     "start_time": "2025-06-18T17:22:07.732953Z"
    }
   },
   "outputs": [],
   "source": [
    "rc_df.to_csv(os.path.join(datadir, 'outputs', 'Features_bio_genesets_test.txt'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:13:07.496431Z",
     "start_time": "2025-06-30T22:13:07.493867Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_r_traits = list(set([x.split('_GCST')[0] for x in pairs]))\n",
    "initial_c_traits = list(set(['GCST'+x.split('_GCST')[-1] for x in pairs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:13:09.080554Z",
     "start_time": "2025-06-30T22:13:09.077534Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['37262146_EFO_0006335', '37262146_EFO_0006336', '37262146_EFO_0009270'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m rc_initial = \u001b[43mrc_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43minitial_r_traits\u001b[49m\u001b[43m+\u001b[49m\u001b[43minitial_c_traits\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/elkon2/shacharbavly/micromamba/envs/networks/lib/python3.11/site-packages/pandas/core/indexing.py:1073\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1070\u001b[39m axis = \u001b[38;5;28mself\u001b[39m.axis \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m   1072\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/elkon2/shacharbavly/micromamba/envs/networks/lib/python3.11/site-packages/pandas/core/indexing.py:1301\u001b[39m, in \u001b[36m_LocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1298\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[33m\"\u001b[39m\u001b[33mndim\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key.ndim > \u001b[32m1\u001b[39m:\n\u001b[32m   1299\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot index with multidimensional key\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1301\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1303\u001b[39m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[32m   1304\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/elkon2/shacharbavly/micromamba/envs/networks/lib/python3.11/site-packages/pandas/core/indexing.py:1239\u001b[39m, in \u001b[36m_LocIndexer._getitem_iterable\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1236\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_key(key, axis)\n\u001b[32m   1238\u001b[39m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m keyarr, indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._reindex_with_indexers(\n\u001b[32m   1241\u001b[39m     {axis: [keyarr, indexer]}, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1242\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/elkon2/shacharbavly/micromamba/envs/networks/lib/python3.11/site-packages/pandas/core/indexing.py:1432\u001b[39m, in \u001b[36m_LocIndexer._get_listlike_indexer\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1429\u001b[39m ax = \u001b[38;5;28mself\u001b[39m.obj._get_axis(axis)\n\u001b[32m   1430\u001b[39m axis_name = \u001b[38;5;28mself\u001b[39m.obj._get_axis_name(axis)\n\u001b[32m-> \u001b[39m\u001b[32m1432\u001b[39m keyarr, indexer = \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1434\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/elkon2/shacharbavly/micromamba/envs/networks/lib/python3.11/site-packages/pandas/core/indexes/base.py:6070\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6067\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6068\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6070\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6072\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6074\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/elkon2/shacharbavly/micromamba/envs/networks/lib/python3.11/site-packages/pandas/core/indexes/base.py:6133\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6130\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6132\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6133\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['37262146_EFO_0006335', '37262146_EFO_0006336', '37262146_EFO_0009270'] not in index\""
     ]
    }
   ],
   "source": [
    "rc_initial = rc_df.loc[initial_r_traits+initial_c_traits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:38:46.458867Z",
     "start_time": "2025-06-30T22:38:46.447869Z"
    }
   },
   "outputs": [],
   "source": [
    "info_df = pd.read_csv(os.path.join(datadir, 'outputs/STable1.tsv'), sep='\\t')\n",
    "domain_df = info_df.loc[:, ['Mapped EFO', 'Trait Type', 'Biological Domain', 'Mapped Trait']]\n",
    "domain_df.columns = ['EFO', 'trait_type', 'Domain', 'TRAIT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:38:47.272059Z",
     "start_time": "2025-06-30T22:38:47.257492Z"
    }
   },
   "outputs": [],
   "source": [
    "info_df['StudyTrait'] = info_df.apply(lambda x: x['Study Identifier']+'_'+x['Mapped EFO'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:38:48.301809Z",
     "start_time": "2025-06-30T22:38:48.297199Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_sizes = info_df.set_index('StudyTrait')['Population Sample Size'].to_dict()\n",
    "cosines = info_df.set_index('StudyTrait')['Trait Cosine Similarity'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:34:38.624440Z",
     "start_time": "2025-06-30T22:34:38.621486Z"
    }
   },
   "outputs": [],
   "source": [
    "info_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:38:50.212607Z",
     "start_time": "2025-06-30T22:38:50.206388Z"
    }
   },
   "outputs": [],
   "source": [
    "#study_df = pd.read_csv(os.path.join(keydir, 'all_study_info.txt'), sep='\\t', index_col=0)\n",
    "#domain_info = pd.read_csv(os.path.join(keydir, 'domain_trait_type.txt'), sep='\\t', index_col=0).drop_duplicates()\n",
    "coloc_df = coloc_df.merge(domain_df, on=['EFO'], how='left')\n",
    "all_pairs = coloc_df.trait_pair.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:40:26.875739Z",
     "start_time": "2025-06-30T22:40:26.872147Z"
    }
   },
   "outputs": [],
   "source": [
    "over_df['StudyR'] = over_df['Rare Study'].astype(int).astype(str) + '_' +over_df['EFO']\n",
    "over_df['StudyC'] = over_df['Common Study']+'_'+over_df['EFO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:40:27.388332Z",
     "start_time": "2025-06-30T22:40:27.385131Z"
    }
   },
   "outputs": [],
   "source": [
    "over_df['N_R'] = over_df['StudyR'].apply(lambda x: sample_sizes[x])\n",
    "over_df['N_C'] = over_df['StudyC'].apply(lambda x: sample_sizes[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:40:28.021559Z",
     "start_time": "2025-06-30T22:40:28.011313Z"
    }
   },
   "outputs": [],
   "source": [
    "over_df['jaccard'] = over_df.apply(lambda x: (x.nShared/(x.nCommon+x.nRare-x.nShared)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:40:31.096122Z",
     "start_time": "2025-06-30T22:40:31.090451Z"
    }
   },
   "outputs": [],
   "source": [
    "over_df = over_df.merge(domain_df, on='EFO', how='left')\n",
    "over_df['binary'] = over_df.trait_type.apply(lambda x: 1 if x=='Categorical' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:41:19.798865Z",
     "start_time": "2025-06-30T22:41:19.772228Z"
    }
   },
   "outputs": [],
   "source": [
    "over_df['jaccard_zero'] =over_df.jaccard.apply(lambda x: 1 if x ==0  else 0)\n",
    "over_df['Gene_ratioRC']= over_df.apply(lambda x: x.nRare/x.nCommon, axis=1)\n",
    "over_df['overlap_logp'] = over_df.pShared.apply(lambda x: -1 * np.log10(x + 1e-250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:41:42.006560Z",
     "start_time": "2025-06-30T22:41:42.002710Z"
    }
   },
   "outputs": [],
   "source": [
    "over_df.trait_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:43:31.059536Z",
     "start_time": "2025-06-30T22:43:31.053643Z"
    }
   },
   "outputs": [],
   "source": [
    "input_initial= over_df.reset_index().loc[over_df.reset_index().trait_pair.isin(pairs), ['N_R', 'N_C', 'nCommon', 'nRare', 'trait_pair']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:43:32.758560Z",
     "start_time": "2025-06-30T22:43:32.751437Z"
    }
   },
   "outputs": [],
   "source": [
    "input_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:43:37.207736Z",
     "start_time": "2025-06-30T22:43:37.200527Z"
    }
   },
   "outputs": [],
   "source": [
    "input_initial = input_initial.assign(TraitR = input_initial.trait_pair.apply(lambda x: x.split('_GCST')[0]))\n",
    "input_initial = input_initial.assign(TraitC = input_initial.trait_pair.apply(lambda x: 'GCST' + x.split('_GCST')[-1]))\n",
    "input_initial = input_initial.melt(id_vars=['trait_pair', 'TraitR', 'TraitC'])\n",
    "input_initial = input_initial.assign(Set = input_initial.variable.apply(lambda x: 'Rare' if (x=='N_R') or (x=='nRare') else 'Common'),\n",
    "                                    metric = input_initial.variable.apply(lambda x: 'N' if 'N' in x else 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:44:03.040330Z",
     "start_time": "2025-06-30T22:44:03.023948Z"
    }
   },
   "outputs": [],
   "source": [
    "input_initial = input_initial.pivot(index=['trait_pair', 'Set', 'TraitR', 'TraitC'], columns='metric', values='value').reset_index()\n",
    "input_initial = input_initial.assign(trait = input_initial.apply(lambda x:  x.TraitR if x.Set=='Rare' else x.TraitC, axis=1)).drop(columns=['TraitR', 'TraitC'])\n",
    "input_initial = input_initial.set_index('trait')\n",
    "input_initial.index.name=''\n",
    "input_initial.columns.name=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:44:10.066869Z",
     "start_time": "2025-06-30T22:44:10.059948Z"
    }
   },
   "outputs": [],
   "source": [
    "input_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T17:22:08.542726Z",
     "start_time": "2025-06-18T17:22:08.488700Z"
    }
   },
   "outputs": [],
   "source": [
    "input_df.to_csv(os.path.join(datadir, 'outputs', 'Features_input_test.txt'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:44:30.223603Z",
     "start_time": "2025-06-30T22:44:30.220241Z"
    }
   },
   "outputs": [],
   "source": [
    "all_rc_initial = input_initial.join(rc_initial.drop(columns=['Set']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:44:32.791738Z",
     "start_time": "2025-06-30T22:44:32.788306Z"
    }
   },
   "outputs": [],
   "source": [
    "def do_paired_test(rc_df, metric=np.median):\n",
    "    print('Diff < 0 = rare is higher')\n",
    "    overall_res = {}\n",
    "    \n",
    "    for met in rc_df.columns:\n",
    "        if met not in ['Set', 'trait_pair']:\n",
    "            test_df = rc_df.loc[:, ('Set', 'trait_pair', met)].pivot(index='trait_pair', columns='Set', values=met).dropna().reset_index()\n",
    "            median_diff = np.median(test_df.Rare.values - test_df.Common.values)\n",
    "            res = wilcoxon(test_df.Rare.values - test_df.Common.values)\n",
    "            overall_res[met] = {'Diff':median_diff, 'p':res.pvalue}\n",
    "    overall_res = pd.DataFrame(overall_res).T\n",
    "    overall_res['q'] = fdrcorrection(overall_res.p)[1]\n",
    "    overall_res['sig'] = overall_res.q < 0.05\n",
    "    return overall_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:44:35.239194Z",
     "start_time": "2025-06-30T22:44:35.212898Z"
    }
   },
   "outputs": [],
   "source": [
    "paired_res = do_paired_test(all_rc_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:44:36.762895Z",
     "start_time": "2025-06-30T22:44:36.758329Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Median Population Sample Sizes')\n",
    "all_rc_initial.groupby('Set').N.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:44:38.416230Z",
     "start_time": "2025-06-30T22:44:38.410218Z"
    }
   },
   "outputs": [],
   "source": [
    "paired_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:44:54.249544Z",
     "start_time": "2025-06-30T22:44:53.536979Z"
    }
   },
   "outputs": [],
   "source": [
    "# need a list of protein coding genes IDed by Entrez.\n",
    "coding_genes = pd.read_csv(os.path.join(datadir, 'Reference_Data/Ensembl_Feb14_2025.txt.gz'), sep='\\t', usecols=['Gene type', 'NCBI gene (formerly Entrezgene) ID'])\n",
    "coding_genes = coding_genes[coding_genes['Gene type']=='protein_coding'].dropna().drop_duplicates()\n",
    "coding_genes.columns=['Gene type', 'Entrez']\n",
    "coding_genes.Entrez = coding_genes.Entrez.astype(int)\n",
    "coding_df = bio_df.loc[[x for x in coding_genes.Entrez.values if x in bio_df.index.values]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:44:56.833494Z",
     "start_time": "2025-06-30T22:44:56.828164Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_r_vs_c_violin2(rc_df, overall_res, labels):\n",
    "    n_sig = len(overall_res)\n",
    "    _ , axs = plt.subplots(nrows=1, ncols=n_sig, figsize=(n_sig, 1.25), gridspec_kw={'wspace':0.8})\n",
    "    for i, met in enumerate(overall_res.index.values):\n",
    "    #plot_median = bio_df[met].dropna().median()\n",
    "        if met in ['Length', 'CDS', 'mrna', 'Cite', 'N', 'n']:\n",
    "            sns.violinplot(rc_df, x='Set', y=met, cut=0, ax=axs[i], log_scale=True, hue_order=['Common', 'Rare'],\n",
    "                           saturation=1, zorder=2, linewidth=0.5, hue='Set', palette=[blue, green])\n",
    "\n",
    "        else:\n",
    "            sns.violinplot(rc_df, x='Set', y=met, cut=0, ax=axs[i], log_scale=False, hue_order=['Common', 'Rare'],\n",
    "                           saturation=1, zorder=2, linewidth=0.5, hue='Set', palette=[blue, green])\n",
    "\n",
    "        _ = axs[i].set_xlabel('')\n",
    "        _ = axs[i].set_ylabel(labels[met])\n",
    "        if overall_res.at[met, \"q\"] < 1e-5:\n",
    "            s= '***'\n",
    "        elif overall_res.at[met, \"q\"] < 1e-3:\n",
    "            s='**'\n",
    "        elif overall_res.at[met, \"q\"] < 0.05:\n",
    "            s='*'\n",
    "        else:\n",
    "            s='n.s.'\n",
    "        axs[i].set_title(f'{s}', fontsize=7)\n",
    "        axs[i].tick_params(axis='x', rotation=30)\n",
    "        out_ax1 = axs\n",
    "    return out_ax1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:45:05.975759Z",
     "start_time": "2025-06-30T22:45:04.300281Z"
    }
   },
   "outputs": [],
   "source": [
    "ax1= plot_r_vs_c_violin2(all_rc_initial, paired_res.loc[['N', 'n', 'Length', 'pli', 'n_mrna','GO','MisSyn', 'mrna']], \n",
    "                              labels={**labels, 'N':'Study Size', 'n': 'Geneset Size'})\n",
    "ax1[2].hlines(y=bio_df.Length.median(), xmin=-0.5, xmax=1.5, linewidth=0.5, color='red')\n",
    "ax1[2].set_ylim(2500, 1.2e6)\n",
    "ax1[1].set_ylim(3, 1000)\n",
    "ax1[3].hlines(y=coding_df.pli.dropna().median(), xmin=-0.5, xmax=1.5, linewidth=0.5, color='red')\n",
    "ax1[4].hlines(y=coding_df.n_mrna.dropna().median(), xmin=-0.5, xmax=1.5, linewidth=0.5, color='red')\n",
    "ax1[5].hlines(y=coding_df.GO.dropna().median(), xmin=-0.5, xmax=1.5, linewidth=0.5, color='red')\n",
    "ax1[6].hlines(y=coding_df.MisSyn.dropna().median(), xmin=-0.5, xmax=1.5, linewidth=0.5, color='red')\n",
    "ax1[7].hlines(y=coding_df.mrna.dropna().median(), xmin=-0.5, xmax=1.5, linewidth=0.5, color='red')\n",
    "#ax1[1].set_ylim(-0/3, 1.2e6)\n",
    "for ax in ax1:\n",
    "    ax.set_xlim(-0.5, 1.5)\n",
    "    \n",
    "_ = ax1[3].set_yticks([0,0.6,4,8])\n",
    "_ = ax1[4].set_yticks([0, 20, 40, 54])\n",
    "ax1[4].set_ylim(0, 54)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV & RV Overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:48:10.522876Z",
     "start_time": "2025-06-30T22:48:10.515465Z"
    }
   },
   "outputs": [],
   "source": [
    "top_over_df = over_df[over_df.trait_pair.isin(pairs)].drop_duplicates()\n",
    "top_over_df['q'] = fdrcorrection(top_over_df.pShared.values)[1]\n",
    "top_over_df['J'] = top_over_df['jaccard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:48:15.268450Z",
     "start_time": "2025-06-30T22:48:15.264424Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Trait with highest CV-RV similarity:')\n",
    "print(top_over_df.sort_values('J', ascending=False).iloc[0].loc[['EFO', 'nRare', 'nCommon', 'nShared', 'q']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:48:16.834409Z",
     "start_time": "2025-06-30T22:48:16.830827Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Traits with no shared genes:', len(top_over_df[top_over_df.nShared==0]))\n",
    "print('Traits with significant number of shared genes:', len(top_over_df[(top_over_df.nShared>0) & (top_over_df.q <0.05)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:49:16.768267Z",
     "start_time": "2025-06-30T22:49:16.762801Z"
    }
   },
   "outputs": [],
   "source": [
    "top_over_df['rare_only'] = top_over_df.nRare - top_over_df.nShared\n",
    "top_over_df['common_only'] = top_over_df.nCommon - top_over_df.nShared\n",
    "top_over_df['total'] = top_over_df.rare_only + top_over_df.common_only + top_over_df.nShared\n",
    "top_over_df['overlap+rare'] = top_over_df.nShared + top_over_df.rare_only\n",
    "top_over_df = top_over_df.sort_values(by=['nShared', 'total'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:49:18.881998Z",
     "start_time": "2025-06-30T22:49:18.878528Z"
    }
   },
   "outputs": [],
   "source": [
    "top_over_df['logq'] = top_over_df.q.apply(lambda x: -1 * np.log10(x+1e-50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:49:45.076993Z",
     "start_time": "2025-06-30T22:49:45.070072Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_df=top_over_df[((top_over_df.total > 100) ) & (top_over_df.total < 1000)].melt(id_vars=['trait_pair', 'q', 'logq'], value_vars=['nShared', 'overlap+rare', 'total'])\n",
    "total_order = top_over_df.sort_values(by=['nShared', 'nRare', 'nCommon'], ascending=[False, False, False]).trait_pair.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:50:18.994088Z",
     "start_time": "2025-06-30T22:50:16.397410Z"
    }
   },
   "outputs": [],
   "source": [
    "_, [[ax1a, ax2a], [ax1, ax2]] = plt.subplots(2, 2, figsize=(8, 2), sharex=False, \n",
    "                                             gridspec_kw={'height_ratios': [1, 20], 'width_ratios':[49,324], 'hspace': 0})\n",
    "\n",
    "\n",
    "\n",
    "order = [x for x in total_order if x in plot_df.trait_pair.values]\n",
    "n1=len(order)\n",
    "#plot_df[plot_df.variable=='nShared'].sort_values('value', ascending=False).trait_pair\n",
    "sns.heatmap(np.array(plot_df[plot_df.variable=='total'].set_index('trait_pair').loc[order]['logq']).reshape(-1, 1).T,\n",
    "            ax=ax1a, cbar=False, cmap='Reds', yticklabels=False, xticklabels=False,vmax=25, vmin=0)\n",
    "\n",
    "sns.barplot(plot_df[plot_df.variable=='nShared'], x='trait_pair', y='value', color='#af3800', zorder=10, order=order, \n",
    "            saturation=1, ax=ax1, alpha=1, width=1)\n",
    "sns.barplot(plot_df[plot_df.variable=='overlap+rare'], x='trait_pair', y='value', color='#5fad56', zorder=5, order=order,\n",
    "            saturation=1,  ax=ax1, alpha=1, width=1)\n",
    "sns.barplot(plot_df[plot_df.variable=='total'], x='trait_pair', y='value', color='#6ec1e0', zorder=1, order=order, \n",
    "            saturation=1, ax=ax1, alpha=1, width=1)\n",
    "ax1.set_xticks([])\n",
    "\n",
    "\n",
    "plot_df2 =top_over_df[ (top_over_df.total <= 100)].melt(id_vars=['trait_pair', 'q', \n",
    "                                                                                                      'logq'], \n",
    "                                                                  value_vars=['nShared', 'overlap+rare', 'total'])\n",
    "order = [x for x in total_order if x in plot_df2.trait_pair.values]\n",
    "#plot_df2[plot_df2.variable=='nShared'].sort_values('value', ascending=False).trait_pair\n",
    "\n",
    "n2=len(order)\n",
    "sns.heatmap(np.array(plot_df2[plot_df2.variable=='total'].set_index('trait_pair').loc[order]['logq']).reshape(-1, 1).T, \n",
    "            ax=ax2a, cbar=False, \n",
    "            cmap='Reds', yticklabels=False, xticklabels=False, vmax=25, vmin=0)\n",
    "\n",
    "sns.barplot(plot_df2[plot_df2.variable=='nShared'], x='trait_pair', y='value', color='#af3800', \n",
    "            zorder=10, order=order, ax=ax2, alpha=1, saturation=1, width=1,)\n",
    "sns.barplot(plot_df2[plot_df2.variable=='overlap+rare'], x='trait_pair', y='value', color='#5fad56', \n",
    "            zorder=5, order=order, ax=ax2, alpha=1, saturation=1, width=1,)\n",
    "sns.barplot(plot_df2[plot_df2.variable=='total'], x='trait_pair', y='value', color='#6ec1e0', \n",
    "            zorder=1, order=order, ax=ax2, alpha=1, saturation=1, width=1)\n",
    "ax2.set_xticks([])\n",
    "ax1.set_xlabel(f'\\nTraits with more than\\n 100 genes (n={n1})')\n",
    "ax2.set_xlabel(f'\\nTraits with fewer than 100 genes (n={n2})')\n",
    "_ = ax1.set_ylabel('Total associated genes')\n",
    "_ = ax2.set_ylabel('Total associated genes')\n",
    "\n",
    "for ax in [ax1a, ax2a]:\n",
    "    for _, spine in ax.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        \n",
    "#plt.savefig(os.path.join(figdir, 'overlap_summary_gcat.svg'), dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:50:22.312790Z",
     "start_time": "2025-06-30T22:50:22.309848Z"
    }
   },
   "outputs": [],
   "source": [
    "top_over_df_sig = top_over_df[(top_over_df.q<0.05) & (top_over_df.nShared>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:50:24.742857Z",
     "start_time": "2025-06-30T22:50:24.740078Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Median percent of CVGs shared:', f'{100*(top_over_df_sig[\"nShared\"]/top_over_df_sig[\"nCommon\"]).median():.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T22:50:25.638565Z",
     "start_time": "2025-06-30T22:50:25.635819Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Median percent of RVGs shared:', f'{100*(top_over_df_sig[\"nShared\"]/top_over_df_sig[\"nRare\"]).median():.1f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
