{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Curation Notebook C - Gene Set Annotation\n",
    "\n",
    "This notebook:...\n",
    "\n",
    "- Processing of annotation data\n",
    "- Biological features\n",
    "- Analysis of gene sets\n",
    "- analysis of overlap data\n",
    "\n",
    "**Inputs:**\n",
    "* Supplemental Table 2 (`'outputs/STable2.tsv'`)\n",
    "* gnomAD constraint metrics (`gnomad.v4.1.constraint_metrics.tsv.gz`)\n",
    "* Selective constraint (`'s_het_estimates.genebayes.tsv`)\n",
    "* mRNA Expression (`gtex_median_processed_1.tsv.gz`)\n",
    "* GO Annotations (`gene2go.gz`)\n",
    "* Gene length & protein coding annotations (`Ensembl_Feb14_2025.txt.gz`)\n",
    "\n",
    "\n",
    "**Figures generated:**\n",
    "- Figure 1C\n",
    "- Figure 1F\n",
    "\n",
    "**Tables generated:**\n",
    "* Supplemental Table 1. Input Information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:47:46.878602Z",
     "start_time": "2025-10-07T18:47:46.873948Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import wilcoxon, mannwhitneyu\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import sys\n",
    "from neteval.gene_mapper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:47:46.882414Z",
     "start_time": "2025-10-07T18:47:46.879852Z"
    }
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "datadir = os.path.join(cwd, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:47:46.888346Z",
     "start_time": "2025-10-07T18:47:46.883746Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "plt.rcParams.update({'font.size': 7})\n",
    "plt.rcParams['axes.linewidth'] = 0.5\n",
    "plt.rcParams['hatch.linewidth'] = 0.5\n",
    "plt.rcParams['xtick.major.width'] = 0.4\n",
    "plt.rcParams['ytick.major.width'] = 0.4\n",
    "plt.rcParams['xtick.minor.width'] = 0.3\n",
    "plt.rcParams['ytick.minor.width'] = 0.3\n",
    "plt.rcParams['legend.frameon'] = False\n",
    "plt.rcParams['xtick.major.size'] = 3\n",
    "plt.rcParams['ytick.major.size'] = 3\n",
    "plt.rcParams['xtick.minor.size'] = 2\n",
    "plt.rcParams['ytick.minor.size'] = 2\n",
    "plt.rcParams['xtick.major.pad'] = 1\n",
    "plt.rcParams['ytick.major.pad'] = 1\n",
    "plt.rcParams['axes.labelpad'] = 1\n",
    "plt.rcParams['patch.linewidth'] = 0.25\n",
    "import matplotlib.font_manager as fm\n",
    "arial_font_path = os.path.join(datadir, 'Reference_Data', 'Arial.TTF')\n",
    "fm.fontManager.addfont(arial_font_path)\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family'] = 'Arial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:47:46.892684Z",
     "start_time": "2025-10-07T18:47:46.889388Z"
    }
   },
   "outputs": [],
   "source": [
    "blue='#6ec1e0'\n",
    "green='#5fad56'\n",
    "shared='#af3800'\n",
    "binary='#00606f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:47:46.897679Z",
     "start_time": "2025-10-07T18:47:46.894124Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def map_trait_code(code):\n",
    "    efo = next((match.group() for match in re.finditer(r'EFO_\\d+', code)), None)\n",
    "    if efo is not None:\n",
    "        return efo\n",
    "    mondo = next((match.group() for match in re.finditer(r'MONDO_\\d+', code)), None)\n",
    "    if mondo is not None:\n",
    "        return mondo\n",
    "    hp = next((match.group() for match in re.finditer(r'HP_\\d+', code)), None)\n",
    "    if hp is not None:\n",
    "        return hp\n",
    "    go = next((match.group() for match in re.finditer(r'GO_\\d+', code)), None)\n",
    "    if go is not None:\n",
    "        return go\n",
    "    oba = next((match.group() for match in re.finditer(r'OBA_\\d+', code)), None)\n",
    "    if oba is not None:\n",
    "        return oba\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:47:46.907329Z",
     "start_time": "2025-10-07T18:47:46.905329Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_trait_pair(df):\n",
    "    df['trait_pair'] = df['Rare Study'].astype(int).astype(str) + '_' + df['EFO'] +'_' +df['Common Study'] +'_'+ df['EFO']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:47:46.919937Z",
     "start_time": "2025-10-07T18:47:46.908717Z"
    }
   },
   "outputs": [],
   "source": [
    "overlap_df = pd.read_csv(os.path.join(datadir, 'outputs/STable2.tsv'), sep='\\t', usecols=['EFO', 'Trait', 'Common Study',\n",
    "            'Rare Study', 'Analysis Set', 'nCommon', 'nRare', 'nShared', 'pShared'])\n",
    "overlap_df = get_trait_pair(overlap_df)\n",
    "over_df = overlap_df[overlap_df['Analysis Set']=='Initial'].copy()\n",
    "over_df['logp'] = -1 * np.log10(over_df['pShared'] + 1e-250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:47:46.933808Z",
     "start_time": "2025-10-07T18:47:46.921146Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs = over_df.trait_pair.values\n",
    "all_pairs = overlap_df.trait_pair.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutational Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:47:46.952642Z",
     "start_time": "2025-10-07T18:47:46.948421Z"
    }
   },
   "outputs": [],
   "source": [
    "def prioritize_gene_duplicates(df, gene, score_cols):\n",
    "    \"\"\"Where there are multiple distinct entries for a gene, we first prioritize those representing canonical transcripts. \n",
    "    If there are multiple or no canonical transcripts we next prioritize MANE Select transcripts. Where these filters are \n",
    "    unable to produce a single gene entry, we prioritize the entry assigned an NCBI Gene ID. \"\"\"\n",
    "    # sort such that NCBI Gene IDs will be first\n",
    "    gene_df = df[df.gene==gene].sort_values('gene_id')\n",
    "    if len(gene_df) == 0:\n",
    "        return None\n",
    "    # if there is only one entry, take this entry\n",
    "    if len(gene_df)==1:\n",
    "        return gene_df.index.values[0]\n",
    "    # if there are multiple entries\n",
    "    else:\n",
    "        # if all entries have the same scores, take the first ID (will be NCBI Gene ID if available)\n",
    "        if len(gene_df.drop_duplicates(subset=score_cols)) == 1:\n",
    "            # results are all the same anyway. Return the entry with entrez id\n",
    "            return gene_df.index.values[0]\n",
    "        \n",
    "        # Otherwise, we need to prioritize amongst the results\n",
    "        else:\n",
    "            # is there at least one canonical transcript\n",
    "            if len(gene_df[(gene_df.canonical)]) >= 1:\n",
    "                gene_df = gene_df[gene_df.canonical]\n",
    "                \n",
    "            # is there at least one mane select transcript\n",
    "            if len(gene_df[(gene_df.mane_select)]) >= 1:\n",
    "                gene_df = gene_df[gene_df.mane_select]\n",
    "                \n",
    "            # at this point all entries should have the same values for canonical and mane_select\n",
    "            # check if these prioritizations have left us with just one entry\n",
    "            if len(gene_df) == 1:\n",
    "                return gene_df.index.values[0]\n",
    "            \n",
    "            # check if there are any duplicates\n",
    "            dups = gene_df.duplicated(subset=score_cols, keep='first')\n",
    "            if sum(dups) > 0:\n",
    "                # take the duplicated values as the correct ones.\n",
    "                return gene_df[~dups].index.values[0]\n",
    "            \n",
    "            # any dfs making it here have different scores, but same transcript designations\n",
    "            return gene_df.index.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOEUF & Expected LoF\n",
    "\n",
    "lof.oe_ci.upper: LOEUF: upper bound of 90% confidence interval for o/e ratio for high confidence pLoF variants (lower values indicate more constrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:47:47.664043Z",
     "start_time": "2025-10-07T18:47:46.966698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18203\n"
     ]
    }
   ],
   "source": [
    "pli_df = pd.read_csv(os.path.join(datadir, 'Reference_Data', 'gnomad.v4.1.constraint_metrics.tsv.gz'), sep='\\t',\n",
    "                    usecols=['gene', 'gene_id', 'canonical','mane_select', 'lof.z_score', 'lof.pLI', 'lof_hc_lc.pLI','lof.oe_ci.upper',\n",
    "                            'lof.exp', 'cds_length'])\n",
    "# exclude non-canonical transcripts\n",
    "print(pli_df.gene.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:52:27.874947Z",
     "start_time": "2025-10-07T18:47:47.665387Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18204/18204 [04:40<00:00, 64.97it/s]\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "for gene in tqdm(pli_df.gene.unique()):\n",
    "    out.append(prioritize_gene_duplicates(pli_df, gene, score_cols=['lof.pLI', 'lof.z_score', 'lof_hc_lc.pLI', 'lof.oe_ci.upper']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:52:27.882754Z",
     "start_time": "2025-10-07T18:52:27.876325Z"
    }
   },
   "outputs": [],
   "source": [
    "gene_pli = pli_df.iloc[out[:-1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map identifiers to NCBI Gene IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:52:27.890948Z",
     "start_time": "2025-10-07T18:52:27.884458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ensembl IDs: 749\n"
     ]
    }
   ],
   "source": [
    "print('# Ensembl IDs:', len(gene_pli[~gene_pli.gene_id.str.isnumeric()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:52:27.937684Z",
     "start_time": "2025-10-07T18:52:27.891993Z"
    }
   },
   "outputs": [],
   "source": [
    "gene_map = pli_df.loc[pli_df.gene_id.str.isnumeric(), ('gene', 'gene_id')].merge(gene_pli[~gene_pli.gene_id.str.isnumeric()], on='gene', suffixes=('', 'x'), how='right').drop_duplicates(subset=['gene'])\n",
    "gene_pli = pd.concat([gene_pli[gene_pli.gene_id.str.isnumeric()], gene_map])#.drop(columns=['gene_idx', 'canonical', 'mane_select'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:52:27.942558Z",
     "start_time": "2025-10-07T18:52:27.938791Z"
    }
   },
   "outputs": [],
   "source": [
    "missing_pli = gene_pli[gene_pli.gene_id.isna()]\n",
    "missing_sym = gene_pli[gene_pli.gene_id.isna()]['gene'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:52:34.674689Z",
     "start_time": "2025-10-07T18:52:27.943588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Ids 110\n",
      "Checking approved symbols\n",
      "Response received\n",
      "Check names 10\n",
      "Previous Ids 8\n",
      "Checking previous symbols\n",
      "Missing: 0\n",
      "Missing: 0\n"
     ]
    }
   ],
   "source": [
    "updated_symb, missing = update_nodes(missing_sym, 'Symbol')\n",
    "print('Missing:', len(missing))\n",
    "converted_ids, missing= convert_node_ids(list(updated_symb.values()), 'Symbol', 'Entrez') \n",
    "print('Missing:', len(missing))\n",
    "missing_pli = missing_pli.assign(gene_id = missing_pli.gene.apply(lambda x: converted_ids[updated_symb[x]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:52:34.687174Z",
     "start_time": "2025-10-07T18:52:34.675581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18237 18200\n"
     ]
    }
   ],
   "source": [
    "gene_pli = pd.concat([gene_pli, missing_pli ])\n",
    "gene_pli = gene_pli.drop_duplicates(subset=['gene_id', 'lof.oe_ci.upper'])\n",
    "print(len(gene_pli), gene_pli.gene_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:52:34.691109Z",
     "start_time": "2025-10-07T18:52:34.688195Z"
    }
   },
   "outputs": [],
   "source": [
    "gene_pli = gene_pli.drop(columns=['gene_idx', 'canonical', 'mane_select'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:52:34.697183Z",
     "start_time": "2025-10-07T18:52:34.693552Z"
    }
   },
   "outputs": [],
   "source": [
    "gene_pli = gene_pli.rename(columns={'gene':'Symbol', 'gene_id':'Entrez', 'lof.oe_ci.upper':'LOEUF'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:52:34.747597Z",
     "start_time": "2025-10-07T18:52:34.698313Z"
    }
   },
   "outputs": [],
   "source": [
    "gene_pli.loc[:, ('Entrez', 'LOEUF', 'lof.exp')].to_csv(os.path.join(datadir, 'outputs', 'Gene_pLI.txt'), index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synonymous Intolerance\n",
    "\n",
    "-syn.z_score: Z-score for synonymous variants in transcript. Higher (more positive) Z scores indicate that the transcript is more intolerant of variation (more constrained)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:52:35.422845Z",
     "start_time": "2025-10-07T18:52:34.748788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18203\n"
     ]
    }
   ],
   "source": [
    "mis_df = pd.read_csv(os.path.join(datadir, 'Reference_Data', 'gnomad.v4.1.constraint_metrics.tsv.gz'), sep='\\t',\n",
    "                    usecols=['gene', 'gene_id', 'canonical','mane_select', 'mis.z_score', 'syn.z_score'])\n",
    "# exclude non-canonical transcripts\n",
    "print(mis_df.gene.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:00.973183Z",
     "start_time": "2025-10-07T18:52:35.424007Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18204/18204 [04:25<00:00, 68.56it/s]\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "for gene in tqdm(mis_df.gene.unique()):\n",
    "    out.append(prioritize_gene_duplicates(mis_df, gene, score_cols=['mis.z_score', 'syn.z_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:00.996997Z",
     "start_time": "2025-10-07T18:57:00.977108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18203"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_mis = mis_df.iloc[out[:-1], :]\n",
    "len(gene_mis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map indentifiers to NCBI Gene IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:01.005818Z",
     "start_time": "2025-10-07T18:57:00.997912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ensembl IDs: 740\n"
     ]
    }
   ],
   "source": [
    "# replace with NCBI IDs as needed\n",
    "print('# Ensembl IDs:', len(gene_mis[~gene_mis.gene_id.str.isnumeric()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:01.078063Z",
     "start_time": "2025-10-07T18:57:01.007151Z"
    }
   },
   "outputs": [],
   "source": [
    "gene_map = mis_df.loc[mis_df.gene_id.str.isnumeric(), ('gene', 'gene_id')].merge(gene_mis[~gene_mis.gene_id.str.isnumeric()], on='gene', suffixes=('', 'x'), how='right').drop_duplicates(subset=['gene'])\n",
    "gene_mis = pd.concat([gene_mis[gene_mis.gene_id.str.isnumeric()], gene_map]).drop(columns=['gene_idx', 'canonical', 'mane_select'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:01.097618Z",
     "start_time": "2025-10-07T18:57:01.091861Z"
    }
   },
   "outputs": [],
   "source": [
    "gene_mis = gene_mis.rename(columns={'gene_id': 'Entrez'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:01.146130Z",
     "start_time": "2025-10-07T18:57:01.098652Z"
    }
   },
   "outputs": [],
   "source": [
    "gene_mis.loc[:, ('Entrez', 'syn.z_score')].to_csv(os.path.join(datadir,'outputs', 'Gene_MisSyn.txt'), index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### s_het\n",
    "\n",
    "Use the mean of the posterior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:01.190855Z",
     "start_time": "2025-10-07T18:57:01.147086Z"
    }
   },
   "outputs": [],
   "source": [
    "shet_raw = pd.read_csv(os.path.join(datadir, 'Reference_Data', 's_het_estimates.genebayes.tsv'), \n",
    "                       sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.329606Z",
     "start_time": "2025-10-07T18:57:01.192166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query batch 0 - 1000\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='rest.ensembl.org', port=443): Max retries exceeded with url: /archive/id (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x15550eb15390>: Failed to resolve 'rest.ensembl.org' ([Errno -2] Name or service not known)\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/carva/lib/python3.10/site-packages/urllib3/connection.py:196\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/carva/lib/python3.10/site-packages/urllib3/util/connection.py:60\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LocationParseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     61\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m~/anaconda3/envs/carva/lib/python3.10/socket.py:955\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    954\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    956\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -2] Name or service not known",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNameResolutionError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/carva/lib/python3.10/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/carva/lib/python3.10/site-packages/urllib3/connectionpool.py:490\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    489\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[0;32m--> 490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[1;32m    492\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/carva/lib/python3.10/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/carva/lib/python3.10/site-packages/urllib3/connectionpool.py:1095\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1095\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/carva/lib/python3.10/site-packages/urllib3/connection.py:615\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    614\u001b[0m sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[0;32m--> 615\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m~/anaconda3/envs/carva/lib/python3.10/site-packages/urllib3/connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mNameResolutionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x15550eb15390>: Failed to resolve 'rest.ensembl.org' ([Errno -2] Name or service not known)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/carva/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/carva/lib/python3.10/site-packages/urllib3/connectionpool.py:873\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    870\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    872\u001b[0m     )\n\u001b[0;32m--> 873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/carva/lib/python3.10/site-packages/urllib3/connectionpool.py:873\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    870\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    872\u001b[0m     )\n\u001b[0;32m--> 873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: HTTPConnectionPool.urlopen at line 873 (12 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/carva/lib/python3.10/site-packages/urllib3/connectionpool.py:873\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    870\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    872\u001b[0m     )\n\u001b[0;32m--> 873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/carva/lib/python3.10/site-packages/urllib3/connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/anaconda3/envs/carva/lib/python3.10/site-packages/urllib3/util/retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='rest.ensembl.org', port=443): Max retries exceeded with url: /archive/id (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x15550eb15390>: Failed to resolve 'rest.ensembl.org' ([Errno -2] Name or service not known)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# convert ensg to NCBI gene ids.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m updated_ensg, missing \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshet_raw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mensg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEnsembl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(missing))\n",
      "File \u001b[0;32m~/anaconda3/envs/carva/lib/python3.10/site-packages/neteval-0.1.12-py3.10.egg/neteval/gene_mapper.py:45\u001b[0m, in \u001b[0;36mupdate_nodes\u001b[0;34m(nodes, id_type, keep, timer)\u001b[0m\n\u001b[1;32m     43\u001b[0m     failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(failed) \u001b[38;5;241m+\u001b[39m [node \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(nodes) \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(exclude_prefix_suffix), node) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m id_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnsembl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnsemblProtein\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m---> 45\u001b[0m     results, failed \u001b[38;5;241m=\u001b[39m \u001b[43mensg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_latest_ensembl_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m id_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntrez\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     47\u001b[0m     results, failed \u001b[38;5;241m=\u001b[39m get_mygene(nodes, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentrezgene\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/carva/lib/python3.10/site-packages/neteval-0.1.12-py3.10.egg/neteval/query_ensembl.py:21\u001b[0m, in \u001b[0;36mget_latest_ensembl_id\u001b[0;34m(ids)\u001b[0m\n\u001b[1;32m     19\u001b[0m session \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mSession()\n\u001b[1;32m     20\u001b[0m session\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://\u001b[39m\u001b[38;5;124m'\u001b[39m, requests\u001b[38;5;241m.\u001b[39madapters\u001b[38;5;241m.\u001b[39mHTTPAdapter(max_retries\u001b[38;5;241m=\u001b[39mretries))\n\u001b[0;32m---> 21\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m :\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m}\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#r = requests.post(server+ext, headers=headers, data='{ \"id\" :' + json.dumps(list(batch_ids)) +'}')\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m r\u001b[38;5;241m.\u001b[39mok:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m#print(r.request)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m#print(\"\\n\".join(batch_ids))\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/carva/lib/python3.10/site-packages/requests/sessions.py:637\u001b[0m, in \u001b[0;36mSession.post\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    627\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/carva/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/carva/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/carva/lib/python3.10/site-packages/requests/adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    697\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='rest.ensembl.org', port=443): Max retries exceeded with url: /archive/id (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x15550eb15390>: Failed to resolve 'rest.ensembl.org' ([Errno -2] Name or service not known)\"))"
     ]
    }
   ],
   "source": [
    "# convert ensg to NCBI gene ids.\n",
    "updated_ensg, missing = update_nodes(shet_raw.ensg.unique(), 'Ensembl')\n",
    "print('Missing:', len(missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.345378Z",
     "start_time": "2025-10-07T18:57:02.345364Z"
    }
   },
   "outputs": [],
   "source": [
    "converted_ids, missing= convert_node_ids(list(updated_ensg.values()), 'Ensembl', 'Entrez') \n",
    "print('Missing:', len(missing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exclude the missing genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.348658Z",
     "start_time": "2025-10-07T18:57:02.348647Z"
    }
   },
   "outputs": [],
   "source": [
    "gene_map = {x: converted_ids[y] for x,y in updated_ensg.items() if y in converted_ids}\n",
    "shet_df = shet_raw[shet_raw.ensg.isin(gene_map.keys())]\n",
    "shet_df = shet_df.assign(Entrez = shet_raw.ensg.map(gene_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.351825Z",
     "start_time": "2025-10-07T18:57:02.351814Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "sum(shet_df.Entrez.value_counts() > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.355006Z",
     "start_time": "2025-10-07T18:57:02.354995Z"
    }
   },
   "outputs": [],
   "source": [
    "shet_df['log_post_mean'] = shet_df.post_mean.apply(lambda x: -1 * np.log10(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.358194Z",
     "start_time": "2025-10-07T18:57:02.358182Z"
    }
   },
   "outputs": [],
   "source": [
    "# extract the mean of the posterior distribution (post_mean) and save\n",
    "shet_df.loc[:, ['Entrez', 'post_mean', 'log_post_mean']].to_csv(os.path.join(datadir, 'outputs', 'Gene_sHet.txt'), sep='\\t', \n",
    "                                              index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mRNA Expression\n",
    "\n",
    "- Average expression\n",
    "- Number of expressed tissues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.361379Z",
     "start_time": "2025-10-07T18:57:02.361368Z"
    }
   },
   "outputs": [],
   "source": [
    "rna_raw = pd.read_csv(os.path.join(datadir, 'Reference_Data', 'gtex_median_processed_1.tsv.gz'), sep='\\t')\n",
    "rna_df = rna_raw[~rna_raw.Entrez.isna()].drop(columns=['Ensembl_ID', 'Symbol']).set_index('Entrez')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.364566Z",
     "start_time": "2025-10-07T18:57:02.364555Z"
    }
   },
   "outputs": [],
   "source": [
    "rna_metrics = pd.DataFrame({'Mean_mRNA':rna_df.mean(axis=1), 'n_Expressed':(rna_df > 1).sum(axis=1)}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.366743Z",
     "start_time": "2025-10-07T18:57:02.366733Z"
    }
   },
   "outputs": [],
   "source": [
    "rna_metrics = rna_metrics.sort_values(by='Mean_mRNA', ascending=False).drop_duplicates(subset='Entrez', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.367535Z",
     "start_time": "2025-10-07T18:57:02.367525Z"
    }
   },
   "outputs": [],
   "source": [
    "rna_metrics.to_csv(os.path.join(datadir, 'outputs', 'Gene_mRNA.txt'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GO Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.368326Z",
     "start_time": "2025-10-07T18:57:02.368316Z"
    }
   },
   "outputs": [],
   "source": [
    "go_df = pd.read_csv(os.path.join(datadir, 'Reference_Data', 'gene2go.gz'), sep='\\t')\n",
    "go_df = go_df[go_df['#tax_id']==9606].drop(columns=['#tax_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.375266Z",
     "start_time": "2025-10-07T18:57:02.375256Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove negating qualifiers\n",
    "exclude_qualifiers = [x for x in go_df.Qualifier.unique() if 'NOT' in x]\n",
    "go_df = go_df[~go_df.Qualifier.isin(exclude_qualifiers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.376048Z",
     "start_time": "2025-10-07T18:57:02.376038Z"
    }
   },
   "outputs": [],
   "source": [
    "go_counts = go_df.groupby(['GeneID', 'Category']).GO_ID.nunique().reset_index()\n",
    "go_counts = go_counts.pivot_table(index='GeneID', columns=['Category'], values='GO_ID', fill_value=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.376873Z",
     "start_time": "2025-10-07T18:57:02.376863Z"
    }
   },
   "outputs": [],
   "source": [
    "go_counts.columns = ['Entrez', 'n_GO_CC', 'n_GO_MF', 'n_GO_BP']\n",
    "go_counts['n_GO']=go_counts['n_GO_CC'] + go_counts['n_GO_MF'] + go_counts['n_GO_BP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.377646Z",
     "start_time": "2025-10-07T18:57:02.377636Z"
    }
   },
   "outputs": [],
   "source": [
    "go_counts.to_csv(os.path.join(datadir, 'outputs', 'Gene_GO.txt'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.378481Z",
     "start_time": "2025-10-07T18:57:02.378471Z"
    }
   },
   "outputs": [],
   "source": [
    "length_df = pd.read_csv(os.path.join(datadir, 'Reference_Data','Ensembl_Feb14_2025.txt.gz'), sep='\\t', low_memory=False,\n",
    "                       usecols=['Gene stable ID', 'Gene start (bp)', 'Gene end (bp)', 'Chromosome/scaffold name',\n",
    "                               'NCBI gene (formerly Entrezgene) ID', 'HGNC symbol',\n",
    "                               'Transcript length (including UTRs and CDS)'],\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.379259Z",
     "start_time": "2025-10-07T18:57:02.379249Z"
    }
   },
   "outputs": [],
   "source": [
    "length_df = length_df.rename(columns = {'Gene stable ID':'Ensembl', 'Gene start (bp)':'Start',\n",
    "                                        'Gene end (bp)': 'End', 'Chromosome/scaffold name':'Chrom',\n",
    "                                        'NCBI gene (formerly Entrezgene) ID': 'Entrez', 'HGNC symbol':'Symbol',\n",
    "                                       'Transcript length (including UTRs and CDS)': 'CDS_length'})\n",
    "length_df = length_df.dropna(subset=['Start', 'End', 'Entrez']).drop_duplicates()\n",
    "length_df = length_df[length_df.Chrom.isin([str(x) for x in range(1, 23)] + ['X', 'Y'])]\n",
    "length_df = length_df[~length_df.Symbol.isna()]\n",
    "length_df['GeneSize'] = length_df['End'] - length_df['Start']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map indentifiers to NCBI Gene IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.380084Z",
     "start_time": "2025-10-07T18:57:02.380074Z"
    }
   },
   "outputs": [],
   "source": [
    "updated_symbols, missing = update_nodes(length_df.Symbol.unique(), 'Symbol')\n",
    "print('Missing:', len(missing))\n",
    "converted_ids, missing= convert_node_ids(list(updated_symbols.values()), 'Symbol', 'Entrez') \n",
    "print('Missing:', len(missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.380895Z",
     "start_time": "2025-10-07T18:57:02.380884Z"
    }
   },
   "outputs": [],
   "source": [
    "gene_map = {x: converted_ids[y] for x,y in updated_symbols.items()}\n",
    "length_df = length_df.assign(Entrez = length_df.Symbol.map(gene_map))\n",
    "# remove duplicated gene lengths\n",
    "length_df = length_df.drop_duplicates(subset=['Entrez', 'GeneSize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.381661Z",
     "start_time": "2025-10-07T18:57:02.381651Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Genes with conflicting entries:',  length_df[length_df.Entrez.duplicated(keep=False)].Entrez.nunique())\n",
    "# Remove genes with conflicting entries\n",
    "length_df = length_df[~length_df.Entrez.isin(length_df[length_df.Entrez.duplicated(keep=False)].Entrez.values)]\n",
    "print('Final size:', len(length_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.382435Z",
     "start_time": "2025-10-07T18:57:02.382423Z"
    }
   },
   "outputs": [],
   "source": [
    "length_df.sort_values('Entrez').loc[:, ('Entrez','Chrom', 'Start', 'End', 'GeneSize', 'CDS_length')].to_csv(os.path.join(datadir, 'outputs', 'Gene_length.txt'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collate Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.383251Z",
     "start_time": "2025-10-07T18:57:02.383241Z"
    }
   },
   "outputs": [],
   "source": [
    "files = { 'MisSyn': 'Gene_MisSyn.txt',  'pli': 'Gene_pLI.txt',\n",
    "    'Length': 'Gene_length.txt',\n",
    "    'GO': 'Gene_GO.txt' , 'sHet': 'Gene_sHet.txt',\n",
    "    'mrna':'Gene_mRNA.txt', 'n_mrna':'Gene_mRNA.txt',\n",
    "         'CDS': 'Gene_PhyloP.txt',\n",
    "         'lof': 'Gene_pLI.txt',\n",
    "         'phy': 'Gene_PhyloP.txt'\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.384069Z",
     "start_time": "2025-10-07T18:57:02.384059Z"
    }
   },
   "outputs": [],
   "source": [
    "missing_val = {\n",
    " 'GO': 0,\n",
    "}\n",
    "\n",
    "usecols = {\n",
    " 'MisSyn': 'syn.z_score',\n",
    " 'pli': 'LOEUF',\n",
    " 'Length': 'GeneSize',\n",
    " 'GO': 'n_GO',\n",
    " 'mrna': 'Mean_mRNA', \n",
    " 'n_mrna': 'n_Expressed',\n",
    "'sHet':'post_mean',\n",
    "'CDS':'CDS_Length',\n",
    "'lof':'lof.exp',\n",
    "'phy':'PhyloP_median'}\n",
    "\n",
    "labels = {\n",
    " 'MisSyn': 'Synonymous intolerance',\n",
    " 'pli': 'Med. LOEUF',\n",
    " 'Length': 'Med. Gene Size',\n",
    " 'GO': 'Med. GO Terms',\n",
    " 'mrna': 'mRNA Exp.', \n",
    " 'n_mrna': 'Med. Exp. Tissues',\n",
    "'sHet': 'Med. Selective Constraint (shet)',\n",
    "'CDS':'Med. CDS Size',\n",
    "'lof': 'Med. Expected LOF',\n",
    "'phy': 'Med. PhyloP'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.384847Z",
     "start_time": "2025-10-07T18:57:02.384838Z"
    }
   },
   "outputs": [],
   "source": [
    "annot_dfs = {}\n",
    "for met, file in files.items():\n",
    "    annot_dfs[met] = pd.read_csv(os.path.join(datadir, 'outputs', file), sep='\\t', index_col=0, usecols=['Entrez']+[usecols[met]]).dropna()\n",
    "    annot_dfs[met] = annot_dfs[met][~annot_dfs[met].index.isna()]\n",
    "    annot_dfs[met].index = annot_dfs[met].index.astype(int)\n",
    "    print(met, annot_dfs[met].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.398376Z",
     "start_time": "2025-10-07T18:57:02.398366Z"
    }
   },
   "outputs": [],
   "source": [
    "bio_df = annot_dfs['MisSyn']\n",
    "for met, df in annot_dfs.items():\n",
    "    if met != 'MisSyn':\n",
    "        bio_df = bio_df.join(annot_dfs[met], how='outer')\n",
    "bio_df = bio_df.dropna(thresh=2)\n",
    "#bio_df = bio_df.fillna({usecols[k]:missing_val[k] for k in missing_val})\n",
    "bio_df = bio_df.rename(columns={usecols[k]:k for k in usecols})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.400180Z",
     "start_time": "2025-10-07T18:57:02.400170Z"
    }
   },
   "outputs": [],
   "source": [
    "bio_df.to_csv(os.path.join(datadir, 'outputs', 'Features_bio_gene.txt'), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene Set Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.400967Z",
     "start_time": "2025-10-07T18:57:02.400958Z"
    }
   },
   "outputs": [],
   "source": [
    "r_traitlist = set([x.split('_GCST')[0] for x in all_pairs])\n",
    "c_traitlist = set(['GCST'+x.split('_GCST')[-1] for x in all_pairs])\n",
    "print(len(r_traitlist), len(c_traitlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.401739Z",
     "start_time": "2025-10-07T18:57:02.401729Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_trait_pair(df, rcol='Rare Study', ccol='Common Study', efocol='EFO'):\n",
    "    df['trait_pair'] = df[rcol].astype(int).astype(str) + '_' + df[efocol] +'_' +df[ccol] +'_'+ df[efocol]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the trait information from Supplemental Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.402519Z",
     "start_time": "2025-10-07T18:57:02.402509Z"
    }
   },
   "outputs": [],
   "source": [
    "st1 = pd.read_csv(os.path.join(datadir, 'outputs', 'STable1_inputs.txt'), sep='\\t', usecols=['Mapped Trait', 'Mapped EFO', \n",
    "        'Study Identifier', 'Variant Type',\n",
    "        'Trait Type', 'Biological Domain', 'Set', 'Reported Trait',\n",
    "        'Trait Cosine Similarity', 'Population Cohort',\n",
    "        'Population Sample Size', 'PUBMED ID', 'Gene Count', 'Gene List'])\n",
    "st1 = st1.assign(StudyTrait = st1['Study Identifier'].astype(str) + '_' + st1['Mapped EFO'])\n",
    "st1 = st1.set_index('StudyTrait')\n",
    "st1.index.name=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median annotations for each gene set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.403298Z",
     "start_time": "2025-10-07T18:57:02.403289Z"
    }
   },
   "outputs": [],
   "source": [
    "rare_annot = {}\n",
    "for gs in tqdm(list(r_traitlist)):\n",
    "    genes = [int(g) for g in st1.at[gs, 'Gene List'].split(',')]\n",
    "    genes = [x for x in genes if x in bio_df.index.values]\n",
    "    gene_df = bio_df.loc[genes, :]\n",
    "    gene_df = gene_df.fillna(missing_val)\n",
    "    #gene_df = gene_df.dropna(axis=1, thresh=)\n",
    "    rare_annot[gs] = gene_df.median(axis=0).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.404073Z",
     "start_time": "2025-10-07T18:57:02.404063Z"
    }
   },
   "outputs": [],
   "source": [
    "common_annot = {}\n",
    "for gs in tqdm(list(c_traitlist)):\n",
    "    genes = [int(g) for g in st1.at[gs, 'Gene List'].split(',')]\n",
    "    genes = [x for x in genes if x in bio_df.index.values]\n",
    "    gene_df = bio_df.loc[genes, :]\n",
    "    gene_df = gene_df.fillna(missing_val)\n",
    "    #gene_df = gene_df.dropna(axis=1, thresh=3)\n",
    "    common_annot[gs] = gene_df.median(axis=0).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.404838Z",
     "start_time": "2025-10-07T18:57:02.404828Z"
    }
   },
   "outputs": [],
   "source": [
    "rare_df = pd.DataFrame(rare_annot).T\n",
    "rare_df['Set'] = 'Rare'\n",
    "common_df = pd.DataFrame(common_annot).T\n",
    "common_df['Set'] = 'Common'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.405610Z",
     "start_time": "2025-10-07T18:57:02.405600Z"
    }
   },
   "outputs": [],
   "source": [
    "rc_df= pd.concat([rare_df, common_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.406377Z",
     "start_time": "2025-10-07T18:57:02.406367Z"
    }
   },
   "outputs": [],
   "source": [
    "rc_df.to_csv(os.path.join(datadir, 'outputs', 'Features_bio_genesets.txt'), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the annotation summary values to Supplemental Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.407141Z",
     "start_time": "2025-10-07T18:57:02.407131Z"
    }
   },
   "outputs": [],
   "source": [
    "st1 = st1.join(rc_df.drop(columns='Set'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.407904Z",
     "start_time": "2025-10-07T18:57:02.407894Z"
    }
   },
   "outputs": [],
   "source": [
    "st1 = st1.rename(columns={'MisSyn':'SynIntol', 'pli':'LOEUF', 'GO':'nGO', 'lof':'ExpLoF',\n",
    "       'phy':'PhyloP'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.408673Z",
     "start_time": "2025-10-07T18:57:02.408663Z"
    }
   },
   "outputs": [],
   "source": [
    "st1.to_csv(os.path.join(datadir, 'outputs', 'STable1.tsv'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trait level annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.409436Z",
     "start_time": "2025-10-07T18:57:02.409427Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_r_traits = list(set([x.split('_GCST')[0] for x in pairs]))\n",
    "initial_c_traits = list(set(['GCST'+x.split('_GCST')[-1] for x in pairs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.410216Z",
     "start_time": "2025-10-07T18:57:02.410206Z"
    }
   },
   "outputs": [],
   "source": [
    "rc_initial = rc_df.loc[initial_r_traits+initial_c_traits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.411012Z",
     "start_time": "2025-10-07T18:57:02.411002Z"
    }
   },
   "outputs": [],
   "source": [
    "domain_df = st1.loc[:, ['Mapped EFO', 'Trait Type', 'Biological Domain', 'Mapped Trait']]\n",
    "domain_df.columns = ['EFO', 'trait_type', 'Domain', 'TRAIT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.411791Z",
     "start_time": "2025-10-07T18:57:02.411782Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_sizes = st1['Population Sample Size'].to_dict()\n",
    "cosines = st1['Trait Cosine Similarity'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.412553Z",
     "start_time": "2025-10-07T18:57:02.412543Z"
    }
   },
   "outputs": [],
   "source": [
    "over_df['StudyR'] = over_df['Rare Study'].astype(int).astype(str) + '_' +over_df['EFO']\n",
    "over_df['StudyC'] = over_df['Common Study']+'_'+over_df['EFO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.413304Z",
     "start_time": "2025-10-07T18:57:02.413295Z"
    }
   },
   "outputs": [],
   "source": [
    "over_df['N_R'] = over_df['StudyR'].apply(lambda x: sample_sizes[x])\n",
    "over_df['N_C'] = over_df['StudyC'].apply(lambda x: sample_sizes[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gene Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.414066Z",
     "start_time": "2025-10-07T18:57:02.414056Z"
    }
   },
   "outputs": [],
   "source": [
    "over_df['jaccard'] = over_df.apply(lambda x: (x.nShared/(x.nCommon+x.nRare-x.nShared)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trait Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.414837Z",
     "start_time": "2025-10-07T18:57:02.414827Z"
    }
   },
   "outputs": [],
   "source": [
    "over_df = over_df.merge(domain_df, on='EFO', how='left')\n",
    "over_df['binary'] = over_df.trait_type.apply(lambda x: 1 if x=='Categorical' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.415611Z",
     "start_time": "2025-10-07T18:57:02.415601Z"
    }
   },
   "outputs": [],
   "source": [
    "over_df['jaccard_zero'] =over_df.jaccard.apply(lambda x: 1 if x ==0  else 0)\n",
    "over_df['Gene_ratioRC']= over_df.apply(lambda x: x.nRare/x.nCommon, axis=1)\n",
    "over_df['overlap_logp'] = over_df.pShared.apply(lambda x: -1 * np.log10(x + 1e-250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.416394Z",
     "start_time": "2025-10-07T18:57:02.416384Z"
    }
   },
   "outputs": [],
   "source": [
    "over_df.to_csv(os.path.join(datadir, 'outputs/StudyInfoExpanded.tsv'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotations for initial study pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.417189Z",
     "start_time": "2025-10-07T18:57:02.417179Z"
    }
   },
   "outputs": [],
   "source": [
    "input_initial= over_df.reset_index().loc[over_df.reset_index().trait_pair.isin(pairs), ['N_R', 'N_C', 'nCommon', 'nRare', 'trait_pair']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.417983Z",
     "start_time": "2025-10-07T18:57:02.417973Z"
    }
   },
   "outputs": [],
   "source": [
    "input_initial = input_initial.assign(TraitR = input_initial.trait_pair.apply(lambda x: x.split('_GCST')[0]))\n",
    "input_initial = input_initial.assign(TraitC = input_initial.trait_pair.apply(lambda x: 'GCST' + x.split('_GCST')[-1]))\n",
    "input_initial = input_initial.melt(id_vars=['trait_pair', 'TraitR', 'TraitC'])\n",
    "input_initial = input_initial.assign(Set = input_initial.variable.apply(lambda x: 'Rare' if (x=='N_R') or (x=='nRare') else 'Common'),\n",
    "                                    metric = input_initial.variable.apply(lambda x: 'N' if 'N' in x else 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.418782Z",
     "start_time": "2025-10-07T18:57:02.418772Z"
    }
   },
   "outputs": [],
   "source": [
    "input_initial = input_initial.pivot(index=['trait_pair', 'Set', 'TraitR', 'TraitC'], columns='metric', values='value').reset_index()\n",
    "input_initial = input_initial.assign(trait = input_initial.apply(lambda x:  x.TraitR if x.Set=='Rare' else x.TraitC, axis=1)).drop(columns=['TraitR', 'TraitC'])\n",
    "input_initial = input_initial.set_index('trait')\n",
    "input_initial.index.name=''\n",
    "input_initial.columns.name=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.419578Z",
     "start_time": "2025-10-07T18:57:02.419568Z"
    }
   },
   "outputs": [],
   "source": [
    "input_initial.to_csv(os.path.join(datadir, 'outputs', 'Features_input_test.txt'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.425750Z",
     "start_time": "2025-10-07T18:57:02.425739Z"
    }
   },
   "outputs": [],
   "source": [
    "input_initial.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.426558Z",
     "start_time": "2025-10-07T18:57:02.426548Z"
    }
   },
   "outputs": [],
   "source": [
    "all_rc_initial = input_initial.join(rc_initial.drop(columns=['Set']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.427336Z",
     "start_time": "2025-10-07T18:57:02.427326Z"
    }
   },
   "outputs": [],
   "source": [
    "def do_paired_test(rc_df, metric=np.median):\n",
    "    print('Diff < 0 = rare is higher')\n",
    "    overall_res = {}\n",
    "    \n",
    "    for met in rc_df.columns:\n",
    "        if met not in ['Set', 'trait_pair']:\n",
    "            test_df = rc_df.loc[:, ('Set', 'trait_pair', met)].pivot(index='trait_pair', columns='Set', values=met).dropna().reset_index()\n",
    "            median_diff = np.median(test_df.Rare.values - test_df.Common.values)\n",
    "            res = wilcoxon(test_df.Rare.values - test_df.Common.values)\n",
    "            overall_res[met] = {'Diff':median_diff, 'p':res.pvalue}\n",
    "    overall_res = pd.DataFrame(overall_res).T\n",
    "    overall_res['q'] = fdrcorrection(overall_res.p)[1]\n",
    "    overall_res['sig'] = overall_res.q < 0.05\n",
    "    return overall_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.428118Z",
     "start_time": "2025-10-07T18:57:02.428108Z"
    }
   },
   "outputs": [],
   "source": [
    "paired_res = do_paired_test(all_rc_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.428908Z",
     "start_time": "2025-10-07T18:57:02.428898Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Median Population Sample Sizes')\n",
    "all_rc_initial.groupby('Set').N.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.429692Z",
     "start_time": "2025-10-07T18:57:02.429683Z"
    }
   },
   "outputs": [],
   "source": [
    "paired_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.430480Z",
     "start_time": "2025-10-07T18:57:02.430470Z"
    }
   },
   "outputs": [],
   "source": [
    "# need a list of protein coding genes IDed by Entrez.\n",
    "coding_genes = pd.read_csv(os.path.join(datadir, 'Reference_Data/Ensembl_Feb14_2025.txt.gz'), sep='\\t', usecols=['Gene type', 'NCBI gene (formerly Entrezgene) ID'])\n",
    "coding_genes = coding_genes[coding_genes['Gene type']=='protein_coding'].dropna().drop_duplicates()\n",
    "coding_genes.columns=['Gene type', 'Entrez']\n",
    "coding_genes.Entrez = coding_genes.Entrez.astype(int)\n",
    "coding_df = bio_df.loc[[x for x in coding_genes.Entrez.values if x in bio_df.index.values]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.431273Z",
     "start_time": "2025-10-07T18:57:02.431263Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_r_vs_c_violin2(rc_df, overall_res, labels):\n",
    "    n_sig = len(overall_res)\n",
    "    _ , axs = plt.subplots(nrows=1, ncols=n_sig, figsize=(n_sig, 1.25), gridspec_kw={'wspace':0.8})\n",
    "    for i, met in enumerate(overall_res.index.values):\n",
    "    #plot_median = bio_df[met].dropna().median()\n",
    "        if met in ['Length', 'CDS', 'mrna', 'Cite', 'N', 'n', 'sHet', 'lof']:\n",
    "            sns.violinplot(rc_df, x='Set', y=met, cut=0, ax=axs[i], log_scale=True, hue_order=['Common', 'Rare'],\n",
    "                           saturation=1, zorder=2, linewidth=0.5, hue='Set', palette=[blue, green])\n",
    "\n",
    "        else:\n",
    "            sns.violinplot(rc_df, x='Set', y=met, cut=0, ax=axs[i], log_scale=False, hue_order=['Common', 'Rare'],\n",
    "                           saturation=1, zorder=2, linewidth=0.5, hue='Set', palette=[blue, green])\n",
    "\n",
    "        _ = axs[i].set_xlabel('')\n",
    "        _ = axs[i].set_ylabel(labels[met])\n",
    "        if overall_res.at[met, \"q\"] < 1e-5:\n",
    "            s= '***'\n",
    "        elif overall_res.at[met, \"q\"] < 1e-3:\n",
    "            s='**'\n",
    "        elif overall_res.at[met, \"q\"] < 0.05:\n",
    "            s='*'\n",
    "        else:\n",
    "            s='n.s.'\n",
    "        axs[i].set_title(f'{s}', fontsize=7)\n",
    "        axs[i].tick_params(axis='x', rotation=30)\n",
    "        out_ax1 = axs\n",
    "    return out_ax1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.432071Z",
     "start_time": "2025-10-07T18:57:02.432062Z"
    }
   },
   "outputs": [],
   "source": [
    "ax1= plot_r_vs_c_violin2(all_rc_initial, paired_res.loc[['N', 'n', 'Length', 'sHet', 'n_mrna','GO','MisSyn', 'mrna']], \n",
    "                              labels={**labels, 'N':'Study Size', 'n': 'Geneset Size'})\n",
    "ax1[2].hlines(y=bio_df.Length.median(), xmin=-0.5, xmax=1.5, linewidth=0.5, color='red')\n",
    "ax1[2].set_ylim(2500, 1.2e6)\n",
    "ax1[1].set_ylim(3, 1000)\n",
    "ax1[3].hlines(y=coding_df.sHet.dropna().median(), xmin=-0.5, xmax=1.5, linewidth=0.5, color='red')\n",
    "ax1[4].hlines(y=coding_df.n_mrna.dropna().median(), xmin=-0.5, xmax=1.5, linewidth=0.5, color='red')\n",
    "ax1[5].hlines(y=coding_df.GO.dropna().median(), xmin=-0.5, xmax=1.5, linewidth=0.5, color='red')\n",
    "ax1[6].hlines(y=coding_df.MisSyn.dropna().median(), xmin=-0.5, xmax=1.5, linewidth=0.5, color='red')\n",
    "ax1[7].hlines(y=coding_df.mrna.dropna().median(), xmin=-0.5, xmax=1.5, linewidth=0.5, color='red')\n",
    "\n",
    "for ax in ax1:\n",
    "    ax.set_xlim(-0.5, 1.5)\n",
    "\n",
    "_ = ax1[4].set_yticks([0, 20, 40, 54])\n",
    "ax1[4].set_ylim(0, 54)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SFigure 1A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.432873Z",
     "start_time": "2025-10-07T18:57:02.432863Z"
    }
   },
   "outputs": [],
   "source": [
    "ax1= plot_r_vs_c_violin2(all_rc_initial, paired_res.loc[['pli', 'phy', 'CDS', 'lof']], \n",
    "                              labels={**labels, 'N':'Study Size', 'n': 'Geneset Size'})\n",
    "\n",
    "ax1[2].set_ylim(400, 20000)\n",
    "ax1[3].set_ylim(5, 600)\n",
    "ax1[1].set_ylim(0.1, 1.3)\n",
    "ax1[0].hlines(y=coding_df.pli.dropna().median(), xmin=-0.5, xmax=1.5, linewidth=0.5, color='red')\n",
    "ax1[1].hlines(y=coding_df.phy.dropna().median(), xmin=-0.5, xmax=1.5, linewidth=0.5, color='red')\n",
    "ax1[2].hlines(y=coding_df.CDS.dropna().median(), xmin=-0.5, xmax=1.5, linewidth=0.5, color='red')\n",
    "ax1[3].hlines(y=coding_df.lof.dropna().median(), xmin=-0.5, xmax=1.5, linewidth=0.5, color='red')\n",
    "\n",
    "for ax in ax1:\n",
    "    ax.set_xlim(-0.5, 1.5)\n",
    "    \n",
    "_ = ax1[0].set_yticks([0.2,0.6,1, 1.4,1.8])\n",
    "_ = ax1[1].set_yticks([0.25, 0.5, 0.75, 1.0, 1.25])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV & RV Overlaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the overlap statistics for the initial study pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.433663Z",
     "start_time": "2025-10-07T18:57:02.433654Z"
    }
   },
   "outputs": [],
   "source": [
    "top_over_df = overlap_df[overlap_df.trait_pair.isin(pairs)].drop_duplicates()\n",
    "top_over_df['J'] = top_over_df.nShared / (top_over_df.nRare + top_over_df.nCommon - top_over_df.nShared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.434454Z",
     "start_time": "2025-10-07T18:57:02.434444Z"
    }
   },
   "outputs": [],
   "source": [
    "top_over_df['q'] = fdrcorrection(top_over_df.pShared.values)[1]\n",
    "top_over_df['EFO'] = top_over_df.trait_pair.apply(lambda x: map_trait_code(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.435697Z",
     "start_time": "2025-10-07T18:57:02.435685Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Trait with highest CV-RV similarity:')\n",
    "print(top_over_df.sort_values('J', ascending=False).iloc[0].loc[['EFO', 'nRare', 'nCommon', 'nShared', 'q']])\n",
    "print('q=', top_over_df.sort_values('J', ascending=False).iloc[0].loc[['EFO', 'nRare', 'nCommon', 'nShared', 'q']].q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.437511Z",
     "start_time": "2025-10-07T18:57:02.437499Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Traits with no shared genes:', len(top_over_df[top_over_df.nShared==0]))\n",
    "print('Traits with significant number of shared genes:', len(top_over_df[(top_over_df.nShared>0) & (top_over_df.q <0.05)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.438360Z",
     "start_time": "2025-10-07T18:57:02.438351Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the bars\n",
    "top_over_df['rare_only'] = top_over_df.nRare - top_over_df.nShared\n",
    "top_over_df['common_only'] = top_over_df.nCommon - top_over_df.nShared\n",
    "top_over_df['total'] = top_over_df.rare_only + top_over_df.common_only + top_over_df.nShared\n",
    "top_over_df['overlap+rare'] = top_over_df.nShared + top_over_df.rare_only\n",
    "top_over_df = top_over_df.sort_values(by=['nShared', 'total'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.451362Z",
     "start_time": "2025-10-07T18:57:02.451352Z"
    }
   },
   "outputs": [],
   "source": [
    "top_over_df['logq'] = top_over_df.q.apply(lambda x: -1 * np.log10(x+1e-50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.452177Z",
     "start_time": "2025-10-07T18:57:02.452167Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_df=top_over_df[((top_over_df.total > 100) ) & (top_over_df.total < 1000)].melt(id_vars=['trait_pair', 'q', 'logq'], value_vars=['nShared', 'overlap+rare', 'total'])\n",
    "total_order = top_over_df.sort_values(by=['nShared', 'nRare', 'nCommon'], ascending=[False, False, False]).trait_pair.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.452958Z",
     "start_time": "2025-10-07T18:57:02.452948Z"
    }
   },
   "outputs": [],
   "source": [
    "_, [[ax1a, ax2a], [ax1, ax2]] = plt.subplots(2, 2, figsize=(8, 2), sharex=False, \n",
    "                                             gridspec_kw={'height_ratios': [1, 20], 'width_ratios':[49,324], 'hspace': 0})\n",
    "\n",
    "order = [x for x in total_order if x in plot_df.trait_pair.values]\n",
    "n1=len(order)\n",
    "sns.heatmap(np.array(plot_df[plot_df.variable=='total'].set_index('trait_pair').loc[order]['logq']).reshape(-1, 1).T,\n",
    "            ax=ax1a, cbar=False, cmap='Reds', yticklabels=False, xticklabels=False,vmax=25, vmin=0)\n",
    "\n",
    "sns.barplot(plot_df[plot_df.variable=='nShared'], x='trait_pair', y='value', color='#af3800', zorder=10, order=order, \n",
    "            saturation=1, ax=ax1, alpha=1, width=1)\n",
    "sns.barplot(plot_df[plot_df.variable=='overlap+rare'], x='trait_pair', y='value', color='#5fad56', zorder=5, order=order,\n",
    "            saturation=1,  ax=ax1, alpha=1, width=1)\n",
    "sns.barplot(plot_df[plot_df.variable=='total'], x='trait_pair', y='value', color='#6ec1e0', zorder=1, order=order, \n",
    "            saturation=1, ax=ax1, alpha=1, width=1)\n",
    "ax1.set_xticks([])\n",
    "\n",
    "\n",
    "plot_df2 =top_over_df[ (top_over_df.total <= 100)].melt(id_vars=['trait_pair', 'q','logq'], \n",
    "                                                                  value_vars=['nShared', 'overlap+rare', 'total'])\n",
    "order = [x for x in total_order if x in plot_df2.trait_pair.values]\n",
    "\n",
    "\n",
    "n2=len(order)\n",
    "sns.heatmap(np.array(plot_df2[plot_df2.variable=='total'].set_index('trait_pair').loc[order]['logq']).reshape(-1, 1).T, \n",
    "            ax=ax2a, cbar=False, \n",
    "            cmap='Reds', yticklabels=False, xticklabels=False, vmax=25, vmin=0)\n",
    "\n",
    "sns.barplot(plot_df2[plot_df2.variable=='nShared'], x='trait_pair', y='value', color='#af3800', \n",
    "            zorder=10, order=order, ax=ax2, alpha=1, saturation=1, width=1,)\n",
    "sns.barplot(plot_df2[plot_df2.variable=='overlap+rare'], x='trait_pair', y='value', color='#5fad56', \n",
    "            zorder=5, order=order, ax=ax2, alpha=1, saturation=1, width=1,)\n",
    "sns.barplot(plot_df2[plot_df2.variable=='total'], x='trait_pair', y='value', color='#6ec1e0', \n",
    "            zorder=1, order=order, ax=ax2, alpha=1, saturation=1, width=1)\n",
    "ax2.set_xticks([])\n",
    "ax1.set_xlabel(f'\\nTraits with more than\\n 100 genes (n={n1})')\n",
    "ax2.set_xlabel(f'\\nTraits with fewer than 100 genes (n={n2})')\n",
    "_ = ax1.set_ylabel('Total associated genes')\n",
    "_ = ax2.set_ylabel('Total associated genes')\n",
    "\n",
    "for ax in [ax1a, ax2a]:\n",
    "    for _, spine in ax.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.453754Z",
     "start_time": "2025-10-07T18:57:02.453742Z"
    }
   },
   "outputs": [],
   "source": [
    "top_over_df_sig = top_over_df[(top_over_df.q<0.05) & (top_over_df.nShared>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.454532Z",
     "start_time": "2025-10-07T18:57:02.454520Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Median percent of CVGs shared:', f'{100*(top_over_df_sig[\"nShared\"]/top_over_df_sig[\"nCommon\"]).median():.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:57:02.455333Z",
     "start_time": "2025-10-07T18:57:02.455324Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Median percent of RVGs shared:', f'{100*(top_over_df_sig[\"nShared\"]/top_over_df_sig[\"nRare\"]).median():.1f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CARVA)",
   "language": "python",
   "name": "carva"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "409.583px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
