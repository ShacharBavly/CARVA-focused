{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focuesed Entrez Convertor\n",
    "#### This file takes the raw gene files and converts them to the carva format without the overhead of running many traits in parallel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elkon2/shacharbavly/micromamba/envs/networks/lib/python3.11/site-packages/obonet/__init__.py:12: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from matplotlib_venn import venn2, venn3\n",
    "from neteval import gene_mapper as gm\n",
    "from neteval import query_ensembl as qe\n",
    "from neteval import query_hgnc as qh\n",
    "import obonet as obo\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### base settings\n",
    "datadir is the directory at the base of the project\n",
    "\n",
    "common data name is the trait for the common genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = Path.cwd().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_data_name = \"lupus_canon\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning\n",
    "in this part we clean the lupus files to match the carva pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: not sure we need the part below, might want to keep those who are connected to several genes.\n",
    "if i want to keep, need to split the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gwas_catalog_data(datafile, outfile, pval_th=5e-8, include_intergenic=False):\n",
    "    \"\"\"Clean the GWAS Catalog data and write to a new file.\n",
    "\n",
    "    Args:\n",
    "        datafile (str): file path for GWAS Catalog data\n",
    "        outfile (str): output file for cleaned data\n",
    "        pval_th (float): p-value threshold for filtering\n",
    "        include_intergenic (bool): whether to include intergenic associations\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    cols= ['DATE', 'PUBMEDID', 'DISEASE/TRAIT', 'MAPPED_GENE', 'SNP_GENE_IDS', 'P-VALUE', 'OR or BETA' ,'MAPPED_TRAIT', \n",
    "           'MAPPED_TRAIT_URI', 'INTERGENIC', 'STUDY ACCESSION', 'SNP_ID_CURRENT', 'INITIAL SAMPLE SIZE', 'GENOTYPING TECHNOLOGY']    \n",
    "    if include_intergenic:\n",
    "        cols = cols + ['UPSTREAM_GENE_ID', 'DOWNSTREAM_GENE_ID', 'UPSTREAM_GENE_DISTANCE', 'DOWNSTREAM_GENE_DISTANCE']\n",
    "    data = pd.read_csv(datafile, sep=\"\\t\", usecols=cols, low_memory=False)\n",
    "    # filter on pval\n",
    "    data = data[data[\"P-VALUE\"] <= pval_th]\n",
    "    # filter on gene and trait present\n",
    "    data = data.dropna(subset=['SNP_GENE_IDS', \"MAPPED_TRAIT_URI\"])\n",
    "    # filter out intergenic\n",
    "    if not include_intergenic:\n",
    "        data = data[data[\"INTERGENIC\"] == 0]\n",
    "    # remove associations with multiple genes\n",
    "    data = data[~data[\"SNP_GENE_IDS\"].str.contains(\",\")]\n",
    "    # remove associations with multiple traits\n",
    "    data = data[~data[\"MAPPED_TRAIT_URI\"].str.contains(\",\")]\n",
    "    # create trait code\n",
    "    data['TRAIT_CODE'] = data['MAPPED_TRAIT_URI'].apply(lambda x: x.split('/')[-1])\n",
    "    # write the cleaned file\n",
    "    data.to_csv(outfile, sep=\"\\t\", index=False)\n",
    "    print(\"Wrote data to\", outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_gwas_catalog_data(datadir/ f\"data/{common_data_name}_common.txt\", datadir/ \"data\" /f\"{common_data_name}_common.txt.update\", pval_th=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwas_genes = pd.read_csv(datadir / \"data\" / f\"{common_data_name}_common.txt.update\", sep=\"\\t\")\n",
    "display(gwas_genes.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code was taken from notebook 1A - map identifiers\n",
    "# First map from Ensembl\n",
    "ensembl_map, missing = qe.get_latest_ensembl_id(gwas_genes['SNP_GENE_IDS'].unique())\n",
    "ensembl_to_entrez, missing_entrez = gm.convert_node_ids(ensembl_map['to'].values, 'Ensembl', 'Entrez')\n",
    "ensembl_map['Entrez'] = [ensembl_to_entrez[x] if x in ensembl_to_entrez else '' for x in ensembl_map['to']]\n",
    "id_ensembl = gwas_genes.merge(ensembl_map.loc[:, ('from', 'Entrez')], left_on='SNP_GENE_IDS', right_on='from', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try mapping based on symbols for unsuccessful conversions \n",
    "symbol_map, symbol_missing = qh.perform_hgnc_query(id_ensembl[(id_ensembl['Entrez'].isnull()) | (id_ensembl['Entrez']== '')]['MAPPED_GENE'].unique(), 'Symbol', 'Symbol')\n",
    "symbol_to_entrez, missing = gm.convert_node_ids(list(symbol_map.values()), 'Symbol', 'Entrez')\n",
    "symbol_map = pd.DataFrame(symbol_map.items(), columns=['from', 'to'])\n",
    "symbol_map['Entrez'] = [symbol_to_entrez[x] if x in symbol_to_entrez else '' for x in symbol_map['to']]\n",
    "id_symbol = gwas_genes.iloc[~id_ensembl.index].merge(symbol_map.loc[:, ('from', 'Entrez')], left_on='MAPPED_GENE', right_on='from', how='inner')\n",
    "id_ensembl = id_ensembl[(id_ensembl['Entrez'] != '') & (~id_ensembl['Entrez'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all together\n",
    "converted_gwas_genes = pd.concat([id_ensembl, id_symbol])\n",
    "converted_gwas_genes = converted_gwas_genes[converted_gwas_genes['Entrez'] != '']\n",
    "converted_gwas_genes.to_csv(datadir/ \"data\" / f\"{common_data_name}_common.txt.update.enterz\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(converted_gwas_genes.head(2)[[\"Entrez\", \"P-VALUE\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commons = pd.read_csv(datadir/ \"data\" / f\"{common_data_name}_common.txt.update.enterz\", sep=\"\\t\")\n",
    "display(commons.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(commons.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commons_clean = commons[[\"Entrez\", \"MAPPED_GENE\", \"P-VALUE\", \"OR or BETA\"]]\n",
    "commons_clean.rename(columns={'P-VALUE': 'P-value'}, inplace=True)\n",
    "display(commons_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### optional: set mapped gene as the entrez col\n",
    "\n",
    "why? for some reason my version of the networks use gene symbol instead of entrez, but the code takes entrez as the input col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entrez</th>\n",
       "      <th>Gene Symbol</th>\n",
       "      <th>P-value</th>\n",
       "      <th>Beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57118</td>\n",
       "      <td>CAMK1D</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51347</td>\n",
       "      <td>TAOK3</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80205</td>\n",
       "      <td>CHD9</td>\n",
       "      <td>5.000000e-08</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Entrez Gene Symbol       P-value  Beta\n",
       "0   57118      CAMK1D  3.000000e-08  1.11\n",
       "1   51347       TAOK3  3.000000e-08  1.12\n",
       "2   80205        CHD9  5.000000e-08  1.15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if already have the file, read it:\n",
    "commons_clean = pd.read_csv(datadir / \"data\" / \"lupus_canon_entrez_cv.txt\", sep=\"\\t\")\n",
    "display(commons_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_mapping = {'Entrez': 'Entrez_old','Gene Symbol': 'Entrez', \"MAPPED_GENE\": \"Entrez\"}\n",
    "commons_renamed = commons_clean.rename(columns=rename_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "commons_renamed.to_csv(datadir/ \"data\" / f\"{common_data_name}_cv.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting ravar genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting the rare genes file to carva standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ravar_genes = pd.read_csv(datadir / \"data\" / \"lupus_rare_genes.txt\", sep=\"\\t\")\n",
    "ravar_genes = ravar_genes.rename(columns={\"P-Value\":\"P-value\"})\n",
    "# note - skipped taking a logp col since gwas doesnt have it, if missing later come back here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl_map, missing = qe.get_latest_ensembl_id(ravar_genes['Ensembl ID'].unique())\n",
    "ensembl_to_entrez, missing_entrez = gm.convert_node_ids(ensembl_map['to'].values, 'Ensembl', 'Entrez')\n",
    "ensembl_map['Entrez'] = [ensembl_to_entrez[x] if x in ensembl_to_entrez else '' for x in ensembl_map['to']]\n",
    "id_ensembl = ravar_genes.merge(ensembl_map.loc[:, ('from', 'Entrez')], left_on='Ensembl ID', right_on='from', how='inner')\n",
    "id_ensembl = id_ensembl[id_ensembl['Entrez'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(missing_entrez) > 0:\n",
    "    symbol_map, symbol_missing = qh.perform_hgnc_query(ravar_genes[ravar_genes['Ensembl ID'].isin(missing_entrez)]['Gene Symbol'].unique(), 'Symbol', 'Symbol')\n",
    "    symbol_to_entrez, missing = gm.convert_node_ids(list(symbol_map.values()), 'Symbol', 'Entrez')\n",
    "    symbol_map = pd.DataFrame(symbol_map.items(), columns=['from', 'to'])\n",
    "    symbol_map['Entrez'] = [symbol_to_entrez[x] if x in symbol_to_entrez else '' for x in symbol_map['to']]\n",
    "    id_symbol = ravar_genes.iloc[~id_ensembl.index].merge(symbol_map.loc[:, ('from', 'Entrez')], left_on='Gene Symbol', right_on='from', how='inner')\n",
    "    converted_ravar_genes = pd.concat([id_ensembl, id_symbol])\n",
    "else:\n",
    "    converted_ravar_genes = id_ensembl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the following ccode i removed pmid, trait label and reported trait as  i dont need them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the PMCIDs to the converted data\n",
    "converted_ravar_genes = converted_ravar_genes.merge(ravar_genes.loc[:, ('Ensembl ID', 'P-value', 'Location',\n",
    "                        'Gene Symbol')].drop_duplicates(), on=['Gene Symbol', 'Ensembl ID', 'P-value', 'Location'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(converted_ravar_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_ravar_genes.to_csv(datadir/ \"data/lupus_rare.txt.update.enterz\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now clean the cols to only have those the original pipeline did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ravars = pd.read_csv(datadir/ \"data/lupus_rare.txt.update.enterz\", sep=\"\\t\")\n",
    "display(ravars.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ravar_clean = ravars[['Entrez', 'Gene Symbol', 'Ensembl ID', 'P-value']]\n",
    "display(ravar_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ravar_clean.to_csv(datadir/ \"data/lupus_rv.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entrez</th>\n",
       "      <th>Gene Symbol</th>\n",
       "      <th>Ensembl ID</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9623</td>\n",
       "      <td>TCL1B</td>\n",
       "      <td>ENSG00000213231</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25948</td>\n",
       "      <td>KBTBD2</td>\n",
       "      <td>ENSG00000170852</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5799</td>\n",
       "      <td>PTPRN2</td>\n",
       "      <td>ENSG00000282185</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1553</td>\n",
       "      <td>CYP2A13</td>\n",
       "      <td>ENSG00000197838</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10206</td>\n",
       "      <td>TRIM13</td>\n",
       "      <td>ENSG00000204977</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Entrez Gene Symbol       Ensembl ID   P-value\n",
       "0    9623       TCL1B  ENSG00000213231  0.000001\n",
       "1   25948      KBTBD2  ENSG00000170852  0.000009\n",
       "2    5799      PTPRN2  ENSG00000282185  0.000071\n",
       "3    1553     CYP2A13  ENSG00000197838  0.000073\n",
       "4   10206      TRIM13  ENSG00000204977  0.000086"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if already have the file, read it:\n",
    "ravar_clean = pd.read_csv(datadir / \"data\" / \"lupus_canon_entrez_rv.txt\", sep=\"\\t\")\n",
    "display(ravar_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_mapping = {'Entrez': 'Entrez_old','Gene Symbol': 'Entrez', \"MAPPED_GENE\": \"Entrez\"}\n",
    "ravar_renamed = ravar_clean.rename(columns=rename_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ravar_renamed.to_csv(datadir/ \"data\" / f\"{common_data_name}_rv.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
