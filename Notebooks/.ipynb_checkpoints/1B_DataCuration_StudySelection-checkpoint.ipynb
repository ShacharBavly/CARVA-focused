{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Curation Notebook B - Study Selection\n",
    "\n",
    "\n",
    "\n",
    "Figures generated by this notebook:\n",
    "- Figure 1A\n",
    "- Figure 1B\n",
    "- Figure 1D\n",
    "- Figure 1E\n",
    "\n",
    "Datasets generated by this notebooks:\n",
    "- Supplemental Table 1. Input information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:44:27.551772Z",
     "start_time": "2025-07-02T21:44:27.549183Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elkon2/shacharbavly/micromamba/envs/networks/lib/python3.11/site-packages/obonet/__init__.py:12: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from matplotlib_venn import venn2, venn3\n",
    "from neteval import gene_mapper as gm\n",
    "from neteval import query_ensembl as qe\n",
    "from neteval import query_hgnc as qh\n",
    "import obonet as obo\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:44:29.244736Z",
     "start_time": "2025-07-02T21:44:29.242957Z"
    }
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "datadir = os.path.join(cwd, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:44:30.811223Z",
     "start_time": "2025-07-02T21:44:30.710680Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.font_manager as fm\n",
    "arial_font_path = os.path.join(datadir, 'Reference_Data', 'Arial.TTF')\n",
    "fm.fontManager.addfont(arial_font_path)\n",
    "matplotlib.rcParams['font.family'] = 'Arial'\n",
    "matplotlib.rcParams['svg.fonttype'] = 'none'\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "plt.rcParams.update({'font.size': 7})\n",
    "plt.rcParams['axes.linewidth'] = 0.5\n",
    "plt.rcParams['hatch.linewidth'] = 0.5\n",
    "plt.rcParams['xtick.major.width'] = 0.4\n",
    "plt.rcParams['ytick.major.width'] = 0.4\n",
    "plt.rcParams['xtick.minor.width'] = 0.3\n",
    "plt.rcParams['ytick.minor.width'] = 0.3\n",
    "plt.rcParams['legend.frameon'] = False\n",
    "plt.rcParams['xtick.major.size'] = 3\n",
    "plt.rcParams['ytick.major.size'] = 3\n",
    "plt.rcParams['xtick.minor.size'] = 2\n",
    "plt.rcParams['ytick.minor.size'] = 2\n",
    "plt.rcParams['xtick.major.pad'] = 1\n",
    "plt.rcParams['ytick.major.pad'] = 1\n",
    "plt.rcParams['axes.labelpad'] = 1\n",
    "plt.rcParams['patch.linewidth'] = 0.25\n",
    "blue='#6ec1e0'\n",
    "green='#5fad56'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:44:42.335031Z",
     "start_time": "2025-07-02T21:44:33.320186Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elkon2/shacharbavly/micromamba/envs/networks/lib/python3.11/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11050). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:44:42.437665Z",
     "start_time": "2025-07-02T21:44:42.340533Z"
    }
   },
   "outputs": [],
   "source": [
    "pc_nodes = pd.read_csv(os.path.join(datadir, 'Reference_Data', 'pcnet2_0_nodes.txt' ), sep='\\t', header=None, names=['Entrez', 'degree']).Entrez.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GWAS Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shachar note: changed clean to cleaned due to a mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:46:38.216731Z",
     "start_time": "2025-07-02T21:46:36.941566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327974, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gwas_genes = pd.read_csv(os.path.join(datadir, 'Reference_Data', 'gwas_catalog_Jan29_2025.txt.cleaned.entrez.gz'), sep='\\t', index_col=0)\n",
    "# filter to PCNet2.0 nodes\n",
    "gwas_genes = gwas_genes[gwas_genes.Entrez.isin(pc_nodes)]\n",
    "gwas_genes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:47:44.371604Z",
     "start_time": "2025-07-02T21:47:44.197131Z"
    }
   },
   "outputs": [],
   "source": [
    "study_info = pd.read_csv(os.path.join(datadir,'Reference_Data', 'cleaned_gwas-catalog-v1.0.3.1-studies-r2025-03-26.tsv.gz'), sep=\"\\t\")\n",
    "study_info = study_info.dropna(subset='TRAIT_CODE_CLEAN')\n",
    "study_info['TRAIT_CODE_CLEAN'] = study_info['TRAIT_CODE_CLEAN'].apply(lambda z: z.split('/')[-1].replace(':', '_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:47:47.454843Z",
     "start_time": "2025-07-02T21:47:47.452172Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_sample_size(s):\n",
    "    if isinstance(s, str):\n",
    "        # Find all occurrences of numbers which may include commas.\n",
    "        matches = re.findall(r'\\d[\\d,]*', s)\n",
    "        # Remove commas and convert each match to an integer, then sum them up.\n",
    "        return sum(int(num.replace(',', '')) for num in matches)\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:47:49.076318Z",
     "start_time": "2025-07-02T21:47:49.024805Z"
    }
   },
   "outputs": [],
   "source": [
    "study_info['N'] = study_info['INITIAL SAMPLE SIZE'].apply(lambda x: extract_sample_size(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:47:50.294939Z",
     "start_time": "2025-07-02T21:47:49.891921Z"
    }
   },
   "outputs": [],
   "source": [
    "# merge the gene and study information\n",
    "gwas_genes = gwas_genes.drop(columns=['TRAIT_CODE']).merge(study_info.drop(columns=['ASSOCIATION COUNT', 'SUMMARY STATS LOCATION']), \n",
    "                      on=['STUDY ACCESSION', \"DISEASE/TRAIT\", 'INITIAL SAMPLE SIZE','MAPPED_TRAIT', 'MAPPED_TRAIT_URI'],\n",
    "                                             how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:47:51.270693Z",
     "start_time": "2025-07-02T21:47:51.267914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327974, 38)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that number of entries is unchanged\n",
    "gwas_genes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PUBMEDID', 'DATE_x', 'DISEASE/TRAIT', 'MAPPED_GENE', 'SNP_GENE_IDS',\n",
      "       'INTERGENIC', 'P-VALUE', 'OR or BETA', 'MAPPED_TRAIT',\n",
      "       'MAPPED_TRAIT_URI', 'STUDY ACCESSION', 'logp', 'from', 'Entrez',\n",
      "       'INITIAL SAMPLE SIZE', 'DATE ADDED TO CATALOG', 'PUBMED ID',\n",
      "       'FIRST AUTHOR', 'DATE_y', 'JOURNAL', 'LINK', 'STUDY',\n",
      "       'REPLICATION SAMPLE SIZE', 'PLATFORM [SNPS PASSING QC]',\n",
      "       'GENOTYPING TECHNOLOGY', 'SUBMISSION DATE', 'STATISTICAL MODEL',\n",
      "       'BACKGROUND TRAIT', 'MAPPED BACKGROUND TRAIT',\n",
      "       'MAPPED BACKGROUND TRAIT URI', 'COHORT', 'FULL SUMMARY STATISTICS',\n",
      "       'GXE', 'TraitExp', 'MappedExp', 'MAPPED_TRAIT_CLEAN',\n",
      "       'TRAIT_CODE_CLEAN', 'N'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#shachar added\n",
    "print(gwas_genes.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:47:55.292799Z",
     "start_time": "2025-07-02T21:47:55.142152Z"
    }
   },
   "outputs": [],
   "source": [
    "geneCounts = gwas_genes.groupby(['DISEASE/TRAIT', 'STUDY ACCESSION', 'TRAIT_CODE_CLEAN']).MAPPED_GENE.nunique().reset_index()\n",
    "study_info = study_info.merge(geneCounts, on=['DISEASE/TRAIT', 'STUDY ACCESSION', 'TRAIT_CODE_CLEAN'], how='left')\n",
    "study_info = study_info[study_info.MAPPED_GENE >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:48:07.679736Z",
     "start_time": "2025-07-02T21:48:07.676409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial number of GWAS: 7583\n",
      "initial number of traits with at least one GWAS: 2339\n"
     ]
    }
   ],
   "source": [
    "print('initial number of GWAS:', study_info.shape[0])\n",
    "cv_start = study_info.TRAIT_CODE_CLEAN.nunique()\n",
    "print('initial number of traits with at least one GWAS:', cv_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAVAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:49:27.627876Z",
     "start_time": "2025-07-02T21:49:27.380488Z"
    }
   },
   "outputs": [],
   "source": [
    "ravar_genes = pd.read_csv(os.path.join(datadir,'Reference_Data' ,'gene_fulltable_06112024.txt.entrez.gz'),sep='\\t', low_memory=False,\n",
    "                            usecols=['Gene Symbol', 'Ensembl ID', 'Gene Type', 'CHR', 'Location', 'Reported Trait', 'Trait Label', \n",
    "                                     'Trait Ontology id', 'EFO synonym', 'P-value', 'PMID', 'TRAIT_CODE', 'Entrez'])\n",
    "ravar_genes = ravar_genes[ravar_genes.Entrez.isin(pc_nodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:49:52.614488Z",
     "start_time": "2025-07-02T21:49:52.599048Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove any with 'Exclude' annotation\n",
    "rv_study_info = pd.read_csv(os.path.join(datadir,'Reference_Data', 'rv_study_info_cleaned_with_manual_mapped_Mar28.tsv'), sep='\\t', index_col=0)\n",
    "rv_study_info = rv_study_info[(~rv_study_info.COHORT.isin(['Exclude', 'Exlcude', 'Exlclude', 'Review'])) & (rv_study_info['Classification']!='Exclude')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:49:55.408014Z",
     "start_time": "2025-07-02T21:49:55.404738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75799, 13)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ravar_genes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Gene Symbol', 'Ensembl ID', 'Gene Type', 'CHR', 'Location',\n",
      "       'Reported Trait', 'Trait Label', 'Trait Ontology id', 'EFO synonym',\n",
      "       'P-value', 'TRAIT_CODE', 'Entrez', 'PMID'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#shachar added\n",
    "print(ravar_genes.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:49:57.492232Z",
     "start_time": "2025-07-02T21:49:57.446263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75799, 13)\n",
      "(62020, 15)\n"
     ]
    }
   ],
   "source": [
    "print(ravar_genes.shape)\n",
    "ravar_genes = ravar_genes.merge(rv_study_info.loc[:, ('Reported Trait', 'PMID', 'MAPPED_TRAIT_CLEAN', 'TRAIT_CODE_CLEAN')], \n",
    "                                on=['Reported Trait', 'PMID'], how='inner')\n",
    "print(ravar_genes.shape)\n",
    "study_counts = ravar_genes.groupby(['Reported Trait', 'PMID']).Entrez.nunique().reset_index()\n",
    "study_counts = study_counts.rename(columns={'Entrez': 'GeneCount'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:50:00.043276Z",
     "start_time": "2025-07-02T21:50:00.013634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62020, 15)\n",
      "(60374, 16)\n"
     ]
    }
   ],
   "source": [
    "print(ravar_genes.shape)\n",
    "ravar_genes = ravar_genes.merge(study_counts[study_counts.GeneCount >= 3], on=['Reported Trait', 'PMID'])\n",
    "rv_study_info = rv_study_info.merge(study_counts, on = ['Reported Trait', 'PMID'])\n",
    "print(ravar_genes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:50:08.695935Z",
     "start_time": "2025-07-02T21:50:08.691672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial number of RV studies: 2207\n",
      "initial number of traits with at least one RV study: 1121\n"
     ]
    }
   ],
   "source": [
    "rv_study_info = rv_study_info[rv_study_info.GeneCount>= 3]\n",
    "rv_start= rv_study_info['TRAIT_CODE_CLEAN'].nunique()\n",
    "print('initial number of RV studies:', rv_study_info.shape[0])\n",
    "print('initial number of traits with at least one RV study:',rv_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trait Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:50:17.697224Z",
     "start_time": "2025-07-02T21:50:17.693201Z"
    },
    "code_folding": [
     2,
     22
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# identify and expand acronyms\n",
    "import re\n",
    "def extract_acronyms(strings):\n",
    "    \"\"\"\n",
    "    Extract acronyms from a list of strings.\n",
    "    Acronyms are identified as words that consist entirely of uppercase letters.\n",
    "    \n",
    "    Args:\n",
    "        strings (list of str): List of strings to search for acronyms.\n",
    "    \n",
    "    Returns:\n",
    "        set: A set of unique acronyms found across the provided strings.\n",
    "    \"\"\"\n",
    "    # Using \\b[A-Z]{2,}\\b to match words with 2 or more uppercase letters.\n",
    "    # Adjust the {2,} if you also want to capture single-letter acronyms.\n",
    "    acronym_pattern = re.compile(r'\\b[A-Z]{2,}\\b')\n",
    "    acronyms = set()\n",
    "    for text in strings:\n",
    "        found = acronym_pattern.findall(text)\n",
    "        acronyms.update(found)\n",
    "    return acronyms\n",
    "\n",
    "def replace_acronyms(text, acronym_dict):\n",
    "    \"\"\"\n",
    "    Replace acronyms in a string with their expansions followed by the original acronym in parentheses.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input string containing acronyms.\n",
    "        acronym_dict (dict): A dictionary where keys are acronyms (str) and values are the expansions (str).\n",
    "    \n",
    "    Returns:\n",
    "        str: The text with acronyms replaced by their expansion and the original acronym in parentheses.\n",
    "    \"\"\"\n",
    "    # This regex matches words consisting of at least two uppercase letters.\n",
    "    acronym_pattern = re.compile(r'[A-Z]{2,}')\n",
    "    \n",
    "    def replacer(match):\n",
    "        word = match.group(0)\n",
    "        if word in acronym_dict:\n",
    "            # Return the expansion with the original acronym in parentheses.\n",
    "            return f\"{acronym_dict[word]} ({word})\"\n",
    "        else:\n",
    "            return word\n",
    "    \n",
    "    return acronym_pattern.sub(replacer, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:50:19.715739Z",
     "start_time": "2025-07-02T21:50:19.708202Z"
    },
    "code_folding": [
     0,
     17
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "common_acronyms = {\n",
    "    'LDL': 'low density lipoprotein',\n",
    "    'HDL': 'high density lipoprotein',\n",
    "    'BMI': 'body mass index',\n",
    "    'VLDL': 'very low density lipoprotein',\n",
    "    'IL': 'interleukin',\n",
    "    'IDL': 'intermediate density lipoprotein',\n",
    "    'FVC': 'forced vital capacity',\n",
    "    'FEV': 'forced expiratory volume',\n",
    "    'COVID': 'coronavirus',\n",
    "    'HIV': 'human immunodeficiency virus',\n",
    "    'SARS': 'severe acute respiratory syndrome',\n",
    "    'APOE': 'apolipoprotein E',\n",
    "    'APOB': 'apolipoprotein B',\n",
    "    'APOA': 'apolipoprotein A',\n",
    "}\n",
    "\n",
    "acronym_expansions = {\n",
    "    'ldl': 'low density lipoprotein',\n",
    "    'hdl': 'high density lipoprotein',\n",
    "    \"FAW3\": 'omega-3 polyunsaturated fatty acid',\n",
    "    \"FAW6\": 'omega-6 polyunsaturated fatty acid',\n",
    "    \"FEC\": \"Forced Expiratory volume\",\n",
    "    \"FEV\": \"Forced Expiratory volume\",\n",
    "    \"HIV\": \"Human Immunodeficiency Virus\",\n",
    "    \"IV\": \"4\",\n",
    "    \"LDH\": \"lumbar disc herniation\",\n",
    "    \"NHDL\": 'non High density ipoprotein',\n",
    "    \"NSAID\": 'nonsteroidal anti inflammatory drug',\n",
    "    \"ACACE\": \"Acetoacetate\",                                \n",
    "    \"ACE\": \"Acetate\",             \n",
    "    \"ALA\": \"Alanine\",                       # An essential omega-3 fatty acid\n",
    "    \"ALB\": \"Albumin\",                                    # Main blood protein\n",
    "    \"APOB\": \"Apolipoprotein B\",                           # Major protein of LDL particles\n",
    "    \"APOC\": \"Apolipoprotein C\",                           # Protein component of several lipoproteins\n",
    "    \"BMI\": \"Body Mass Index\",                            # Anthropometric measure\n",
    "    \"BP\": \"Blood Pressure\",                              # Cardiovascular measure\n",
    "    \"CHOLA\": \"Cholesterol\",                              # Cholesterol level (a general measure)\n",
    "    \"CIT\": \"Citrate\",                                    # Metabolite in the citric acid cycle\n",
    "    \"CRP\": \"C-Reactive Protein\",                         # Inflammatory marker\n",
    "    \"DHA\": \"Docosahexaenoic Acid\",                       # An omega-3 fatty acid important in brain health\n",
    "    \"DISTRIB\": \"Distribution\",                           # Typically referring to a dispersion measure (e.g. cell size distribution)\n",
    "    \"EGFR\": \"Estimated Glomerular Filtration Rate\",      # Kidney function measure\n",
    "    \"FRAC\": \"Fraction\",                                  # Proportion or fractional measure of a component\n",
    "    \"FVC\": \"Forced Vital Capacity\",                      # Lung function measure\n",
    "    \"GLN\": \"Glutamine\",                                  # An amino acid\n",
    "    \"GLOL\": \"Glycerol\",                             # Summary measure across lipid traits\n",
    "    \"GLY\": \"Glycine\",                                    # An amino acid\n",
    "    \"GP\": \"Glycoproteins\",                        # Inflammatory biomarker (often abbreviated GlycA)\n",
    "    \"HDL\": \"High Density Lipoprotein\",                   # ‘Good’ cholesterol carrier\n",
    "    \"HDLC\": \"High Density Lipoprotein Cholesterol\",      # Cholesterol within HDL particles\n",
    "    \"HEEL\": \"Heel Bone Mineral Density\",                 # Bone density measurement (often via heel ultrasound)\n",
    "    \"HEIGHT\": \"Height\",                                  # Stature\n",
    "    \"HIS\": \"Histidine\",                                  # An essential amino acid\n",
    "    \"IDL\": \"Intermediate Density Lipoprotein\",           # A lipoprotein class between VLDL and LDL\n",
    "    \"IGF\": \"Insulin like Growth Factor\",                 # A hormone linked to growth processes\n",
    "    \"III\": \"Type III\",                                  # Often denotes a subclass or type (context dependent)\n",
    "    \"INS\": \"Insulin\",                                    # Hormone regulating blood sugar\n",
    "    \"LA\": \"Linoleic Acid\",                               # An essential omega-6 fatty acid\n",
    "    \"LDL\": \"Low Density Lipoprotein\",                    # ‘Bad’ cholesterol carrier\n",
    "    \"LDLC\": \"Low Density Lipoprotein Cholesterol\",       # Cholesterol within LDL particles\n",
    "    \"LIGHT\": \"Light Scatter\",                            # Measure from flow cytometry (reflects cell granularity)\n",
    "    \"MUFA\": \"Monounsaturated Fatty Acids\",               # Type of dietary fat\n",
    "    \"PC\": \"Phosphatidylcholine\",                         # A major phospholipid in cell membranes\n",
    "    \"PHE\": \"Phenylalanine\",                              # An amino acid\n",
    "    \"PUFA\": \"Polyunsaturated Fatty Acids\",              # Type of dietary fat\n",
    "    \"PYR\": \"Pyruvate\",                                   # Key metabolite in energy metabolism\n",
    "    \"RBC\": \"Red Blood Cell Count\",                       # Red blood cells count\n",
    "    \"SCZD\": \"Schizophrenia\",                             # Psychiatric disorder trait\n",
    "    \"SHBG\": \"Sex Hormone-Binding Globulin\",              # Protein that binds sex hormones\n",
    "    \"SPHERED\": \"Spherical Diameter\",                     # Typically refers to the diameter of lipoprotein particles\n",
    "    \"SYST\": \"Systolic Blood Pressure\",                   # Upper value in blood pressure measurement\n",
    "    \"TOTCHO\": \"Total Cholines\",                       # Overall cholesterol level\n",
    "    \"TOTCHOL\": \"Total Cholesterol\",                      # Overall cholesterol level\n",
    "    \"TOTPG\": \"Total Phosphoglycerides\",                  # Sum of phosphoglyceride species\n",
    "    \"TSCORE\": \"T-Score\",                                 # Bone density T-score\n",
    "    \"TYR\": \"Tyrosine\",                                   # An amino acid\n",
    "    \"VAL\": \"Valine\",                                     # An amino acid\n",
    "    \"VIT\": \"Vitamin (unspecified)\",                     # Vitamin level (exact vitamin may vary by context)\n",
    "    \"VLDL\": \"Very Low Density Lipoprotein\",              # A lipoprotein class rich in triglycerides\n",
    "    \"VLDLPL\": \"Very low density lipoprotein Phospholipids\",                      # Phospholipid content in VLDL particles\n",
    "    \"VLDLTG\": \"Very low density lipoprotein Triglycerides\",                      # Triglyceride content in VLDL particles\n",
    "    \"VOL\": \"Volume\",                                     # A generic volume measure (often of cells or particles)\n",
    "    \"Whr\": \"Waist Hip Ratio\",\n",
    "    \"whr\": \"Waist Hip Ratio\",\n",
    "    \"WHR\": \"Waist Hip Ratio\",                            # Measure of body fat distribution\n",
    "    \"XL\": \"Extra Large\",                                # Refers to an extra-large size category (e.g., lipoprotein particles)\n",
    "    \"XS\": \"Extra Small\"                                 # Refers to an extra-small size category (e.g., lipoprotein particles)\n",
    "}\n",
    "\n",
    "all_acronyms = {**common_acronyms, **acronym_expansions}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GWAS Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:50:22.558205Z",
     "start_time": "2025-07-02T21:50:22.544671Z"
    }
   },
   "outputs": [],
   "source": [
    "study_info['MappedCleanExp'] = study_info['MAPPED_TRAIT_CLEAN'].apply(lambda x: replace_acronyms(x, all_acronyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:50:58.629478Z",
     "start_time": "2025-07-02T21:50:23.332469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ced584004e43e2b42167ad65aec471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66aa13fa14741a6a9d1388da190abc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trait = model.encode(study_info['TraitExp'].values, batch_size=32)\n",
    "mapped = model.encode(study_info['MappedCleanExp'].values, batch_size=32)\n",
    "cosines = cosine_similarity(trait, mapped)\n",
    "study_info = study_info.assign(Cosine=[cosines[i,i] for i in range(len(trait))])\n",
    "study_info = study_info.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T22:18:34.348070Z",
     "start_time": "2025-06-09T22:18:34.345284Z"
    }
   },
   "source": [
    "### RAVAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:50:58.737141Z",
     "start_time": "2025-07-02T21:50:58.730596Z"
    }
   },
   "outputs": [],
   "source": [
    "rv_study_info['MappedCleanExp'] = rv_study_info['MAPPED_TRAIT_CLEAN'].apply(lambda x: replace_acronyms(x, acronym_expansions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:51:06.668020Z",
     "start_time": "2025-07-02T21:50:58.826461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a02f4bf39d44d4b82588ca2cc1f0e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8642f867589d4035a9f01b7ec0619e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['SpiroMeta,CHARGE', 'WTCCC', 'TOPMed', 'Mixed', 'UKB', 'ADNI',\n",
       "       'MyCode', 'WHI', 'ARIC', 'Meta', 'Finnish', 'COPDGene',\n",
       "       'SCOOP,INTERVAL', 'Study36038634', 'KARE', 'Psoriasis',\n",
       "       'Faroe Islands', 'GAW19', 'PDAY', 'SCZD', 'NHLBI-ESP,CHARGE',\n",
       "       'AGP', 'HyperGEN', 'GIANT', 'Nevada', 'Study30140000', 'FHS',\n",
       "       'Qatar', 'NCRAD', 'SLSJ'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reported = model.encode(rv_study_info['TraitExp'].values, batch_size=32)\n",
    "labeled = model.encode(rv_study_info['MappedCleanExp'].values, batch_size=32)\n",
    "cosines = cosine_similarity(reported, labeled)\n",
    "rv_study_info = rv_study_info.assign(Cosine=[cosines[i,i] for i in range(len(reported))])\n",
    "rv_study_info.COHORT.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GWAS Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:52:10.595684Z",
     "start_time": "2025-07-02T21:52:10.582233Z"
    },
    "code_folding": [
     42,
     69,
     73
    ]
   },
   "outputs": [],
   "source": [
    "def select_top_gwas_study(gwas_data, trait, study_info, keep_studies, exclude=['UKB', 'UKBB']):\n",
    "    study_info['StudyTrait'] = study_info['STUDY ACCESSION'] + '_' + study_info['TRAIT_CODE_CLEAN']\n",
    "    study_subset = study_info[study_info['STUDY ACCESSION'].isin(gwas_data[(gwas_data.TRAIT_CODE_CLEAN==trait) & (gwas_data['STUDY ACCESSION'].isin(keep_studies))]['STUDY ACCESSION'])]\n",
    "    study_subset = study_subset.dropna(subset=['N'])\n",
    "    #print(len(study_subset))\n",
    "    \n",
    "    if len(study_subset) > 1:\n",
    "        study_subset = prioritize_by_cosine(study_subset, th=0.8)\n",
    "        if len(study_subset) > 1:\n",
    "            study_subset = prioritize_by_cohort(study_subset, exclude=exclude)\n",
    "            if len(study_subset) > 1:\n",
    "                study_subset = prioritize_by_n(study_subset)\n",
    "                if len(study_subset) > 1:\n",
    "                    study_subset = prioritize_by_sumstats(study_subset)\n",
    "                    if len(study_subset) > 1:\n",
    "                        study_subset = prioritize_by_cohort(study_subset)\n",
    "                        if len(study_subset) > 1:\n",
    "                            return select_top_n(study_subset)\n",
    "                        else:\n",
    "                            return study_subset['STUDY ACCESSION'].values[0]\n",
    "                    else:\n",
    "                        return study_subset['STUDY ACCESSION'].values[0]\n",
    "                else:\n",
    "                    return study_subset['STUDY ACCESSION'].values[0]\n",
    "            else:\n",
    "                return study_subset['STUDY ACCESSION'].values[0]\n",
    "        else:\n",
    "            return study_subset['STUDY ACCESSION'].values[0]\n",
    "    elif len(study_subset) == 0:\n",
    "        #print('No studies with N information')\n",
    "        return np.nan\n",
    "    else:\n",
    "        return study_subset['STUDY ACCESSION'].values[0]\n",
    "\n",
    "\n",
    "def prioritize_by_cosine(study_subset, th=0.8):\n",
    "    while th > -0.1:\n",
    "        high_cosine = study_subset[study_subset.Cosine>th]\n",
    "        if len(high_cosine) >= 1:\n",
    "            non_found = False\n",
    "            return high_cosine\n",
    "        else:\n",
    "            th -= 0.1\n",
    "    return high_cosine\n",
    "    \n",
    "    \n",
    "def prioritize_by_sumstats(study_subset):\n",
    "    with_sumstats = study_subset[~study_subset['SUMMARY STATS LOCATION'].isna()]\n",
    "    if len(with_sumstats) == 0:\n",
    "        return study_subset\n",
    "    else:\n",
    "        return with_sumstats\n",
    "\n",
    "def prioritize_by_n(study_subset):\n",
    "    high_n = study_subset[study_subset.N > 100000]\n",
    "    if len(high_n) == 0:\n",
    "        high_n = study_subset[study_subset.N > 50000]\n",
    "        if len(high_n) == 0:\n",
    "            return study_subset\n",
    "        else:\n",
    "            return high_n\n",
    "    else:\n",
    "        return high_n\n",
    "    \n",
    "\n",
    "def prioritize_by_cohort(study_subset, exclude=[]):\n",
    "    if len(exclude) > 0:\n",
    "        excluded = study_subset[~study_subset.COHORT.isin(exclude)]\n",
    "        if len(excluded) > 0:\n",
    "            return excluded\n",
    "        else:\n",
    "            return study_subset\n",
    "    else:\n",
    "        with_cohort = study_subset[~study_subset.COHORT.isna()]\n",
    "        if len(with_cohort) == 0:\n",
    "            return study_subset\n",
    "        else:\n",
    "            return with_cohort\n",
    "        \n",
    "\n",
    "def select_top_n(study_subset):\n",
    "    return study_subset.sort_values('N', ascending=False)['STUDY ACCESSION'].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:53:23.009755Z",
     "start_time": "2025-07-02T21:52:11.258772Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2339/2339 [01:45<00:00, 22.07it/s]\n"
     ]
    }
   ],
   "source": [
    "multi_select_cv = {}\n",
    "for t in tqdm(study_info['TRAIT_CODE_CLEAN'].unique()):\n",
    "    t.replace(':', '_')\n",
    "    \n",
    "    multi_select_cv[t] = select_top_gwas_study(gwas_genes, t, study_info, exclude=[],\n",
    "                                               keep_studies=study_info['STUDY ACCESSION'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAVAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:53:36.785441Z",
     "start_time": "2025-07-02T21:53:36.779750Z"
    }
   },
   "outputs": [],
   "source": [
    "def prioritize_rv_studies(ravar_genes, trait, study_info, keep_studies, cosine_th=0.8, exclude=['UKB']):\n",
    "    study_subset = study_info[study_info.PMID.isin(ravar_genes[(ravar_genes.TRAIT_CODE_CLEAN==trait) & (ravar_genes.PMID.isin(keep_studies))].PMID.unique())]\n",
    "    # filter\n",
    "    study_subset = study_subset[~study_subset.isin(['Exclude', 'Review'])]\n",
    "    study_subset = study_subset.sort_values('Cosine', ascending=False)\n",
    "    if len(study_subset) > 1:\n",
    "        cosine = prioritize_by_cosine(study_subset, th=0.8)\n",
    "        cosine = prioritize_by_cohort(cosine, exclude=exclude)\n",
    "        if len(cosine) == 1:\n",
    "            return cosine.PMID.values[0]\n",
    "        elif len(cosine) > 1:\n",
    "            # return the best match/largest\n",
    "            return cosine.sort_values(by=['Cosine','N' ], ascending=False).PMID.values[0]\n",
    "        else:\n",
    "            # none with \n",
    "            return np.nan\n",
    "    elif len(study_subset) == 0: \n",
    "        return np.nan\n",
    "    else:\n",
    "        return study_subset.PMID.values[0]\n",
    "\n",
    "def prioritize_by_cohort(study_subset, exclude=['UKB']):\n",
    "    if len(exclude) == 0:\n",
    "        return study_subset\n",
    "    excluded = study_subset[~study_subset.COHORT.isin(exclude)]\n",
    "    if len(excluded) > 0:\n",
    "        return excluded\n",
    "    else:\n",
    "        return study_subset\n",
    "    \n",
    "\n",
    "def prioritize_by_cosine(study_subset, th=0.8):\n",
    "    while th > -0.1:\n",
    "        high_cosine = study_subset[study_subset.Cosine>th]\n",
    "        if len(high_cosine) >= 1:\n",
    "            non_found = False\n",
    "            return high_cosine\n",
    "        else:\n",
    "            th -= 0.1\n",
    "    return high_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:53:47.446315Z",
     "start_time": "2025-07-02T21:53:38.146970Z"
    }
   },
   "outputs": [],
   "source": [
    "multi_select_rv = {}\n",
    "for t in rv_study_info['TRAIT_CODE_CLEAN'].unique():\n",
    "    t = t.replace(':', '_')\n",
    "    multi_select_rv[t] = prioritize_rv_studies(ravar_genes, t, rv_study_info, exclude=[],\n",
    "                                                      keep_studies=rv_study_info.PMID.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identification of shared traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:53:55.511973Z",
     "start_time": "2025-07-02T21:53:55.476558Z"
    }
   },
   "outputs": [],
   "source": [
    "shared_studies = list(set(multi_select_cv.keys()).intersection(multi_select_rv.keys()))\n",
    "shared_rv = pd.DataFrame({'TRAIT_CODE_CLEAN':shared_studies, 'PMID': [multi_select_rv[x] for x in shared_studies]}, index=shared_studies)\n",
    "shared_rv = shared_rv.dropna()\n",
    "shared_rv['PMID'] = shared_rv.PMID.astype(int)\n",
    "rv_study_info['PMID'] = rv_study_info.PMID.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect study information for matched traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:53:57.883571Z",
     "start_time": "2025-07-02T21:53:57.875489Z"
    }
   },
   "outputs": [],
   "source": [
    "shared_rv = rv_study_info.merge(shared_rv, on=['PMID', 'TRAIT_CODE_CLEAN'], \n",
    "                    how='inner').drop_duplicates().sort_values(by='Cosine', ascending=False)\n",
    "shared_rv = shared_rv.drop_duplicates(subset=['PMID', 'TRAIT_CODE_CLEAN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:54:00.449842Z",
     "start_time": "2025-07-02T21:54:00.435778Z"
    }
   },
   "outputs": [],
   "source": [
    "shared_cv = pd.DataFrame({'STUDY ACCESSION': multi_select_cv}).reset_index().rename(columns={'index':'TRAIT_CODE_CLEAN'}).dropna()\n",
    "shared_cv = shared_cv[shared_cv.TRAIT_CODE_CLEAN.isin(shared_studies)]\n",
    "shared_cv = study_info.merge(shared_cv, on=['STUDY ACCESSION', 'TRAIT_CODE_CLEAN'], \n",
    "                             how='inner').drop_duplicates().sort_values(by='Cosine', ascending=False)\n",
    "#shared_cv.to_csv(os.path.join(datadir, 'GWASCatalog', 'gwascat_ravar_study_Mar28.txt'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:54:53.672911Z",
     "start_time": "2025-07-02T21:54:51.956274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01e5ea3730144bf8d07dd97ef840b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3fe5fd6d994274acf185712077bc71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = shared_cv.loc[:, ('DISEASE/TRAIT', 'STUDY ACCESSION', 'COHORT', 'TRAIT_CODE_CLEAN', 'MAPPED_TRAIT_CLEAN', 'N', 'Cosine', 'TraitExp', 'MappedCleanExp', 'PUBMED ID')]\n",
    "b = shared_rv.loc[:, ('Reported Trait', 'Trait Label', 'PMID', 'COHORT', 'N', 'Classification', 'Cosine', 'MAPPED_TRAIT_CLEAN', 'TRAIT_CODE_CLEAN','TraitExp', 'MappedCleanExp' )]\n",
    "shared_df = a.merge(b, on=['TRAIT_CODE_CLEAN'], how='inner', suffixes=['_C', '_R'])\n",
    "shared_cv_trait = model.encode(shared_df['TraitExp_C'], batch_size=32)\n",
    "shared_rv_trait = model.encode(shared_df['TraitExp_R'], batch_size=32)\n",
    "cosines = cosine_similarity(shared_cv_trait, shared_rv_trait)\n",
    "shared_df = shared_df.assign(CosineRC=[cosines[i,i] for i in range(len(shared_cv_trait))])\n",
    "# Export for manual checking\n",
    "#shared_df.loc[:, ('Reported Trait', 'DISEASE/TRAIT','MAPPED_TRAIT_CLEAN_C', 'MAPPED_TRAIT_CLEAN_R', 'Cosine_R', 'Cosine_C', \n",
    "#                  'CosineRC')].to_csv(os.path.join(datadir, 'outputs', 'check_trait_matches.tsv'), sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shachar note: moved the line from the following cell out of the cell after it to enable the manual fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_shared_df = pd.read_csv(os.path.join(datadir, 'outputs','RV Study Info - Shared Traits6.tsv'), sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:57:30.997689Z",
     "start_time": "2025-07-02T21:57:30.987200Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "final_shared_df = shared_df.merge(clean_shared_df.loc[clean_shared_df.Keep==1, ('Reported Trait', 'DISEASE/TRAIT', 'Domain', 'trait_type')], \n",
    "                       on=['Reported Trait', 'DISEASE/TRAIT'], how='inner', suffixes=['', 'Final'])\n",
    "assert len(final_shared_df) == clean_shared_df.Keep.sum(), 'Manual file does not match'\n",
    "final_shared_df['StudyC'] = final_shared_df['STUDY ACCESSION'] + '_' + final_shared_df['TRAIT_CODE_CLEAN']\n",
    "final_shared_df['StudyR'] = final_shared_df['PMID'].astype(str) + '_' + final_shared_df['TRAIT_CODE_CLEAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated rows in clean_copy:\n",
      "                         DISEASE/TRAIT            Reported Trait\n",
      "42            Diastolic blood pressure  Diastolic blood pressure\n",
      "66             Systolic blood pressure   Systolic blood pressure\n",
      "146                  Eosinophil counts          Eosinophil count\n",
      "303  Heel bone mineral density T score           Bmd HEEL TSCORE\n",
      "\n",
      "Updated rows in shared_copy:\n",
      "              DISEASE/TRAIT    Reported Trait\n",
      "135        Neutrophil count  Neutrophil count\n",
      "320  Body mass index (MTAG)   Body mass index\n"
     ]
    }
   ],
   "source": [
    "# manual fix for assertion dont match\n",
    "\n",
    "# --- Copy clean_shared_df and shared_df so originals stay intact ---\n",
    "clean_original = clean_shared_df.copy()\n",
    "shared_original = shared_df.copy()\n",
    "\n",
    "# --- Define mappings (keys = DISEASE/TRAIT, values = new Reported Trait) ---\n",
    "clean_mapping = {\n",
    "    'Diastolic blood pressure': 'Diastolic blood pressure',\n",
    "    'Systolic blood pressure': 'Systolic blood pressure',\n",
    "    'Eosinophil counts': 'Eosinophil count',\n",
    "    'Heel bone mineral density T score': 'Bmd HEEL TSCORE'\n",
    "}\n",
    "\n",
    "shared_mapping = {\n",
    "    'Body mass index (MTAG)': 'Body mass index',\n",
    "    'Neutrophil count': 'Neutrophil count'\n",
    "}\n",
    "\n",
    "# --- Apply mappings ---\n",
    "# For clean_copy\n",
    "clean_shared_df.loc[\n",
    "    clean_shared_df['DISEASE/TRAIT'].isin(clean_mapping.keys()), 'Reported Trait'\n",
    "] = clean_shared_df['DISEASE/TRAIT'].map(clean_mapping)\n",
    "\n",
    "# For shared_copy\n",
    "shared_df.loc[\n",
    "    shared_df['DISEASE/TRAIT'].isin(shared_mapping.keys()), 'Reported Trait'\n",
    "] = shared_df['DISEASE/TRAIT'].map(shared_mapping)\n",
    "\n",
    "# --- Sanity check ---\n",
    "print(\"Updated rows in clean_copy:\")\n",
    "print(clean_shared_df.loc[clean_shared_df['DISEASE/TRAIT'].isin(clean_mapping.keys()),\n",
    "                    ['DISEASE/TRAIT','Reported Trait']])\n",
    "\n",
    "print(\"\\nUpdated rows in shared_copy:\")\n",
    "print(shared_df.loc[shared_df['DISEASE/TRAIT'].isin(shared_mapping.keys()),\n",
    "                    ['DISEASE/TRAIT','Reported Trait']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shachar note:\n",
    "i got assertion error in the cell above, and upon manual checking, i saw that all the missing values in clean_shared_df exist in shared_df, but in different names\\pairs.\n",
    "\n",
    "for example BMI instead of body masss index.\n",
    "\n",
    "bigger problem - clean has Neutrophil count\tNeutrophil count\n",
    "shared has: Neutrophill count\tGranulocyte count,,, Blood NEUTROPHIL COUNT\tNeutrophil count\n",
    "\n",
    "which one to take?\n",
    "\n",
    "i have decided to manually fix the values to the more logical one, eg Diastolic blood pressure over Diastolic_blood_pressure_automated_reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367\n",
      "373\n",
      "394\n"
     ]
    }
   ],
   "source": [
    "print(len(final_shared_df))\n",
    "print(clean_shared_df.Keep.sum())\n",
    "print(len(shared_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only in clean_shared_df (Keep=1, missing from shared_df): 0\n",
      "Only in shared_df (not in clean_keep_df): 21\n",
      "In both: 373\n"
     ]
    }
   ],
   "source": [
    "# Subset clean_shared_df to only the rows with Keep==1\n",
    "clean_keep_df = clean_shared_df.loc[clean_shared_df.Keep==1, ['Reported Trait','DISEASE/TRAIT']]\n",
    "\n",
    "# Keys in each dataframe\n",
    "keys_clean = set(map(tuple, clean_keep_df[['Reported Trait','DISEASE/TRAIT']].values))\n",
    "keys_shared = set(map(tuple, shared_df[['Reported Trait','DISEASE/TRAIT']].values))\n",
    "\n",
    "# Differences\n",
    "only_in_clean = keys_clean - keys_shared\n",
    "only_in_shared = keys_shared - keys_clean\n",
    "in_both = keys_clean & keys_shared\n",
    "\n",
    "print(\"Only in clean_shared_df (Keep=1, missing from shared_df):\", len(only_in_clean))\n",
    "print(\"Only in shared_df (not in clean_keep_df):\", len(only_in_shared))\n",
    "print(\"In both:\", len(in_both))\n",
    "\n",
    "only_in_clean_df = clean_keep_df[\n",
    "    clean_keep_df.set_index(['Reported Trait','DISEASE/TRAIT']).index.isin(only_in_clean)\n",
    "]\n",
    "\n",
    "only_in_shared_df = shared_df[\n",
    "    shared_df.set_index(['Reported Trait','DISEASE/TRAIT']).index.isin(only_in_shared)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(only_in_clean_df[\"DISEASE/TRAIT\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reported Trait</th>\n",
       "      <th>DISEASE/TRAIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Reported Trait, DISEASE/TRAIT]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(only_in_clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reported Trait</th>\n",
       "      <th>DISEASE/TRAIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Abnormalitof white blood cells| not elsewhere ...</td>\n",
       "      <td>Granulocyte percentage of myeloid white cells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Neutrophill count</td>\n",
       "      <td>Granulocyte count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Icd10 z85: personal history of malignant neoplasm</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Leg predicted mass left (23118)</td>\n",
       "      <td>Left ventricular mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Premature rupture of membranes| unspecified</td>\n",
       "      <td>Spontaneous preterm birth (preterm birth)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Postprocedural respiratory disorders| not else...</td>\n",
       "      <td>Respiratory diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Sequelae of injuries of neck and trunk</td>\n",
       "      <td>Cutaneous melanoma (MTAG)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Other congenital malformations of heart</td>\n",
       "      <td>Conotruncal heart defects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Congenital malformations of spine and bony thorax</td>\n",
       "      <td>Diffuse idiopathic skeletal hyperostosis flow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Other local infections of skin and subcutaneou...</td>\n",
       "      <td>Skin and soft tissue infections</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>Abnormal serum enlevels measurement</td>\n",
       "      <td>IgG glycosylation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>TOTPG measurement</td>\n",
       "      <td>Phospholipid levels (plasma)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Phospholipids to Total Lipids in Large LDL per...</td>\n",
       "      <td>Phospholipids to total lipids in very small VL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Urinartract infection|kidneinfection</td>\n",
       "      <td>Systemic infections</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Body BMI measurement</td>\n",
       "      <td>Body mass index (change over time)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>Appendicitis</td>\n",
       "      <td>Gangrenous vs non-gangrenous appendicitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>Total Triglycerides to Total Lipids percentage</td>\n",
       "      <td>Lipid metabolism phenotypes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>Lnlvidd measurement</td>\n",
       "      <td>Left ventricular end systole inferoseptal wall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>Abnormal glucose tolerance test</td>\n",
       "      <td>Two-hour glucose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>Cardiovascular measurement</td>\n",
       "      <td>Cardiac structure and function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Certain disorders involving the immune mechanism</td>\n",
       "      <td>Celiac disease or Rheumatoid arthritis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Reported Trait  \\\n",
       "48   Abnormalitof white blood cells| not elsewhere ...   \n",
       "101                                  Neutrophill count   \n",
       "112  Icd10 z85: personal history of malignant neoplasm   \n",
       "129                    Leg predicted mass left (23118)   \n",
       "149        Premature rupture of membranes| unspecified   \n",
       "273  Postprocedural respiratory disorders| not else...   \n",
       "285             Sequelae of injuries of neck and trunk   \n",
       "295            Other congenital malformations of heart   \n",
       "301  Congenital malformations of spine and bony thorax   \n",
       "337  Other local infections of skin and subcutaneou...   \n",
       "349                Abnormal serum enlevels measurement   \n",
       "354                                  TOTPG measurement   \n",
       "363  Phospholipids to Total Lipids in Large LDL per...   \n",
       "368               Urinartract infection|kidneinfection   \n",
       "374                               Body BMI measurement   \n",
       "381                                       Appendicitis   \n",
       "383     Total Triglycerides to Total Lipids percentage   \n",
       "385                                Lnlvidd measurement   \n",
       "388                    Abnormal glucose tolerance test   \n",
       "389                         Cardiovascular measurement   \n",
       "390   Certain disorders involving the immune mechanism   \n",
       "\n",
       "                                         DISEASE/TRAIT  \n",
       "48       Granulocyte percentage of myeloid white cells  \n",
       "101                                  Granulocyte count  \n",
       "112                                             Cancer  \n",
       "129                              Left ventricular mass  \n",
       "149          Spontaneous preterm birth (preterm birth)  \n",
       "273                               Respiratory diseases  \n",
       "285                          Cutaneous melanoma (MTAG)  \n",
       "295                          Conotruncal heart defects  \n",
       "301  Diffuse idiopathic skeletal hyperostosis flow ...  \n",
       "337                    Skin and soft tissue infections  \n",
       "349                                  IgG glycosylation  \n",
       "354                       Phospholipid levels (plasma)  \n",
       "363  Phospholipids to total lipids in very small VL...  \n",
       "368                                Systemic infections  \n",
       "374                 Body mass index (change over time)  \n",
       "381          Gangrenous vs non-gangrenous appendicitis  \n",
       "383                        Lipid metabolism phenotypes  \n",
       "385  Left ventricular end systole inferoseptal wall...  \n",
       "388                                   Two-hour glucose  \n",
       "389                     Cardiac structure and function  \n",
       "390             Celiac disease or Rheumatoid arthritis  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(only_in_shared_df[['Reported Trait', \"DISEASE/TRAIT\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DISEASE/TRAIT', 'STUDY ACCESSION', 'COHORT_C', 'TRAIT_CODE_CLEAN',\n",
      "       'MAPPED_TRAIT_CLEAN_C', 'N_C', 'Cosine_C', 'TraitExp_C',\n",
      "       'MappedCleanExp_C', 'PUBMED ID', 'Reported Trait', 'Trait Label',\n",
      "       'PMID', 'COHORT_R', 'N_R', 'Classification', 'Cosine_R',\n",
      "       'MAPPED_TRAIT_CLEAN_R', 'TraitExp_R', 'MappedCleanExp_R', 'CosineRC',\n",
      "       'Domain', 'trait_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(final_shared_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Input Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:00:32.432285Z",
     "start_time": "2025-07-02T23:00:32.424905Z"
    }
   },
   "outputs": [],
   "source": [
    "inputdir = os.path.join(datadir, 'outputs')\n",
    "with open(os.path.join(inputdir, 'common.traitlist'), 'w') as f:\n",
    "    f.writelines('\\n'.join(final_shared_df.StudyC.values)+'\\n')\n",
    "with open(os.path.join(inputdir, 'rare.traitlist'), 'w') as f:\n",
    "    f.writelines('\\n'.join(final_shared_df.StudyR.values)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:00:57.876252Z",
     "start_time": "2025-07-02T23:00:34.790861Z"
    }
   },
   "outputs": [],
   "source": [
    "c_size= []\n",
    "c_sets = {}\n",
    "for i, t in tqdm(enumerate(final_shared_df.TRAIT_CODE_CLEAN.values)):\n",
    "    accession = final_shared_df.iloc[i]['STUDY ACCESSION']\n",
    "    trait = final_shared_df.iloc[i]['DISEASE/TRAIT']\n",
    "    study_genes = gwas_genes[(gwas_genes.TRAIT_CODE_CLEAN==t) & (gwas_genes['STUDY ACCESSION']==accession) & (gwas_genes['DISEASE/TRAIT']==trait)]\n",
    "    study_genes = study_genes.sort_values('logp', ascending=False)\n",
    "    study_genes = study_genes.drop_duplicates(subset='Entrez')\n",
    "    study_out = study_genes.loc[:, ('Entrez', 'MAPPED_GENE', 'P-VALUE', 'OR or BETA' )]\n",
    "    study_out.columns = ['Entrez', 'Gene Symbol', 'P-value', 'Beta']\n",
    "    c_size.append(len(study_out))\n",
    "    c_sets[t] = study_out\n",
    "    ## uncomment to save gene lists to file\n",
    "    study_out.to_csv(os.path.join(inputdir, accession+'_'+t+'_CV.txt'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:01:03.397622Z",
     "start_time": "2025-07-02T23:00:59.245354Z"
    }
   },
   "outputs": [],
   "source": [
    "r_size=[]\n",
    "r_sets={}\n",
    "for i, t in tqdm(enumerate(final_shared_df.TRAIT_CODE_CLEAN.values)):\n",
    "    pmid = final_shared_df.iloc[i]['PMID']\n",
    "    trait = final_shared_df.iloc[i]['Reported Trait']\n",
    "    study_genes = ravar_genes[(ravar_genes.TRAIT_CODE_CLEAN==t) & (ravar_genes['PMID']==pmid) & (ravar_genes['Reported Trait']==trait)]\n",
    "    study_genes = study_genes.sort_values('P-value', ascending=True)\n",
    "    study_genes = study_genes.drop_duplicates(subset='Entrez')\n",
    "    study_out = study_genes.loc[:, ('Entrez', 'Gene Symbol','Ensembl ID',  'P-value')]\n",
    "    r_size.append(len(study_out))\n",
    "    r_sets[t] = study_out\n",
    "    ## uncomment to save gene lists to file\n",
    "    study_out.to_csv(os.path.join(inputdir, str(int(pmid))+'_'+t+'_RV.txt'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificaiton of trait replicates\n",
    "\n",
    "This is where I was running into issues with it not prioritizing the same sets as used in the actual study... \n",
    "Thought I had notes somewhere but cannot find them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:41:08.348153Z",
     "start_time": "2025-07-02T22:41:08.341073Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove already used studies\n",
    "def identify_trait_repeats_cv(trait, study_info, exclude_study_info=('pmid', 'study acc', 'dis/t'), n=4, cosine_min=0.7, verbose=False):\n",
    "    trait_info = study_info[study_info.TRAIT_CODE_CLEAN==trait].copy()\n",
    "   # trait_info['Cosine'] = trait_info.Cosine.apply(lambda x: min(x, 0.9999))\n",
    "    # identify the info of the already selected study:\n",
    "    cohort = trait_info[(trait_info['STUDY ACCESSION'] == exclude_study_info[1]) &\n",
    "                       (trait_info['DISEASE/TRAIT'] == exclude_study_info[2]) &\n",
    "                       (trait_info['PUBMED ID'] == exclude_study_info[0])].COHORT.values[0]\n",
    "    # drop based on cosine similarities\n",
    "    trait_info = trait_info[trait_info.Cosine >= cosine_min]\n",
    "    # first drop by PMID\n",
    "    trait_info = trait_info[~trait_info['PUBMED ID'].isin([exclude_study_info[0]])]\n",
    "    \n",
    "    # now prioritize remaining studies\n",
    "    if len(trait_info) == 0:\n",
    "        #print(1)\n",
    "        return np.nan\n",
    "    elif len(trait_info) <= n:\n",
    "        #print(2)\n",
    "        return [x for x in zip(trait_info['STUDY ACCESSION'].values, trait_info['DISEASE/TRAIT'].values)]\n",
    "    else:\n",
    "        # still too many studies\n",
    "        remove_cohort = trait_info[trait_info.COHORT!=cohort].sort_values(by=['Cosine', 'N'], ascending=False)\n",
    "        #print(remove_cohort)\n",
    "        remove_cohort=remove_cohort.drop_duplicates(subset='COHORT')\n",
    "        out_studies = []\n",
    "        out_studies += [x for x in zip(remove_cohort['STUDY ACCESSION'].values, remove_cohort['DISEASE/TRAIT'].values)]\n",
    "        if len(out_studies) == n:\n",
    "            #print(3)\n",
    "            return out_studies\n",
    "        elif len(out_studies) >= n:\n",
    "            #print(remove_cohort)\n",
    "            return out_studies[0:n]\n",
    "        else:\n",
    "            while len(out_studies) < n:\n",
    "            \n",
    "                remaining_n = n - len(out_studies)\n",
    "                remaining_studies = trait_info[~trait_info['STUDY ACCESSION'].isin([x[0] for x in out_studies])].sort_values(by=['Cosine', 'N'], ascending=False)\n",
    "                if len(remaining_studies.drop_duplicates(subset='COHORT')) > remaining_n:\n",
    "                    out_studies += [x for x in zip(remaining_studies.drop_duplicates(subset='COHORT')['STUDY ACCESSION'].values[0:remaining_n],\n",
    "                                                  remaining_studies.drop_duplicates(subset='COHORT')['DISEASE/TRAIT'].values[0:remaining_n])]\n",
    "                    #print(5)\n",
    "                    return out_studies\n",
    "                else:\n",
    "                    out_studies += [x for x in zip(remaining_studies.drop_duplicates(subset='COHORT')['STUDY ACCESSION'].values,\n",
    "                                                  remaining_studies.drop_duplicates(subset='COHORT')['DISEASE/TRAIT'].values)]\n",
    "            #print(6)\n",
    "            return out_studies\n",
    "                \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:47:53.671465Z",
     "start_time": "2025-07-02T22:47:51.529484Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 373/373 [00:03<00:00, 118.59it/s]\n"
     ]
    }
   ],
   "source": [
    "drop_cv = ['GCST003987_MONDO_0004979', 'GCST012230_EFO_0007788', 'GCST009004_EFO_0004340', \n",
    "          'GCST90013709_EFO_0000341', 'GCST90013697_MONDO_0005575']\n",
    "cv_repeats = {}\n",
    "for t in tqdm(final_shared_df['TRAIT_CODE_CLEAN'].unique()):\n",
    "    t.replace(':', '_')\n",
    "    pmid = final_shared_df.loc[final_shared_df.TRAIT_CODE_CLEAN==t,('PUBMED ID')].values[0]\n",
    "    acc = final_shared_df.loc[final_shared_df.TRAIT_CODE_CLEAN==t,('STUDY ACCESSION')].values[0]\n",
    "    dis = final_shared_df.loc[final_shared_df.TRAIT_CODE_CLEAN==t,('DISEASE/TRAIT')].values[0]\n",
    "    if t=='MONDO_xxxxx':\n",
    "        break\n",
    "    cv_repeats[t] = identify_trait_repeats_cv( t, study_info[~study_info.StudyTrait.isin(drop_cv)], exclude_study_info=(pmid, acc, dis),n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:51:15.810074Z",
     "start_time": "2025-07-02T22:51:15.807374Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fix a one-study discrepancy for EFO_0004340 & EFO_0007788\n",
    "cv_repeats['EFO_0004340'] = [('GCST90255621', 'Body mass index'),\n",
    " ('GCST90103755', 'Body mass index'),\n",
    " ('GCST90446645', 'Body mass index'),\n",
    " ('GCST008158', 'Body mass index')]\n",
    "cv_repeats['EFO_0007788'] = [('GCST008733', 'Waist-to-hip ratio adjusted for BMI'),\n",
    " ('GCST90131908', 'Waist-to-hip ratio adjusted for BMI'),\n",
    " ('GCST008994', 'Waist-to-hip ratio adjusted for BMI'),\n",
    " ('GCST008159', 'Waist-to-hip ratio adjusted for BMI')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shachar notet: the following cell was adjusted to dettect mismatches created due to the manual fix from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:34:24.450965Z",
     "start_time": "2025-07-02T22:34:24.443710Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove already used studies\n",
    "def identify_trait_repeats_rv(trait, study_info, exclude_study_info=('pmid', 'dis/t'), n=4, cosine_min=0.7):\n",
    "    trait_info = study_info[study_info.TRAIT_CODE_CLEAN==trait]\n",
    "    # identify the info of the already selected study:\n",
    "    \n",
    "    #print(trait_info['Reported Trait'])\n",
    "    try:\n",
    "    \n",
    "        #cohort = trait_info[(trait_info['Reported Trait'] == exclude_study_info[1]) & (trait_info['PMID'] == exclude_study_info[0])].COHORT.values[0]\n",
    "        cohort1 = trait_info[(trait_info['Reported Trait'] == exclude_study_info[1]) & (trait_info['PMID'] == exclude_study_info[0])]\n",
    "        #print(cohort1)\n",
    "        #assert False, \"Stopping cell cohprt\"\n",
    "        cohort = cohort1.COHORT.values[0]\n",
    "    \n",
    "    except IndexError:\n",
    "        print(\"trait:\\n\", trait)\n",
    "        #print(\"study_info\\n\", study_info)\n",
    "        print(\"exclude_study_info\\n\", exclude_study_info)\n",
    "        print(\"trait_info\\n\", trait_info)\n",
    "        print(\"cohort1!!!!!!!!\\n\", cohort1)\n",
    "        display(trait_info)\n",
    "        assert False, \"Stopping cell intentionally\"\n",
    "    \n",
    "    # drop based on cosine similarities\n",
    "    trait_info = trait_info[trait_info.Cosine >= cosine_min]\n",
    "    \n",
    "    # first drop by PMID\n",
    "    trait_info = trait_info[~trait_info['PMID'].isin([exclude_study_info[0]])]\n",
    "    \n",
    "    # now prioritize remaining studies\n",
    "    if len(trait_info) == 0:\n",
    "        return np.nan\n",
    "    elif len(trait_info) <= n:\n",
    "        out_info = trait_info.sort_values(by=['Cosine', 'N'], ascending=False).drop_duplicates(subset='PMID')\n",
    "        return [x for x in zip(out_info['PMID'].values, out_info['Reported Trait'])]\n",
    "    else:\n",
    "        # still too many studies\n",
    "        remove_cohort = trait_info[trait_info.COHORT!=cohort].sort_values(by=['Cosine', 'N'], ascending=False).drop_duplicates(subset='COHORT').drop_duplicates(subset='PMID')\n",
    "        out_studies = []\n",
    "        out_studies += [x for x in zip(remove_cohort['PMID'].values, remove_cohort['Reported Trait'])]\n",
    "        if len(out_studies) == n:\n",
    "            return out_studies\n",
    "        elif len(out_studies) >= n:\n",
    "            return out_studies[0:n]\n",
    "        else:\n",
    "            while len(out_studies) < n:\n",
    "            \n",
    "                remaining_n = n - len(out_studies)\n",
    "                remaining_studies = trait_info[~trait_info['PMID'].isin([x[0] for x in out_studies])].sort_values(by=['Cosine', 'N'], ascending=False).drop_duplicates(subset='PMID')\n",
    "                if len(remaining_studies) == 0:\n",
    "                    return out_studies\n",
    "                if len(remaining_studies.drop_duplicates(subset='COHORT')) > remaining_n:\n",
    "                    out_studies += [x for x in zip(remaining_studies.drop_duplicates(subset='COHORT')['PMID'].values[0:remaining_n],\n",
    "                                   remaining_studies.drop_duplicates(subset='COHORT')['Reported Trait'].values[0:remaining_n])]\n",
    "                    return out_studies\n",
    "                else:\n",
    "                    out_studies += [x for x in zip(remaining_studies.drop_duplicates(subset='COHORT')['PMID'].values,\n",
    "                                   remaining_studies.drop_duplicates(subset='COHORT')['Reported Trait'].values)]\n",
    "            return out_studies\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shachar note: the following code block failed, probably because of the fix to the mismatch from before.\n",
    "im adding a code block that will cahnge the origin as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rv_original.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_original = rv_study_info.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_study_info.loc[\n",
    "    rv_study_info['TRAIT_CODE_CLEAN'] == \"EFO_0004833\", 'Reported Trait'\n",
    "] = \"Neutrophil count\"\n",
    "\n",
    "rv_study_info.loc[\n",
    "    rv_study_info['TRAIT_CODE_CLEAN'] == \"EFO_0004340\", 'Reported Trait'\n",
    "] = \"Body mass index\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "invalid fix\n",
    "shared_mapping = {\n",
    "    'Body mass index (MTAG)': 'Body mass index',\n",
    "    'Neutrophil count': 'Neutrophil count'\n",
    "}\n",
    "\n",
    "# Make a copy to keep the original safe\n",
    "rv_original = rv_study_info.copy()\n",
    "\n",
    "# Define the same mappings (keys = DISEASE/TRAIT, values = new Reported Trait)\n",
    "fix_mapping = {\n",
    "    'Body mass index (MTAG)': 'Body mass index',\n",
    "    'Neutrophil count': 'Neutrophil count'\n",
    "}\n",
    "\n",
    "# Apply fix: update Reported Trait wherever DISEASE/TRAIT matches\n",
    "rv_study_info.loc[\n",
    "    rv_study_info['DISEASE/TRAIT'].isin(fix_mapping.keys()), 'Reported Trait'\n",
    "] = rv_study_info['DISEASE/TRAIT'].map(fix_mapping)\n",
    "\n",
    "# Sanity check: show updated rows\n",
    "print(rv_study_info.loc[rv_copy['DISEASE/TRAIT'].isin(fix_mapping.keys()),\n",
    "                  ['DISEASE/TRAIT','Reported Trait']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_study_info = rv_original\n",
    "display(rv_study_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:34:26.655934Z",
     "start_time": "2025-07-02T22:34:25.914921Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/373 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 373/373 [00:01<00:00, 287.19it/s]\n"
     ]
    }
   ],
   "source": [
    "rv_repeats = {}\n",
    "for t in tqdm(final_shared_df['TRAIT_CODE_CLEAN'].unique()):\n",
    "    t.replace(':', '_')\n",
    "    pmid = final_shared_df.loc[final_shared_df.TRAIT_CODE_CLEAN==t,('PMID')].values[0]\n",
    "    dis = final_shared_df.loc[final_shared_df.TRAIT_CODE_CLEAN==t,('Reported Trait')].values[0]\n",
    "    rv_repeats[t] = identify_trait_repeats_rv( t, rv_study_info, exclude_study_info=(pmid,dis),n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create genesets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:01:39.771859Z",
     "start_time": "2025-07-02T23:01:04.759105Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "373it [00:38,  9.71it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, t in tqdm(enumerate(cv_repeats.keys())):\n",
    "    if isinstance(cv_repeats[t], list):\n",
    "        for acc, dis in cv_repeats[t]:\n",
    "            study_genes = gwas_genes[(gwas_genes.TRAIT_CODE_CLEAN==t) & \n",
    "                                     (gwas_genes['STUDY ACCESSION']==acc) & \n",
    "                                     (gwas_genes['DISEASE/TRAIT']==dis)]\n",
    "            study_genes = study_genes.sort_values('P-VALUE', ascending=True)\n",
    "            study_genes = study_genes.drop_duplicates(subset='Entrez')\n",
    "            study_out = study_genes.loc[:, ('Entrez', 'MAPPED_GENE', 'P-VALUE', 'OR or BETA' )]\n",
    "            study_out.columns = ['Entrez', 'Gene Symbol', 'P-value', 'Beta']\n",
    "            study_out.to_csv(os.path.join(inputdir, acc+'_'+t+'_CV.txt'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:01:42.897185Z",
     "start_time": "2025-07-02T23:01:41.146489Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "373it [00:02, 169.40it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, t in tqdm(enumerate(rv_repeats.keys())):\n",
    "    if isinstance(rv_repeats[t], list):\n",
    "        for acc, dis in rv_repeats[t]:  \n",
    "            study_genes = ravar_genes[(ravar_genes.TRAIT_CODE_CLEAN==t) & \n",
    "                                      (ravar_genes['PMID']==acc) & \n",
    "                                      (ravar_genes['Reported Trait']==dis)]\n",
    "\n",
    "            study_genes = study_genes.sort_values('P-value', ascending=True)\n",
    "            study_genes = study_genes.drop_duplicates(subset='Entrez')\n",
    "            study_out = study_genes.loc[:, ('Entrez', 'Gene Symbol','Ensembl ID',  'P-value')]\n",
    "            study_out.to_csv(os.path.join(inputdir, str(int(acc))+'_'+t+'_RV.txt'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create repeat pairs, including originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:50:26.247298Z",
     "start_time": "2025-07-02T22:50:26.184324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1246, 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pairs = []\n",
    "for trait in cv_repeats.keys():\n",
    "    original_cv = multi_select_cv[trait]\n",
    "    original_rv = multi_select_rv[trait]\n",
    "    new_cv = cv_repeats[trait]\n",
    "    new_rv = rv_repeats[trait]\n",
    "    if isinstance(new_cv, list):\n",
    "        all_cv = [original_cv] + [x[0] for x in new_cv]\n",
    "    else:\n",
    "        all_cv = [original_cv]\n",
    "    if isinstance(new_rv, list):\n",
    "        all_rv = [original_rv] + [x[0] for x in new_rv]\n",
    "    else:\n",
    "        all_rv = [original_rv]\n",
    "    r_studies = []\n",
    "    c_studies = []\n",
    "    for studyC in all_cv:\n",
    "        for studyR in all_rv:\n",
    "            if (studyR != original_rv) or (studyC != original_cv):\n",
    "                r_studies.append(studyR)\n",
    "                c_studies.append(studyC)\n",
    "    if len(c_studies) > 0:\n",
    "        all_pairs.append(pd.DataFrame({'C':c_studies, 'R':r_studies, 'TRAIT_CODE_CLEAN':trait}))\n",
    "        \n",
    "repeat_df = pd.concat(all_pairs)\n",
    "repeat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:50:27.591005Z",
     "start_time": "2025-07-02T22:50:27.586896Z"
    }
   },
   "outputs": [],
   "source": [
    "repeat_df = repeat_df.assign(StudyC=repeat_df.C+'_'+repeat_df.TRAIT_CODE_CLEAN)\n",
    "repeat_df = repeat_df.assign(StudyR=repeat_df.R.astype(int).astype(str)+'_'+repeat_df.TRAIT_CODE_CLEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:50:28.940286Z",
     "start_time": "2025-07-02T22:50:28.931112Z"
    }
   },
   "outputs": [],
   "source": [
    "inputdir=os.path.join(datadir, 'outputs')\n",
    "with open(os.path.join(inputdir, 'common_repeats.traitlist'), 'w') as f:\n",
    "    f.writelines('\\n'.join(repeat_df.StudyC.values)+'\\n')\n",
    "with open(os.path.join(inputdir, 'rare_repeats.traitlist'), 'w') as f:\n",
    "    f.writelines('\\n'.join(repeat_df.StudyR.values)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:50:30.294020Z",
     "start_time": "2025-07-02T22:50:30.269731Z"
    }
   },
   "outputs": [],
   "source": [
    "repeat_df2 = repeat_df.merge(study_info.loc[:, ('StudyTrait', 'DISEASE/TRAIT', 'N', 'COHORT', 'Cosine', 'PUBMED ID', 'MAPPED_GENE')], \n",
    "                            left_on='StudyC', right_on='StudyTrait',\n",
    "               how='left').drop(columns='StudyTrait')\n",
    "rv_study_info['StudyTrait'] = rv_study_info.PMID.astype(int).astype(str) + '_' + rv_study_info.TRAIT_CODE_CLEAN\n",
    "repeat2 = repeat_df2.merge(rv_study_info.loc[:, ('PMID','Reported Trait', 'COHORT', 'N', 'Ancestry', 'Cosine', 'GeneCount', 'StudyTrait')].drop_duplicates(subset=['StudyTrait']), \n",
    "                left_on='StudyR', right_on='StudyTrait', suffixes=('_C', '_R'), how='left')\n",
    "repeat2.to_csv(os.path.join(datadir, 'outputs','repeat_study_info.txt'), sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:50:31.623917Z",
     "start_time": "2025-07-02T22:50:31.621598Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_trait_pair(df, rcol='Rare Study', ccol='Common Study', efocol='EFO'):\n",
    "    df['trait_pair'] = df[rcol].astype(int).astype(str) + '_' + df[efocol] +'_' +df[ccol] +'_'+ df[efocol]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:50:32.957008Z",
     "start_time": "2025-07-02T22:50:32.953450Z"
    }
   },
   "outputs": [],
   "source": [
    "repeat2 = get_trait_pair(repeat2, rcol='R', ccol='C', efocol='TRAIT_CODE_CLEAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplemental Table 1 - Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:55:34.491021Z",
     "start_time": "2025-07-02T22:55:34.487504Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_C = final_shared_df.loc[:, ['DISEASE/TRAIT', 'STUDY ACCESSION', 'COHORT_C', 'TRAIT_CODE_CLEAN', \n",
    "                                     'N_C', 'Cosine_C', 'PUBMED ID']]\n",
    "initial_C.columns =['Reported Trait', 'Study Identifier', 'Population Cohort', 'Mapped EFO', \n",
    "                    'Population Sample Size', 'Trait Cosine Similarity', 'PUBMED ID']\n",
    "initial_C['Set']='Initial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:55:35.854003Z",
     "start_time": "2025-07-02T22:55:35.850804Z"
    }
   },
   "outputs": [],
   "source": [
    "repeat_C = repeat2.loc[:, ('DISEASE/TRAIT', 'C', 'COHORT_C', 'TRAIT_CODE_CLEAN', \n",
    "                                     'N_C', 'Cosine_C', 'PUBMED ID',)]\n",
    "repeat_C.columns= ['Reported Trait', 'Study Identifier', 'Population Cohort', 'Mapped EFO', \n",
    "                    'Population Sample Size', 'Trait Cosine Similarity', 'PUBMED ID']\n",
    "repeat_C['Set'] = 'Additional'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:57:01.248923Z",
     "start_time": "2025-07-02T22:57:01.242777Z"
    }
   },
   "outputs": [],
   "source": [
    "info_C = pd.concat([initial_C, repeat_C])\n",
    "info_C = info_C.sort_values('Set').drop_duplicates(subset=['Reported Trait', 'Study Identifier', 'Population Cohort', \n",
    "                                                           'Mapped EFO', 'Population Sample Size', 'Trait Cosine Similarity', \n",
    "                                                           'PUBMED ID'], keep='first')\n",
    "info_C['Variant Type'] = 'Common'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:59:24.745355Z",
     "start_time": "2025-07-02T22:59:24.742593Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_R = final_shared_df.loc[:, ('Reported Trait','PMID', 'COHORT_R','TRAIT_CODE_CLEAN',\n",
    "                                     'N_R', 'Cosine_R', 'PMID')]\n",
    "initial_R['Set'] = 'Initial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:59:26.126931Z",
     "start_time": "2025-07-02T22:59:26.123103Z"
    }
   },
   "outputs": [],
   "source": [
    "repeat_R = repeat2.loc[:, ('Reported Trait','R', 'COHORT_R','TRAIT_CODE_CLEAN',\n",
    "                                     'N_R', 'Cosine_R', 'PMID')]\n",
    "repeat_R = repeat_R.rename(columns={'R':'PMID'})\n",
    "repeat_R['Set'] = 'Additional'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:59:27.484999Z",
     "start_time": "2025-07-02T22:59:27.479253Z"
    }
   },
   "outputs": [],
   "source": [
    "info_R = pd.concat([initial_R, repeat_R])\n",
    "info_R = info_R.sort_values('Set').drop_duplicates(subset=['Reported Trait','PMID', 'COHORT_R','TRAIT_CODE_CLEAN',\n",
    "                                     'N_R', 'Cosine_R', 'PMID'], keep='first')\n",
    "info_R.columns = ['Reported Trait', 'Study Identifier', 'Population Cohort', 'Mapped EFO',\n",
    "                    'Population Sample Size', 'Trait Cosine Similarity', 'PUBMED ID', 'Set']\n",
    "info_R['Variant Type'] = 'Rare'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:59:45.271124Z",
     "start_time": "2025-07-02T22:59:45.268329Z"
    }
   },
   "outputs": [],
   "source": [
    "trait_info = final_shared_df.loc[:, ( 'TRAIT_CODE_CLEAN', 'MAPPED_TRAIT_CLEAN_C', 'trait_type', 'Domain')]\n",
    "trait_info.columns = [ 'Mapped EFO', 'Mapped Trait',\n",
    "                    'Trait Type', 'Biological Domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:59:52.738917Z",
     "start_time": "2025-07-02T22:59:52.734020Z"
    }
   },
   "outputs": [],
   "source": [
    "all_info = pd.concat([info_R.drop_duplicates(), info_C.drop_duplicates()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:59:54.125622Z",
     "start_time": "2025-07-02T22:59:54.123015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1496, 9)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:59:57.396583Z",
     "start_time": "2025-07-02T22:59:57.392230Z"
    }
   },
   "outputs": [],
   "source": [
    "all_info = all_info.merge(trait_info, on=['Mapped EFO'], how='left').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:00:03.225349Z",
     "start_time": "2025-07-02T23:00:03.222421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1496, 12)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:01:45.540396Z",
     "start_time": "2025-07-02T23:01:44.268831Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1496it [00:07, 187.72it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_genes(s,t,v):\n",
    "    if v == 'Rare':\n",
    "        genes = pd.read_csv(os.path.join(inputdir, str(int(s))+'_'+t+'_RV.txt'), sep='\\t')\n",
    "    else:\n",
    "        genes = pd.read_csv(os.path.join(inputdir, s+'_'+t+'_CV.txt'), sep='\\t')\n",
    "    return genes.Entrez.unique()\n",
    "\n",
    "all_genes = {}\n",
    "n_genes = {}\n",
    "for idx, study, trait, vartype in tqdm(zip(all_info.index.values, all_info['Study Identifier'].values, all_info['Mapped EFO'].values, all_info['Variant Type'].values)):\n",
    "    try:\n",
    "        genes = load_genes(study, trait, vartype)\n",
    "        all_genes[idx] = ','.join([str(int(x)) for x in list(genes)])\n",
    "        n_genes[idx] = len(genes)\n",
    "    except:\n",
    "        print(study, trait, vartype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:07:52.173962Z",
     "start_time": "2025-07-02T23:07:52.167196Z"
    }
   },
   "outputs": [],
   "source": [
    "gene_info = pd.DataFrame({'Gene List':all_genes, 'Gene Count':n_genes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:07:53.711481Z",
     "start_time": "2025-07-02T23:07:53.708466Z"
    }
   },
   "outputs": [],
   "source": [
    "all_info = all_info.join(gene_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:07:55.105480Z",
     "start_time": "2025-07-02T23:07:55.100830Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "all_info = all_info.loc[:, ('Mapped Trait', 'Mapped EFO', 'Study Identifier', 'Variant Type', 'Trait Type', \n",
    "                            'Biological Domain', 'Set', 'Reported Trait', 'Trait Cosine Similarity', 'Population Cohort', \n",
    "                            'Population Sample Size', \n",
    "                            'PUBMED ID', 'Gene Count', 'Gene List')]\n",
    "all_info['Trait Type'] = all_info['Trait Type'].map({'Q':'Continuous', 'CC':'Categorical'})\n",
    "all_info['Set'] = all_info['Set'].map({'Original':'Initial', 'Repeat': 'Additional'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T19:21:56.470217Z",
     "start_time": "2025-06-22T19:21:56.451362Z"
    }
   },
   "outputs": [],
   "source": [
    "all_info.to_csv(os.path.join(datadir, 'outputs/STable1.txt'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1A - Study Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:08:39.903633Z",
     "start_time": "2025-07-02T23:08:39.901306Z"
    }
   },
   "outputs": [],
   "source": [
    "final_count = final_shared_df.TRAIT_CODE_CLEAN.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:08:41.299313Z",
     "start_time": "2025-07-02T23:08:41.297476Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_start = 2339"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:08:46.518056Z",
     "start_time": "2025-07-02T23:08:45.837042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams.update({'font.size': 7})\n",
    "_ = plt.figure(figsize=(3,2))\n",
    "v = venn2(subsets=(cv_start-final_count, rv_start-final_count, final_count), set_labels=( 'GWAS Catalog','RAVAR'))\n",
    "v.get_patch_by_id('10').set_color('#6ec1e0')\n",
    "v.get_patch_by_id('01').set_color('#5fad56')\n",
    "v.get_patch_by_id('11').set_color('#00606f')\n",
    "for patch in ['01', '10', '11']:\n",
    "    v.get_patch_by_id(patch).set_alpha(1)\n",
    "    v.get_patch_by_id(patch).set_ec('black')\n",
    "    v.get_patch_by_id(patch).set_lw(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1B - Domain Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:08:58.541120Z",
     "start_time": "2025-07-02T23:08:58.226255Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Lipid Measurement'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/elkon2/shacharbavly/micromamba/envs/networks/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key, method, tolerance)\u001b[39m\n\u001b[32m   3801\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3802\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3803\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/elkon2/shacharbavly/micromamba/envs/networks/lib/python3.11/site-packages/pandas/_libs/index.pyx:138\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/elkon2/shacharbavly/micromamba/envs/networks/lib/python3.11/site-packages/pandas/_libs/index.pyx:165\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Lipid Measurement'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[96]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m plot_df.at[\u001b[33m'\u001b[39m\u001b[33mOther\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m] = \u001b[32m0\u001b[39m\n\u001b[32m     25\u001b[39m plot_df = plot_df.sort_values(\u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m lipid = \u001b[43mplot_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mLipid Measurement\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mContinuous\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     27\u001b[39m plot_df.at[\u001b[33m'\u001b[39m\u001b[33mLipid Measurement\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mContinuous\u001b[39m\u001b[33m'\u001b[39m] = \u001b[32m38\u001b[39m\n\u001b[32m     28\u001b[39m plot_df.drop(columns=\u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m).plot(kind=\u001b[33m'\u001b[39m\u001b[33mbar\u001b[39m\u001b[33m'\u001b[39m, stacked=\u001b[38;5;28;01mTrue\u001b[39;00m, ax=plt.gca(),edgecolor=\u001b[33m'\u001b[39m\u001b[33mblack\u001b[39m\u001b[33m'\u001b[39m, linewidth=\u001b[32m0.3\u001b[39m, width=\u001b[32m0.8\u001b[39m,\n\u001b[32m     29\u001b[39m                                                                               color=[ \u001b[33m'\u001b[39m\u001b[33m#509AA6\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m#00606f\u001b[39m\u001b[33m'\u001b[39m,])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/elkon2/shacharbavly/micromamba/envs/networks/lib/python3.11/site-packages/pandas/core/indexing.py:2431\u001b[39m, in \u001b[36m_AtIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   2428\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInvalid call for scalar access (getting)!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2429\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj.loc[key]\n\u001b[32m-> \u001b[39m\u001b[32m2431\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/elkon2/shacharbavly/micromamba/envs/networks/lib/python3.11/site-packages/pandas/core/indexing.py:2382\u001b[39m, in \u001b[36m_ScalarAccessIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   2379\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInvalid call for scalar access (getting)!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2381\u001b[39m key = \u001b[38;5;28mself\u001b[39m._convert_key(key)\n\u001b[32m-> \u001b[39m\u001b[32m2382\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/elkon2/shacharbavly/micromamba/envs/networks/lib/python3.11/site-packages/pandas/core/frame.py:3924\u001b[39m, in \u001b[36mDataFrame._get_value\u001b[39m\u001b[34m(self, index, col, takeable)\u001b[39m\n\u001b[32m   3918\u001b[39m engine = \u001b[38;5;28mself\u001b[39m.index._engine\n\u001b[32m   3920\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.index, MultiIndex):\n\u001b[32m   3921\u001b[39m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[32m   3922\u001b[39m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[32m   3923\u001b[39m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3924\u001b[39m     row = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m series._values[row]\n\u001b[32m   3927\u001b[39m \u001b[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001b[39;00m\n\u001b[32m   3928\u001b[39m \u001b[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/elkon2/shacharbavly/micromamba/envs/networks/lib/python3.11/site-packages/pandas/core/indexes/base.py:3804\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key, method, tolerance)\u001b[39m\n\u001b[32m   3802\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._engine.get_loc(casted_key)\n\u001b[32m   3803\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m-> \u001b[39m\u001b[32m3804\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3805\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3806\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3808\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3809\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Lipid Measurement'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 300x100 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "domains = final_shared_df.Domain.value_counts().reset_index()\n",
    "domains[\"count\"] = domains[\"Domain\"] # attempting to restore original name\n",
    "#print(domains)\n",
    "#shachar note: it seems like in the og version col Domain was count.\n",
    "domain_plot_values = domains[domains['Domain']>=5].Domain.values # was count >=5\n",
    "\n",
    "domains = final_shared_df[final_shared_df.trait_type=='Q'].Domain.value_counts().reset_index()\n",
    "domains[\"count\"] = domains[\"Domain\"] # attempting to restore original name\n",
    "domains_plot = domains[domains.Domain.isin(domain_plot_values)]\n",
    "other=domains[~domains.Domain.isin(domain_plot_values)]['count'].sum()\n",
    "domain_dict =domains_plot.set_index('Domain')['count'].to_dict() # was count .to dict\n",
    "domain_dict['Other'] = other\n",
    "\n",
    "domains = final_shared_df[final_shared_df.trait_type=='CC'].Domain.value_counts().reset_index()\n",
    "domains[\"count\"] = domains[\"Domain\"] # attempting to restore original name\n",
    "domains_plot2 = domains[domains.Domain.isin(domain_plot_values)]\n",
    "other2=domains[~domains.Domain.isin(domain_plot_values)]['count'].sum()\n",
    "domain_dict2 =domains_plot2.set_index('Domain')['count'].to_dict() \n",
    "domain_dict2['Other'] = other2\n",
    "\n",
    "_ = plt.figure(figsize=(3, 1))\n",
    "plot_df = pd.DataFrame({'Continuous': domain_dict, 'Categorical': domain_dict2}).iloc[::-1]\n",
    "plot_df['sum'] = np.nansum(plot_df, axis=1)\n",
    "plot_df.at['Other', 'sum'] = 0\n",
    "plot_df = plot_df.sort_values('sum', ascending=False)\n",
    "lipid = plot_df.at['Lipid Measurement', 'Continuous']\n",
    "plot_df.at['Lipid Measurement', 'Continuous'] = 38\n",
    "plot_df.drop(columns='sum').plot(kind='bar', stacked=True, ax=plt.gca(),edgecolor='black', linewidth=0.3, width=0.8,\n",
    "                                                                              color=[ '#509AA6', '#00606f',])\n",
    "\n",
    "\n",
    "plt.hlines(y=34, xmin=-18.5, xmax=20.5,color='white', linewidth=3)\n",
    "plt.ylim(0, 40)\n",
    "plt.yticks([0, 10, 20, 30, 38], labels=[0,10,20,30,int(lipid)])\n",
    "plt.ylabel('Trait Count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                index  Domain\n",
      "0   Lipid Measurement     116\n",
      "1           Metabolic      23\n",
      "2       Hematological      12\n",
      "3       Immunological      10\n",
      "4      Anthropometric       5\n",
      "5               Renal       4\n",
      "6      Cardiovascular       3\n",
      "7           Endocrine       3\n",
      "8         Respiratory       3\n",
      "9             Hepatic       2\n",
      "10       Neurological       1\n",
      "11     Opthamological       1\n",
      "12           Muscular       1\n",
      "13           Skeletal       1\n",
      "14          Infection       1\n"
     ]
    }
   ],
   "source": [
    "print(domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:09:22.618817Z",
     "start_time": "2025-07-02T23:09:22.613303Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of categorical traits:', int(plot_df.sum()['Categorical']))\n",
    "print('\\nTop categorical dommains:\\n',pd.DataFrame({'Categorical':domain_dict2}).sort_values('Categorical', ascending=False).head(3))\n",
    "print('\\nTop continuous dommains:\\n',pd.DataFrame({'Continuous':domain_dict}).sort_values('Continuous', ascending=False).head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1D & E - Shared & disjoint genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:09:53.114033Z",
     "start_time": "2025-07-02T23:09:26.406087Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "373it [00:30, 12.42it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_common_genes(t, gwas_genes, accession, trait):\n",
    "    study_genes = gwas_genes[(gwas_genes.TRAIT_CODE_CLEAN==t) & (gwas_genes['STUDY ACCESSION']==accession) & (gwas_genes['DISEASE/TRAIT']==trait)]\n",
    "    study_genes = study_genes.sort_values('logp', ascending=False)\n",
    "    study_genes = study_genes.drop_duplicates(subset='Entrez')\n",
    "    return study_genes\n",
    "\n",
    "def get_rare_genes(t, pmid, trait, ravar_gene):\n",
    "    study_genes = ravar_genes[(ravar_genes.TRAIT_CODE_CLEAN==t) & (ravar_genes['PMID']==pmid) & (ravar_genes['Reported Trait']==trait)]\n",
    "    study_genes = study_genes.sort_values('P-value', ascending=True)\n",
    "    study_genes = study_genes.drop_duplicates(subset='Entrez')\n",
    "    study_genes['logp'] = study_genes['P-value'].apply(lambda x: -1 * np.log10(x +1e-250))\n",
    "    return study_genes\n",
    "\n",
    "results = {}\n",
    "n_overlaps = {}\n",
    "\n",
    "for i, t in tqdm(enumerate(final_shared_df.TRAIT_CODE_CLEAN.values)):\n",
    "    # get common genes\n",
    "    accession = final_shared_df.iloc[i]['STUDY ACCESSION']\n",
    "    trait = final_shared_df.iloc[i]['DISEASE/TRAIT']\n",
    "    c_genes = get_common_genes(t, gwas_genes, accession, trait)\n",
    "    pmid = final_shared_df.iloc[i]['PMID']\n",
    "    trait = final_shared_df.iloc[i]['Reported Trait']\n",
    "    r_genes = get_rare_genes(t, pmid, trait, ravar_genes )\n",
    "    overlap_genes = set(c_genes.Entrez.values).intersection(set(r_genes.Entrez.values))\n",
    "    n_overlaps[t] = len(overlap_genes)\n",
    "    c_disjoint = c_genes[~c_genes.Entrez.isin(overlap_genes)]\n",
    "    r_disjoint = r_genes[~r_genes.Entrez.isin(overlap_genes)]\n",
    "    if len(overlap_genes) > 0:\n",
    "    # common\n",
    "        if len(c_disjoint) > 0:\n",
    "            cDisjoint = c_disjoint.logp.median()\n",
    "            cShared = c_genes[c_genes.Entrez.isin(overlap_genes)].logp.median()\n",
    "        else:\n",
    "            cDisjoint = np.nan\n",
    "            cShared = np.nan\n",
    "            \n",
    "    \n",
    "    # rare\n",
    "        if len(r_disjoint) > 0:\n",
    "            rDisjoint = r_disjoint.logp.median()\n",
    "            rShared = r_genes[r_genes.Entrez.isin(overlap_genes)].logp.median()\n",
    "        else:\n",
    "            rDisjoint = np.nan\n",
    "            rShared = np.nan\n",
    "    else:\n",
    "        cDisjoint = np.nan\n",
    "        cShared = np.nan\n",
    "        rDisjoint = np.nan\n",
    "        rShared = np.nan\n",
    "    results[t] = {'rSharedMed': rShared, 'cSharedMed': cShared, 'rOnlyMed':rDisjoint, 'cOnlyMed': cDisjoint}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:09:54.528704Z",
     "start_time": "2025-07-02T23:09:54.492198Z"
    }
   },
   "outputs": [],
   "source": [
    "over_df = final_shared_df.loc[:, ('TRAIT_CODE_CLEAN', 'trait_type')].set_index('TRAIT_CODE_CLEAN').join(pd.DataFrame({'Shared':n_overlaps}))\n",
    "counts_q={}\n",
    "counts_cc = {}\n",
    "for lo,hi in [(0,0), (1,2), (3, 4), (5,6), (7,8), (9,10), (11,40)]:\n",
    "    c_df = over_df[over_df.trait_type=='CC']\n",
    "    q_df = over_df[over_df.trait_type=='Q']\n",
    "    counts_cc[f'{lo}-{hi}'] = c_df[(c_df.Shared >= lo) & (c_df.Shared<=hi)].shape[0]\n",
    "    counts_q[f'{lo}-{hi}'] = q_df[(q_df.Shared >= lo) & (q_df.Shared<=hi)].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:09:56.014912Z",
     "start_time": "2025-07-02T23:09:55.911551Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(1.5,1.5))\n",
    "ax=plt.gca()\n",
    "pd.DataFrame({'Continuous':counts_q, 'Categorical':counts_cc}).plot(kind='bar', stacked=True, edgecolor='black', linewidth=0.3, width=0.8,\n",
    "                                                                             ax=ax, color=[ '#D47866', '#AE3B24',])\n",
    "ax.set_ylabel('Phenotype Count')\n",
    "ax.set_xlabel('# Shared genes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:09:59.886081Z",
     "start_time": "2025-07-02T23:09:59.883291Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[87]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m test_df = pd.DataFrame.from_dict(\u001b[43mresults\u001b[49m, orient=\u001b[33m'\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "test_df = pd.DataFrame.from_dict(results, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:10:04.203160Z",
     "start_time": "2025-07-02T23:10:03.773070Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[88]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m _, [ax1, ax2] = plt.subplots( nrows=\u001b[32m1\u001b[39m, ncols=\u001b[32m2\u001b[39m, figsize=(\u001b[32m3\u001b[39m, \u001b[32m1.5\u001b[39m), gridspec_kw={\u001b[33m'\u001b[39m\u001b[33mwspace\u001b[39m\u001b[33m'\u001b[39m:\u001b[32m0.4\u001b[39m})\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m sns.violinplot(\u001b[43mtest_df\u001b[49m.melt(value_vars=[ \u001b[33m'\u001b[39m\u001b[33mcSharedMed\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcOnlyMed\u001b[39m\u001b[33m'\u001b[39m], var_name=\u001b[33m'\u001b[39m\u001b[33mSet\u001b[39m\u001b[33m'\u001b[39m, value_name=\u001b[33m'\u001b[39m\u001b[33mMedP\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m      3\u001b[39m               x=\u001b[33m'\u001b[39m\u001b[33mSet\u001b[39m\u001b[33m'\u001b[39m, y=\u001b[33m'\u001b[39m\u001b[33mMedP\u001b[39m\u001b[33m'\u001b[39m, hue=\u001b[33m'\u001b[39m\u001b[33mSet\u001b[39m\u001b[33m'\u001b[39m, cut=\u001b[32m0\u001b[39m, fill=\u001b[38;5;28;01mFalse\u001b[39;00m, palette=[\u001b[33m'\u001b[39m\u001b[33mk\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mk\u001b[39m\u001b[33m'\u001b[39m], linewidth=\u001b[32m0.3\u001b[39m,\n\u001b[32m      4\u001b[39m               order = [ \u001b[33m'\u001b[39m\u001b[33mcSharedMed\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcOnlyMed\u001b[39m\u001b[33m'\u001b[39m,], zorder=\u001b[32m2\u001b[39m, ax=ax1)\n\u001b[32m      5\u001b[39m sns.stripplot(test_df.dropna().melt(value_vars=[ \u001b[33m'\u001b[39m\u001b[33mcSharedMed\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcOnlyMed\u001b[39m\u001b[33m'\u001b[39m], \n\u001b[32m      6\u001b[39m                                     var_name=\u001b[33m'\u001b[39m\u001b[33mSet\u001b[39m\u001b[33m'\u001b[39m, value_name=\u001b[33m'\u001b[39m\u001b[33mMedP\u001b[39m\u001b[33m'\u001b[39m), palette=[blue, blue],\n\u001b[32m      7\u001b[39m               order= [ \u001b[33m'\u001b[39m\u001b[33mcSharedMed\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcOnlyMed\u001b[39m\u001b[33m'\u001b[39m],jitter=\u001b[32m0.2\u001b[39m,\n\u001b[32m      8\u001b[39m               x=\u001b[33m'\u001b[39m\u001b[33mSet\u001b[39m\u001b[33m'\u001b[39m, y=\u001b[33m'\u001b[39m\u001b[33mMedP\u001b[39m\u001b[33m'\u001b[39m, hue=\u001b[33m'\u001b[39m\u001b[33mSet\u001b[39m\u001b[33m'\u001b[39m, edgecolor=\u001b[33m'\u001b[39m\u001b[33mblack\u001b[39m\u001b[33m'\u001b[39m, s=\u001b[32m2\u001b[39m, zorder=\u001b[32m1\u001b[39m, ax=ax1)\n\u001b[32m     10\u001b[39m sns.violinplot(test_df.melt(value_vars=[\u001b[33m'\u001b[39m\u001b[33mrSharedMed\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrOnlyMed\u001b[39m\u001b[33m'\u001b[39m], var_name=\u001b[33m'\u001b[39m\u001b[33mSet\u001b[39m\u001b[33m'\u001b[39m, value_name=\u001b[33m'\u001b[39m\u001b[33mMedP\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     11\u001b[39m               x=\u001b[33m'\u001b[39m\u001b[33mSet\u001b[39m\u001b[33m'\u001b[39m, y=\u001b[33m'\u001b[39m\u001b[33mMedP\u001b[39m\u001b[33m'\u001b[39m, hue=\u001b[33m'\u001b[39m\u001b[33mSet\u001b[39m\u001b[33m'\u001b[39m, cut=\u001b[32m0\u001b[39m, fill=\u001b[38;5;28;01mFalse\u001b[39;00m, palette=[\u001b[33m'\u001b[39m\u001b[33mk\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mk\u001b[39m\u001b[33m'\u001b[39m], linewidth=\u001b[32m0.3\u001b[39m,\n\u001b[32m     12\u001b[39m               order = [ \u001b[33m'\u001b[39m\u001b[33mrSharedMed\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrOnlyMed\u001b[39m\u001b[33m'\u001b[39m], zorder=\u001b[32m2\u001b[39m, ax=ax2)\n",
      "\u001b[31mNameError\u001b[39m: name 'test_df' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x150 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, [ax1, ax2] = plt.subplots( nrows=1, ncols=2, figsize=(3, 1.5), gridspec_kw={'wspace':0.4})\n",
    "sns.violinplot(test_df.melt(value_vars=[ 'cSharedMed', 'cOnlyMed'], var_name='Set', value_name='MedP'),\n",
    "              x='Set', y='MedP', hue='Set', cut=0, fill=False, palette=['k','k'], linewidth=0.3,\n",
    "              order = [ 'cSharedMed', 'cOnlyMed',], zorder=2, ax=ax1)\n",
    "sns.stripplot(test_df.dropna().melt(value_vars=[ 'cSharedMed', 'cOnlyMed'], \n",
    "                                    var_name='Set', value_name='MedP'), palette=[blue, blue],\n",
    "              order= [ 'cSharedMed', 'cOnlyMed'],jitter=0.2,\n",
    "              x='Set', y='MedP', hue='Set', edgecolor='black', s=2, zorder=1, ax=ax1)\n",
    "\n",
    "sns.violinplot(test_df.melt(value_vars=['rSharedMed', 'rOnlyMed'], var_name='Set', value_name='MedP'),\n",
    "              x='Set', y='MedP', hue='Set', cut=0, fill=False, palette=['k', 'k'], linewidth=0.3,\n",
    "              order = [ 'rSharedMed', 'rOnlyMed'], zorder=2, ax=ax2)\n",
    "sns.stripplot(test_df.dropna().melt(value_vars=[ 'rSharedMed', 'rOnlyMed'], \n",
    "                                    var_name='Set', value_name='MedP'), palette=[ green, green],\n",
    "              order= [ 'rSharedMed', 'rOnlyMed'],jitter=0.2,\n",
    "              x='Set', y='MedP', hue='Set', edgecolor='black', s=2, zorder=1, ax=ax2)\n",
    "\n",
    "common_df = test_df.loc[:, ('cSharedMed', 'cOnlyMed')].dropna()\n",
    "rare_df = test_df.loc[:, ('rSharedMed', 'rOnlyMed')].dropna()\n",
    "\n",
    "p_common = wilcoxon(common_df.cSharedMed, common_df.cOnlyMed).pvalue\n",
    "p_rare = wilcoxon(rare_df.rSharedMed, rare_df.rOnlyMed).pvalue\n",
    "\n",
    "\n",
    "for i, ax in enumerate([ax1, ax2]):\n",
    "    ax.set_xticks([0,1], labels=['Shared', 'Disjoint'])\n",
    "    ax.set_xlabel(f'{[\"Common\", \"Rare\"][i]} (n={[len(common_df), len(rare_df)][i]})')\n",
    "    ax.set_ylim(0, [320, 150][i])\n",
    "    ax.text(x=0.25, y=[320, 150][i]*0.75, s=f'p={[p_common, p_rare][i]:.1e}')\n",
    "    ax.set_ylabel('Median Assoc P-value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.406px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
