{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplemental Notebook - Interactive Hierarchy Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows the generation of hierarchy networks in HCX format for interactive capabilities using [web.cytoscape.org](web.cytoscape.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T22:42:35.072959Z",
     "start_time": "2025-06-21T22:42:33.882562Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import ndex2 as ndex\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from ndex2.cx2 import NetworkXToCX2NetworkFactory, CX2Network,  PandasDataFrameToCX2NetworkFactory, CX2NetworkXFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T22:42:35.095260Z",
     "start_time": "2025-06-21T22:42:35.088896Z"
    }
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "sys.path.append(os.path.join(cwd, '../carva'))\n",
    "from network_utils import *\n",
    "from geneset_utils import *\n",
    "from hierarchy_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T22:58:44.929273Z",
     "start_time": "2025-06-21T22:42:35.285696Z"
    }
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "user = getpass('Username:')\n",
    "password = getpass('Password:')\n",
    "client = ndex2.client.Ndex2(username=user, password=password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the subnetworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T22:29:58.359847Z",
     "start_time": "2025-06-21T22:29:58.358203Z"
    }
   },
   "outputs": [],
   "source": [
    "subnetworks = {'autism spectrum disorder': '94590325-4ed4-11f0-a218-005056ae3c32',\n",
    " 'Alzheimer disease': 'a25cd00e-4ed4-11f0-a218-005056ae3c32',\n",
    " 'bipolar disorder': 'a454f6a0-4ed4-11f0-a218-005056ae3c32'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which network is which is a mess. the uuid_list.txt files from whhich \"'autism spectrum disorder': '94590325-4ed4-11f0-a218-005056ae3c32' \" is, is a network of 'all' (z*>3, coloc network) created by S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shachar note: i will need to load the networks manually from local instead of from remote\n",
    "\n",
    "G = nx.read_gpickle(os.path.join(cwd, '../out/net_out/lupus_lupus_net1.gpickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'networkx.classes.graph.Graph'>\n"
     ]
    }
   ],
   "source": [
    "print(type(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is some experimenting with the other graph format, made by create subnetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_other = nx.read_gpickle(os.path.join(cwd, '../out/net_out/lupus_lupus_net1_all.gpickle'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_cx_other = ndex2.create_nice_cx_from_networkx(G_other)\n",
    "first_node_id_other, _ = next(iter(g_cx_other.get_nodes()))\n",
    "node_attributes_other = g_cx_other.get_node_attributes(first_node_id_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(node_attributes_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G_cx = G #.to_networkx()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T22:30:53.153854Z",
     "start_time": "2025-06-21T22:30:52.089675Z"
    }
   },
   "outputs": [],
   "source": [
    "asd_parentG= load_network(uuid=subnetworks['autism spectrum disorder'], use_password=True,ndex_password=password, ndex_user=user)\n",
    "bip_parentG=load_network(uuid=subnetworks['bipolar disorder'], use_password=True,ndex_password=password, ndex_user=user)\n",
    "azd_parentG=load_network(uuid=subnetworks['Alzheimer disease'], use_password=True,ndex_password=password, ndex_user=user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create hierarchy via community detection\n",
    "\n",
    "Example for creation of network hierarchy using HiDeF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid = '3cc84672-1653-11f0-9806-005056ae3c32'\n",
    "outdir = '/output/directory/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_cx = load_network(uuid, use_password=True, return_cx=True, username=username, password=password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### name attribute problem\n",
    "apperantly, my network is missing a \"name\" attribute for the nodes.\n",
    "\n",
    "i will attempt to assign it manually using the GeneID attribute (Entrez id) instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, data in G.nodes(data=True):\n",
    "    if 'name' not in data:\n",
    "        # use a biologically meaningful label if available\n",
    "        G.nodes[n]['name'] = data.get('GeneID', str(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = NetworkXToCX2NetworkFactory()\n",
    "G_cx = factory.get_cx2network(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_cx.set_name(\"pcnet2.2_lupus_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = G_cx.get_name()\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the first few nodes\n",
    "print(type(G))\n",
    "print(len(list(G.nodes(data=True))))\n",
    "list(G.nodes(data=True))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shachar note: changed the returned object on heir utils side, will now convert back to networkx here\n",
    "#G_hier = create_hierarchy(G_cx, verbose=True)\n",
    "CX_hier = create_hierarchy(G_cx, verbose=True)\n",
    "\n",
    "factory = CX2NetworkXFactory()\n",
    "G_hier_multidigraph = factory.get_graph(CX_hier) \n",
    "G_hier = nx.Graph(G_hier_multidigraph)\n",
    "\n",
    "hier_df = create_hier_df(G_hier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old conversion\n",
    "factory = CX2NetworkXFactory()\n",
    "G_hier = factory.get_graph(CX_hier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(type(G_hier))\n",
    "print(G_hier.name)\n",
    "print(len(G_hier.nodes(data=True)))\n",
    "list(G_hier.nodes(data=True))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shachar note: adding uploading the hierarchy network\n",
    "this will enable to run different algorithms than the native one carva runs\n",
    "this might solve the problem with the rest of the pipeline not fitting the output of the algorithm - missing CD_Community_Pval etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_str = upload_network(G_hier, G_hier.name+'_Hierarchy_only', username=user, password=password, template=None)\n",
    "print(id_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for good measures, lets upload the base not and do the whole process there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_str = upload_network(G, G.name+'_base_only', username=user, password=password, template=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(CX_hier))\n",
    "count = 0\n",
    "count0 = 0\n",
    "# Assuming 'hier_net' is your CX2Network object\n",
    "for node_id, node_object in CX_hier.get_nodes().items():\n",
    "    \n",
    "    # 'node_object' contains all node data, including attributes in 'v'\n",
    "    attributes_dict = node_object.get('v', {})\n",
    "    \n",
    "    #print(f\"Node ID: {node_id}\")\n",
    "    #print(f\"Attributes: {attributes_dict}\")\n",
    "    display(attributes_dict)\n",
    "    break\n",
    "    if attributes_dict['CD_AnnotatedMembers_Pvalue'] == 0:\n",
    "        count0 += 1\n",
    "    count+=1\n",
    "    \n",
    "    # Example of getting a specific attribute ('name')\n",
    "    name = attributes_dict.get('name')\n",
    "    #print(f\"Name: {name}\\n\")\n",
    "print(count, count0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempting to fix mismatch by converting from cx2 to cx1\n",
    "G_cx1 = ndex2.create_nice_cx_from_networkx(CX2NetworkXFactory().get_graph(G_cx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to udnerstand network naming conventions\n",
    "print(type(G_cx1))\n",
    "first_node_id, _ = next(iter(G_cx1.get_nodes()))\n",
    "#node_attributes = G_cx1.get_node_attribute(first_node_id, 'GeneClass')\n",
    "node_attributes = G_cx1.get_node_attributes(first_node_id)\n",
    "display(node_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to the pipeline\n",
    "changed the gene fractions function to thew new one, adjusted for the new network format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hier_df = add_seed_gene_fractions(hier_df, G_cx) # was G_cx\n",
    "hier_df = add_seed_gene_fractions_new_format(hier_df, G_cx1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(hier_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../out/net_out/lupus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hier_df_annot = name_hierarchy_systems(hier_df, outdir=outdir, gene_col='SymbolList', write=True, hier_name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hier_df_annot['GO_Name'] = hier_df_annot['GO_Name'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(hier_df_annot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(hier_df_annot[\"GO_Name\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_nx_hierarchy(G_hier, hier_df_annot, outdir, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_out2 = add_annotations_to_hierarchy(G_hier, hier_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(G_out2))\n",
    "list(G_out2.nodes(data=True))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload cx doesnt seem to accept outdir anymore\n",
    "upload_cx_hierarchy(G_hier, hier_df_annot, name, user, password)#, annot_cols=['GO_Name', 'rare', 'common', 'shared', 'rare_z', 'common_z', 'shared_z', 'rc_ratio','CD_MemberList', \n",
    "                                    #'SymbolList', 'CD_MemberList_Size','CD_MemberList_LogSize', 'HiDeF_persistence', 'CD_AnnotatedMembers', 'CD_AnnotatedMembers_Size', 'CD_AnnotatedMembers_Size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_cx_hierarchy(G_hier, hier_df_annot, outdir, name, username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(G_hier.nodes(data=True))[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: using hierr df annot makes the labels go away, using hier df doesnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#again, instead of uploading the hierarchy online, we will save it locally\n",
    "print(type(G_out))\n",
    "nx.write_gpickle(G_out, (os.path.join(outdir, f'{name}_Hierarchy2.gpickle')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(G_out.nodes(data=True))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offline Treatment\n",
    "apperantly, in order to get some cols, you need to do extra analysis outside of this notebook.\n",
    "\n",
    "to not get keyerror over node_data = node_data.loc[:, ['CD_MemberList', 'CD_AnnotatedMembers_Pvalue', 'CD_CommunityName', 'CD_MemberList_LogSize', 'CD_AnnotatedMembers_SourceTerm', 'CD_AnnotatedMembers_SourceDB']]\n",
    "\n",
    "you will need to upload the previous net, do \"Run Community Detection\" using CDAP in cytospcace\\ndex, and then create a new network om which the clustering was performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-computed Hierarchies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T22:31:51.881559Z",
     "start_time": "2025-06-21T22:31:51.879618Z"
    }
   },
   "outputs": [],
   "source": [
    "lupus_uuid = '4c4ffe8a-3cc5-11f0-a469-005056ae3c32'\n",
    "azd_uuid = '44345758-3cc5-11f0-a469-005056ae3c32'\n",
    "bip_uuid = '3f551676-3cc5-11f0-a469-005056ae3c32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lupus_uuid = \"e1a15afa-ba30-11f0-a218-005056ae3c32\" #\"70c44c45-ba2e-11f0-a218-005056ae3c32\" #\"0bbf51af-b982-11f0-a218-005056ae3c32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T22:31:56.087251Z",
     "start_time": "2025-06-21T22:31:56.077768Z"
    }
   },
   "outputs": [],
   "source": [
    "asdG = load_network(uuid=asd_uuid, ndex_password=password, ndex_user=user, verbose=True, use_password=True,\n",
    "                return_cx=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T22:31:57.000241Z",
     "start_time": "2025-06-21T22:31:56.991190Z"
    }
   },
   "outputs": [],
   "source": [
    "azdG = load_network(uuid=azd_uuid, ndex_password=password, ndex_user=user, verbose=True, use_password=True,\n",
    "                return_cx=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T22:31:58.289279Z",
     "start_time": "2025-06-21T22:31:58.280293Z"
    }
   },
   "outputs": [],
   "source": [
    "bipG = load_network(uuid=bip_uuid, ndex_password=password, ndex_user=user, verbose=True, use_password=True,\n",
    "                return_cx=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lupusG = nx.read_gpickle(os.path.join(cwd, '../out/net_out/lupus/pcnet2.2_lupus_Hierarchy.gpickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Name:pcnet2.2_lupus_step1-carva_step2-cdap\n",
      "Number of nodes: 56\n",
      "Number of edges: 58\n"
     ]
    }
   ],
   "source": [
    "lupusG = load_network(uuid=lupus_uuid, ndex_password=password, ndex_user=user, verbose=True, use_password=True,\n",
    "                return_cx=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = str(os.path.join(outdir , \"pcnet2.2_lupus_2_step1-carva_step2-carva.cx\"))\n",
    "\n",
    "lupus_cx = ndex2.create_nice_cx_from_file(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lupusG = lupus_cx.to_networkx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C128706714',\n",
       "  {'CD_MemberList': '3586 11009 6774 29949',\n",
       "   'CD_AnnotatedMembers_Size': '2',\n",
       "   'CD_AnnotatedMembers_Pvalue': '4.7613107361530627E-7',\n",
       "   'CD_AnnotatedMembers': '3586 6774',\n",
       "   'CD_CommunityName': 'FGFR4 p G388R signaling',\n",
       "   'CD_AnnotatedMembers_Overlap': '0.4',\n",
       "   'HiDeF_persistence': '8',\n",
       "   'HCX::isRoot': 'false',\n",
       "   'CD_AnnotatedMembers_SourceTerm': 'WP:WP5428',\n",
       "   'CD_MemberList_LogSize': '2.0',\n",
       "   'HCX::members': ['3586', '11009', '6774', '29949'],\n",
       "   'CD_Labeled': 'true',\n",
       "   'CD_AnnotatedAlgorithm': 'Annotated by gProfiler [Docker: coleslawndex/cdgprofilergenestoterm:0.3.0] {{--organism=hsapiens, --maxpval=0.00001, --minoverlap=0.05, --maxgenelistsize=5000}} via CyCommunityDetection Cytoscape App (1.12.1)',\n",
       "   'selected': 'true',\n",
       "   'CD_NonAnnotatedMembers': '11009 29949',\n",
       "   'CD_AnnotatedMembers_SourceDB': 'WP',\n",
       "   'CD_MemberList_Size': '4'}),\n",
       " ('C128706701',\n",
       "  {'CD_MemberList': '29126 3120 3118 80380 55824',\n",
       "   'CD_AnnotatedMembers_Size': '4',\n",
       "   'CD_AnnotatedMembers_Pvalue': '6.508742513529479E-12',\n",
       "   'CD_AnnotatedMembers': '29126 3120 3118 80380',\n",
       "   'CD_CommunityName': 'Co-inhibition by PD-1',\n",
       "   'CD_AnnotatedMembers_Overlap': '0.16',\n",
       "   'HiDeF_persistence': '25',\n",
       "   'HCX::isRoot': 'false',\n",
       "   'CD_AnnotatedMembers_SourceTerm': 'REAC:R-HSA-389948',\n",
       "   'CD_MemberList_LogSize': '2.322',\n",
       "   'HCX::members': ['29126', '3120', '3118', '80380', '55824'],\n",
       "   'CD_Labeled': 'true',\n",
       "   'CD_AnnotatedAlgorithm': 'Annotated by gProfiler [Docker: coleslawndex/cdgprofilergenestoterm:0.3.0] {{--organism=hsapiens, --maxpval=0.00001, --minoverlap=0.05, --maxgenelistsize=5000}} via CyCommunityDetection Cytoscape App (1.12.1)',\n",
       "   'selected': 'true',\n",
       "   'CD_NonAnnotatedMembers': '55824',\n",
       "   'CD_AnnotatedMembers_SourceDB': 'REAC',\n",
       "   'CD_MemberList_Size': '5'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(lupusG.nodes(data=True))[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes_data = G_out.nodes.data()\n",
    "print(all_nodes_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "supicitions: some GO_Name for the nodes are just the node id (number) while others are actual go terms, ig regulation of immune response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T22:31:59.499735Z",
     "start_time": "2025-06-21T22:31:59.496862Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_hierarchy_info(G):\n",
    "    node_data = {}\n",
    "    for n, data in G.nodes(data=True):\n",
    "        node_data[n] = data\n",
    "    #display(node_data)\n",
    "    node_data = pd.DataFrame(node_data).T\n",
    "    node_data = node_data.loc[:, ['CD_MemberList', 'CD_AnnotatedMembers_Pvalue', 'CD_CommunityName', 'CD_MemberList_LogSize',\n",
    "                                 'CD_AnnotatedMembers_SourceTerm', 'CD_AnnotatedMembers_SourceDB']]\n",
    "    node_data.columns = ['Genes', 'Pvalue', 'Name', 'LogSize', 'SourceTerm', 'SourceDB']\n",
    "    gene_dict = {}\n",
    "    for comm, genes in zip(node_data.index, node_data.Genes):\n",
    "        gene_dict[comm] = [int(x) for x in genes.split(' ')]\n",
    "    return node_data, gene_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lupus_df, lupus_genes = load_hierarchy_info(lupusG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(100507650,\n",
       "  {'GeneID': '100507650',\n",
       "   'represents': 'ncbigene:100507650',\n",
       "   'NPS_R': -1.1150704446291682,\n",
       "   'NPS_C': 5.543708452301536,\n",
       "   'NPS_RC': -6.181625448802352,\n",
       "   'GeneClass': 'common',\n",
       "   'COLOC Gene': 0,\n",
       "   'InputGene': True}),\n",
       " (2052,\n",
       "  {'GeneID': '2052',\n",
       "   'represents': 'ncbigene:2052',\n",
       "   'HGNC': 'MAP9',\n",
       "   'NPS_R': -0.0712179709662565,\n",
       "   'NPS_C': 2.933210439243172,\n",
       "   'NPS_RC': -0.2088972958999407,\n",
       "   'GeneClass': 'common',\n",
       "   'COLOC Gene': 0,\n",
       "   'InputGene': True})]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lupus_parentG = G\n",
    "display(list(lupus_parentG.nodes(data=True))[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T22:32:07.596023Z",
     "start_time": "2025-06-21T22:32:07.586952Z"
    }
   },
   "outputs": [],
   "source": [
    "asd_df, asd_genes = load_hierarchy_info(asdG)\n",
    "azd_df, azd_genes = load_hierarchy_info(azdG)\n",
    "bip_df, bip_genes = load_hierarchy_info(bipG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the HCX Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T22:32:12.083891Z",
     "start_time": "2025-06-21T22:32:12.081103Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cx2_networks(hierG, parentG, comm_df):\n",
    "    factory = NetworkXToCX2NetworkFactory()\n",
    "    factorypd = PandasDataFrameToCX2NetworkFactory()\n",
    "    parent_net =factory.get_cx2network(parentG)\n",
    "    hier_df = nx.to_pandas_edgelist(hierG)\n",
    "    hier_net = factorypd.get_cx2network(hier_df, source_field='source', target_field='target')\n",
    "    for node_id, node_obj in hier_net.get_nodes().items():\n",
    "        comm = hier_net.get_node(node_id).get('v', {}).get('name')\n",
    "        hier_net.add_node_attribute(node_id, 'CD_MemberList', comm_df.loc[comm]['Genes'] ,datatype='string')\n",
    "    return hier_net, parent_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lupus_hier, lupus_parent = get_cx2_networks(lupusG, lupus_parentG, lupus_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T22:32:14.034686Z",
     "start_time": "2025-06-21T22:32:13.298503Z"
    }
   },
   "outputs": [],
   "source": [
    "asd_hier, asd_parent = get_cx2_networks(asdG, asd_parentG, asd_df)\n",
    "azd_hier, azd_parent = get_cx2_networks(azdG, azd_parentG, azd_df)\n",
    "bip_hier, bip_parent = get_cx2_networks(bipG, bip_parentG, bip_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T22:32:14.720615Z",
     "start_time": "2025-06-21T22:32:14.716406Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_hcx(hier_net, parent_net, parent_uuid, hier_name):\n",
    "    hier_net.add_network_attribute('ndexSchema', 'hierarchy_v0.1', datatype='string')\n",
    "    hier_net.add_network_attribute('HCX::modelFileCount', '2', datatype='integer')\n",
    "    hier_net.set_name(hier_name)\n",
    "    hier_net.add_network_attribute('HCX::interactionNetworkUUID', parent_uuid, datatype='string')\n",
    "    all_nodes = set(hier_net.get_nodes().keys())\n",
    "    targets = set()\n",
    "    for edge_id, edge_obj in hier_net.get_edges().items():\n",
    "        targets.add(edge_obj['t'])\n",
    "    # Source node is not a target of any edge\n",
    "    root_nodes = all_nodes.difference(targets)\n",
    "    attr_name = 'HCX::isRoot'\n",
    "    for node_id in hier_net.get_nodes().keys():\n",
    "        hier_net.add_node_attribute(node_id, attr_name, str(node_id in root_nodes).lower(), datatype='boolean')\n",
    "    for node_id, node_obj in hier_net.get_nodes().items():\n",
    "        memberlist = hier_net.get_node(node_id).get('v', {}).get('CD_MemberList', '').split(' ')\n",
    "        membersids = []\n",
    "        for member in memberlist:\n",
    "            membersids.append(int(member))\n",
    "        hier_net.add_node_attribute(node_id, 'HCX::members', membersids, datatype='list_of_integer')\n",
    "    return hier_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lupus_HCX = get_hcx(lupus_hier, lupus_parent, '288f9830-ba29-11f0-a218-005056ae3c32', hier_name='lupus Hierarchy HCX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd_HCX = get_hcx(asd_hier, asd_parent, 'ccd5e0d3-31ac-11f0-a469-005056ae3c32', hier_name='ASD Hierarchy HCX')\n",
    "azd_HCX = get_hcx(azd_hier, azd_parent, 'cd0ad385-31ac-11f0-a469-005056ae3c32', hier_name='AZD Hierarchy HCX')\n",
    "bip_HCX = get_hcx(bip_hier, bip_parent, 'cd515269-31ac-11f0-a469-005056ae3c32', hier_name='BIP Hierarchy HCX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload hiearchies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.ndexbio.org/v3/networks/d628718b-baef-11f0-a218-005056ae3c32'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.save_new_cx2_network(lupus_HCX.to_cx2(), visibility='PRIVATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.save_new_cx2_network(asd_HCX.to_cx2(), visibility='PRIVATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.save_new_cx2_network(azd_HCX.to_cx2(), visibility='PRIVATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.save_new_cx2_network(bip_HCX.to_cx2(), visibility='PRIVATE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add hierarchy annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T21:49:04.244024Z",
     "start_time": "2025-06-13T21:49:04.240498Z"
    }
   },
   "outputs": [],
   "source": [
    "def annotate_and_clean_hierarchy(hier_df, parentG):\n",
    "    hier_df['logp'] = hier_df.Pvalue.apply(lambda x: -1 * np.log10(float(x)))\n",
    "    hier_df['Name'] = clean_names(hier_df['Name'].values)\n",
    "    hier_df = hier_df.drop(columns = ['Pvalue', 'SourceDB'])\n",
    "    comm_features = {comm: {} for comm in hier_df.index.values} \n",
    "    node_data = parentG.nodes(data=True)\n",
    "\n",
    "    node_data_dict = {node_id: data_dict for (node_id, data_dict) in node_data} # this way getting tthe data from the nodes is less error-prone\n",
    "    \n",
    "    #print(type(parentG))\n",
    "    #print([node['GeneID'] for node in list(node_data)])\n",
    "    #print(3586 in [node[1]['GeneID'] for node in list(parentG.nodes(data=True))])\n",
    "    #print(list(parentG.nodes(data=True))[:2])\n",
    "\n",
    "    for comm in comm_features:\n",
    "        genes = hier_df.at[comm, 'Genes'].split(' ')\n",
    "        # seed genes\n",
    "        #debugging\n",
    "\n",
    "        #print([data for data in node_data])\n",
    "        \n",
    "        #print(node_data_dict[3586])\n",
    "        #print(node_data_dict)\n",
    "        '''\n",
    "        for n in genes:\n",
    "            print(n)\n",
    "            #print(node['GeneID'])\n",
    "            #print(type(node_data))\n",
    "            print(parentG.nodes)\n",
    "            for node_id, data_dict in node_data:\n",
    "                if data_dict['GeneID'] == '3586':\n",
    "                    print(f\"Node: {node_id}, Data: {data_dict}\")\n",
    "                    \n",
    "            break\n",
    "        '''\n",
    "        #debend\n",
    "        #gene_classes = pd.DataFrame({'gene_class':[node_data[str(n)]['GeneClass'] for n in genes]}).gene_class.value_counts()\n",
    "        gene_classes = pd.DataFrame({'gene_class':[node_data_dict[int(n)]['GeneClass'] for n in genes]}).gene_class.value_counts()\n",
    "        for frac in ['shared_fraction', 'rare_fraction', 'common_fraction', 'network_fraction']:\n",
    "            comm_features[comm][frac] = 0\n",
    "        if 'shared' in gene_classes.index.values:\n",
    "            comm_features[comm]['shared_fraction'] = gene_classes['shared']/len(genes)\n",
    "        if 'rare' in gene_classes.index.values:\n",
    "            comm_features[comm]['rare_fraction'] = gene_classes['rare']/len(genes)\n",
    "        if 'common' in gene_classes.index.values:\n",
    "            comm_features[comm]['common_fraction'] = gene_classes['common']/len(genes)\n",
    "        if 'Network' in gene_classes.index.values:\n",
    "            comm_features[comm]['network_fraction'] = gene_classes['Network']/len(genes)\n",
    "        assert (comm_features[comm]['shared_fraction'] +comm_features[comm]['rare_fraction']+comm_features[comm]['common_fraction']+comm_features[comm]['network_fraction']) == 1, 'Fractions do not add up to ...'\n",
    "\n",
    "        # NPS scores\n",
    "\n",
    "        correct_keys = ['NPS_C', 'NPS_R', 'NPS_RC'] \n",
    "        nps_names = ['NPSc', 'NPSr', 'NPSrc']\n",
    "\n",
    "        #for z, nps in zip(['z_C', 'z_R', 'Z_coloc'], ['NPSc', 'NPSr', 'NPSrc']): shachar note: they changed the foramat...\n",
    "        for data_key, nps_name in zip(correct_keys, nps_names):\n",
    "            #scores = [float(node_data[n][z]) for n in genes]\n",
    "            scores = [float(node_data_dict[int(n)][data_key]) for n in genes]\n",
    "            comm_features[comm][nps_name] = np.mean(np.array(scores))\n",
    "        comm_features[comm]['c_vs_r'] = comm_features[comm]['NPSc'] / (comm_features[comm]['NPSc'] + comm_features[comm]['NPSr']) - 0.5\n",
    "        # symbols\n",
    "        #symbols = [node_data[n]['HGNC'] for n in genes]\n",
    "        #data_dic = ([node_data_dict[int(n)] for n in genes])\n",
    "        #node_data_dict[29949]['HGNC'] = 'IL19'\n",
    "        \n",
    "        add_hgnc(node_data_dict)\n",
    "        '''\n",
    "        #code to find how many missing hgnc values are there \n",
    "        symbols = []\n",
    "        error_count = 0\n",
    "        for n in genes:\n",
    "            try:\n",
    "                symbols.append(node_data_dict[int(n)]['HGNC'])\n",
    "            except KeyError:\n",
    "                error_count+=1\n",
    "                print(f\"Problem: Gene {n} is missing the 'HGNC' key.\")\n",
    "                # Optional: Print the whole data dict to see what it has\n",
    "                print(f\"Data for gene {n}: {node_data_dict[int(n)]}\")\n",
    "        print(\"error count:\", error_count)\n",
    "        '''\n",
    "        \n",
    "\n",
    "        symbols = [node_data_dict[int(n)][\"HGNC\"] for n in genes]\n",
    "        comm_features[comm]['HGNC'] = ' '.join(symbols)\n",
    "\n",
    "    comm_df = pd.DataFrame.from_dict(comm_features, orient='index')\n",
    "    return hier_df.join(comm_df)\n",
    "    \n",
    "def clean_names(names):\n",
    "    replace = {'calcium': 'Ca', 'Calcium':'Ca', 'regulation':'reg.', 'Regulation':'Reg.', \n",
    "          'activity': 'activ.', 'organization':'org.', '(none)': 'NA'}\n",
    "    names_out =[]\n",
    "    for name in names:\n",
    "        for before, after in replace.items():\n",
    "            name = name.replace(before, after)\n",
    "        names_out.append(name[0].capitalize() + name[1:])\n",
    "    return names_out\n",
    "\n",
    "\n",
    "def add_hgnc(node_data_dict):\n",
    "    \"\"\"\n",
    "        input: a dict of the form node_id: attributes_dict\n",
    "        output: adds missing HGNC values to input dict. changes in place.\n",
    "    \"\"\"\n",
    "\n",
    "    import mygene\n",
    "\n",
    "    # --- Setup ---\n",
    "    # (Your existing code to get node_data_dict and genes list)\n",
    "    # node_data_dict = ...\n",
    "    # genes = ...\n",
    "\n",
    "    # --- Step 1: Collect all Entrez IDs that need translation ---\n",
    "    ids_to_query = []\n",
    "    nodes_to_update = [] # We'll store the node keys (int) here\n",
    "\n",
    "    for n in node_data_dict.keys():\n",
    "        int_n = int(n)\n",
    "        node_data = node_data_dict[int_n]\n",
    "        \n",
    "        # Check if 'HGNC' is missing, None, or an empty string\n",
    "        if 'HGNC' not in node_data or not node_data['HGNC']:\n",
    "            gene_id = node_data.get('GeneID')\n",
    "            \n",
    "            # Only query if we have a valid GeneID\n",
    "            if gene_id:\n",
    "                ids_to_query.append(gene_id)\n",
    "                nodes_to_update.append(int_n) # Save the node key\n",
    "\n",
    "    # Get a unique list of IDs to query\n",
    "    ids_to_query = list(set(ids_to_query))\n",
    "\n",
    "    # --- Step 2: Batch query mygene.info ---\n",
    "    entrez_to_hgnc_map = {} # This will store our {entrez: hgnc} mappings\n",
    "\n",
    "    if ids_to_query:\n",
    "        print(f\"Querying mygene.info for {len(ids_to_query)} Entrez IDs...\")\n",
    "        mg = mygene.MyGeneInfo()\n",
    "        \n",
    "        # Send all IDs in one batch request\n",
    "        # scope='entrezgene' tells it we are sending Entrez IDs\n",
    "        # fields='symbol' asks it to return the 'symbol' (which is HGNC)\n",
    "        results = mg.querymany(ids_to_query, scopes='entrezgene', fields='symbol', species='human')\n",
    "        print(\"...query complete.\")\n",
    "        \n",
    "        # --- Step 3: Create a simple translation dictionary ---\n",
    "        for res in results:\n",
    "            query_id = res.get('query') # The Entrez ID we sent\n",
    "            hgnc_symbol = res.get('symbol')\n",
    "            \n",
    "            if query_id and hgnc_symbol:\n",
    "                entrez_to_hgnc_map[query_id] = hgnc_symbol\n",
    "\n",
    "    # --- Step 4: Update your main data dictionary ---\n",
    "    for int_n in nodes_to_update:\n",
    "        node_data = node_data_dict[int_n]\n",
    "        gene_id = node_data['GeneID'] # We know this exists\n",
    "        \n",
    "        # Get the translated symbol from our map\n",
    "        translated_symbol = entrez_to_hgnc_map.get(gene_id)\n",
    "        \n",
    "        if translated_symbol:\n",
    "            # Success! Fill in the correct HGNC symbol\n",
    "            node_data['HGNC'] = translated_symbol\n",
    "        else:\n",
    "            # Translation failed, use the GeneID as a fallback\n",
    "            # print(f\"Warning: Could not find HGNC for Entrez {gene_id}. Using ID.\")\n",
    "            node_data['HGNC'] = gene_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input sequence provided is already in string format. No operation performed\n",
      "Input sequence provided is already in string format. No operation performed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying mygene.info for 221 Entrez IDs...\n",
      "...query complete.\n"
     ]
    }
   ],
   "source": [
    "lupus_out = annotate_and_clean_hierarchy(lupus_df.copy(), lupus_parentG.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../out/net_out/lupus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "lupus_out.to_csv(os.path.join(outdir, 'lupus_hier_info.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd_out = annotate_and_clean_hierarchy(asd_df.copy(), asd_parentG.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azd_out = annotate_and_clean_hierarchy(azd_df.copy(), azd_parentG.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bip_out = annotate_and_clean_hierarchy(bip_df.copy(), bip_parentG.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd_out.to_csv('~/Data/Transfer/RVC/figures/NPD/ASD_hier_info.tsv', sep='\\t')\n",
    "azd_out.to_csv('~/Data/Transfer/RVC/figures/NPD/AZD_hier_info.tsv', sep='\\t')\n",
    "bip_out.to_csv('~/Data/Transfer/RVC/figures/NPD/BIP_hier_info.tsv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
